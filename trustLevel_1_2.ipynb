{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trustLevel_1_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Idea:** Train separate models based on different trustLevel scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.tree import DecisionTreeClassifier as DT\n",
    "from sklearn import svm as SVM\n",
    "from sklearn.naive_bayes import GaussianNB as NB\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom imports\n",
    "from funcs import plot_cv_confidence_vs_profit, score_dmc_profit,dmc_profit,cv_preds_and_confusion_matrix,cv_profits_for_models, profit_scoring\n",
    "from customClassifiers import CustomModelWithThreshold, TrustHard, PerceptronLearner\n",
    "from pipes import CustomAttributeAdder,Scaling,RandomAttributeAdder,Transformer,ClfSwitcher\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use sklearn pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nico's script\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, random_state=42)\n",
    "def profit_scorer(y, y_pred):\n",
    "    profit_matrix = {(0,0): 0, (0,1): -5, (1,0): -25, (1,1): 5}\n",
    "    return sum(profit_matrix[(pred, actual)] for pred, actual in zip(y_pred, y))\n",
    "profit_scoring = make_scorer(profit_scorer, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "df_train = pd.read_csv('train.csv' ,delimiter=\"|\")\n",
    "df_test = pd.read_csv('test.csv', delimiter=\"|\")\n",
    "X_train, y_train = df_train.drop(columns='fraud'), df_train['fraud']\n",
    "#y_test = test.pop('fraud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1879, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trustLevel</th>\n",
       "      <th>totalScanTimeInSeconds</th>\n",
       "      <th>grandTotal</th>\n",
       "      <th>lineItemVoids</th>\n",
       "      <th>scansWithoutRegistration</th>\n",
       "      <th>quantityModifications</th>\n",
       "      <th>scannedLineItemsPerSecond</th>\n",
       "      <th>valuePerSecond</th>\n",
       "      <th>lineItemVoidsPerPosition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1054</td>\n",
       "      <td>54.70</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.027514</td>\n",
       "      <td>0.051898</td>\n",
       "      <td>0.241379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>108</td>\n",
       "      <td>27.36</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.129630</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.357143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1516</td>\n",
       "      <td>62.16</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.008575</td>\n",
       "      <td>0.041003</td>\n",
       "      <td>0.230769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   trustLevel  totalScanTimeInSeconds  grandTotal  lineItemVoids  \\\n",
       "0           5                    1054       54.70              7   \n",
       "1           3                     108       27.36              5   \n",
       "2           3                    1516       62.16              3   \n",
       "\n",
       "   scansWithoutRegistration  quantityModifications  scannedLineItemsPerSecond  \\\n",
       "0                         0                      3                   0.027514   \n",
       "1                         2                      4                   0.129630   \n",
       "2                        10                      5                   0.008575   \n",
       "\n",
       "   valuePerSecond  lineItemVoidsPerPosition  \n",
       "0        0.051898                  0.241379  \n",
       "1        0.253333                  0.357143  \n",
       "2        0.041003                  0.230769  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "X_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trustLevel==1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(332, 9)\n",
      "(332,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trustLevel</th>\n",
       "      <th>totalScanTimeInSeconds</th>\n",
       "      <th>grandTotal</th>\n",
       "      <th>lineItemVoids</th>\n",
       "      <th>scansWithoutRegistration</th>\n",
       "      <th>quantityModifications</th>\n",
       "      <th>scannedLineItemsPerSecond</th>\n",
       "      <th>valuePerSecond</th>\n",
       "      <th>lineItemVoidsPerPosition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>770</td>\n",
       "      <td>11.09</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.033766</td>\n",
       "      <td>0.014403</td>\n",
       "      <td>0.423077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>870</td>\n",
       "      <td>32.45</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.006897</td>\n",
       "      <td>0.037299</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>78.91</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>1.111408</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    trustLevel  totalScanTimeInSeconds  grandTotal  lineItemVoids  \\\n",
       "5            1                     770       11.09             11   \n",
       "15           1                     870       32.45              3   \n",
       "24           1                      71       78.91              1   \n",
       "\n",
       "    scansWithoutRegistration  quantityModifications  \\\n",
       "5                          5                      2   \n",
       "15                         1                      5   \n",
       "24                         4                      4   \n",
       "\n",
       "    scannedLineItemsPerSecond  valuePerSecond  lineItemVoidsPerPosition  \n",
       "5                    0.033766        0.014403                  0.423077  \n",
       "15                   0.006897        0.037299                  0.500000  \n",
       "24                   0.014085        1.111408                  1.000000  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create X_train trustLevel==1\n",
    "df_train = pd.read_csv('train.csv' ,delimiter=\"|\")\n",
    "\n",
    "is_trust1 = df_train['trustLevel']==1\n",
    "df_train_trust1 = df_train[is_trust1]\n",
    "\n",
    "X_train_trust1, y_train_trust1 = df_train_trust1.drop(columns='fraud'), df_train_trust1['fraud']\n",
    "\n",
    "print(X_train_trust1.shape)\n",
    "print(y_train_trust1.shape)\n",
    "X_train_trust1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data size trustLevel==1: 332\n",
      "[(0, 243), (1, 89)]\n",
      "Max. profit: 445\n"
     ]
    }
   ],
   "source": [
    "# show distribution\n",
    "from collections import Counter\n",
    "\n",
    "print(\"training data size trustLevel==1: {}\".format(len(y_train_trust1)))\n",
    "print(sorted(Counter(y_train_trust1).items()))\n",
    "print(\"Max. profit: {}\".format(89*5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Maximal profit equals **445**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select one or more out of feature list below that will be added in the featureGenerationPipeline\n",
    "feature_list = ['scannedLineItemsTotal',\n",
    "                'valuePerLineItem',\n",
    "                'quantityModificationsPerLineItem',\n",
    "                'lineItemVoids*scansWithoutRegistration',\n",
    "                #'totalScanTimeInSeconds/trustLevel',\n",
    "                #'trustLevel_Log', \n",
    "               ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Only two preprocessing steps at the moment are adding newly designed features (see above) and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureGeneration_pipeline = Pipeline([\n",
    "    (\"attribs_adder\", CustomAttributeAdder(featurelist=feature_list)),                \n",
    "    #(\"RandomAttributeAdder\", RandomAttributeAdder())         #  This class is still void\n",
    "    ])\n",
    "\n",
    "\n",
    "preprocessing_pipeline = Pipeline([\n",
    "    #(\"transformer\", Transformer()),                           # This class is still void\n",
    "    (\"scaler\", Scaling(strategy='Standard')),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roman/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/roman/anaconda3/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "# combine two pipeline into a single data_preparation_pipeline\n",
    "data_preparation_pipeline = Pipeline([\n",
    "    ('feature_generation', featureGeneration_pipeline),\n",
    "    ('preprocessing', preprocessing_pipeline)\n",
    "])\n",
    "\n",
    "X_train_trust1_prepared = data_preparation_pipeline.fit_transform(X_train_trust1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete trustLevel feature!\n",
    "X_train_trust1_prepared = np.delete(X_train_trust1_prepared, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(332, 12)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_trust1_prepared.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the library for Bayesian optimization from here: https://github.com/fmfn/BayesianOptimization\n",
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateLogistic(C):\n",
    "    \n",
    "    model = LogisticRegression(C=C, solver='liblinear', random_state=42)\n",
    "    \n",
    "    return np.mean(cross_validate(model, X_train_trust1_prepared, y=y_train_trust1, cv=cv,\n",
    "                                scoring=profit_scoring,\n",
    "                                  #scoring=\"f1\"\n",
    "                                 )['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_logistic = {\n",
    "    'C': (1,35),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimization_logistic = BayesianOptimization(evaluateLogistic, params_logistic, random_state=231)\n",
    "optimization_logistic.maximize(n_iter=50, init_points=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimization_logistic.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "335"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(cross_validate(LogisticRegression(C=2.32,\n",
    "                                      solver='liblinear',\n",
    "                                      random_state=42),\n",
    "                   X_train_trust1_prepared,\n",
    "                   y=y_train_trust1,\n",
    "                   cv=cv,\n",
    "                   scoring=profit_scoring)['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7528089887640449"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "335/445"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:** For **trustLevel==1** Logistic Regression achieves profit of **335** or **0.75** percent of maximal profit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateSgd(alpha, l1_ratio, tol, penalty, loss):\n",
    "    \n",
    "    # 3 options, l1 by default\n",
    "    penalty_str = 'l1'\n",
    "    if int(penalty) == 0:\n",
    "        penalty_str = 'l2'\n",
    "    elif int(penalty) == 1:\n",
    "        penalty_str = 'elasticnet'\n",
    "    \n",
    "    # 3 options, modified_huber by default\n",
    "    loss_str = 'modified_huber'\n",
    "    if int(loss) == 0:\n",
    "        loss_str = 'hinge'\n",
    "    elif int(loss) == 1:\n",
    "        loss_str = 'log'\n",
    "        \n",
    "    \n",
    "    model = SGDClassifier(alpha=alpha, l1_ratio=l1_ratio, tol=tol,\n",
    "                          penalty=penalty_str, loss=loss_str, random_state=231)\n",
    "    \n",
    "    # This integrates sampling into the training. Trains on oversampled data but evaluates on unsampled data\n",
    "    #return cross_val_imbalanced(model, X_train_prepared, y_train, RandomOverSampler(random_state=42))\n",
    "    \n",
    "    # this trains the classifier on the unbalanced folds\n",
    "    return sum(cross_validate(model, X_train_trust1_prepared, y=y_train_trust1, cv=cv,\n",
    "                              #scoring=\"f1\",\n",
    "                              scoring=profit_scoring,\n",
    "                             )['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_sgd = {\n",
    "    'alpha': (1e-6, 1),\n",
    "    'l1_ratio': (0, 1),\n",
    "    'tol': (1e-9, 1e-1),\n",
    "    'penalty': (0, 3),\n",
    "    'loss': (0, 3)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimization_sgd = BayesianOptimization(evaluateSgd, params_sgd, random_state=231)\n",
    "optimization_sgd.maximize(n_iter=200, init_points=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimization_sgd.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "320"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(cross_validate(SGDClassifier(alpha=0.448373,\n",
    "                                 l1_ratio=0.0859590,\n",
    "                                 tol=0.0403,\n",
    "                                 penalty='elasticnet',\n",
    "                                 loss='modified_huber',\n",
    "                                 random_state=231),\n",
    "                   X_train_trust1_prepared,\n",
    "                   y=y_train_trust1,\n",
    "                   cv=cv,\n",
    "                   scoring=profit_scoring)['test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BorderLineSMOTE + SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sampling classes\n",
    "from imblearn.pipeline import make_pipeline\n",
    "\n",
    "# oversampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "from imblearn.over_sampling import SVMSMOTE\n",
    "\n",
    "# combination of over and undersampling\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.combine import SMOTETomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateSgd(alpha,\n",
    "                l1_ratio,\n",
    "                tol,\n",
    "                n_neighbors,\n",
    "                #k_neighbors,\n",
    "                #m_neighbors\n",
    "               ):\n",
    "    \n",
    "    sampler = RandomOverSampler(random_state=231,\n",
    "                     #n_neighbors=int(n_neighbors),\n",
    "                     #sampling_strategy='all',\n",
    "                     #k_neighbors=int(k_neighbors),\n",
    "                     #m_neighbors=int(m_neighbors)\n",
    "                    )\n",
    "    \n",
    "    model = SGDClassifier(alpha=alpha,\n",
    "                          l1_ratio=l1_ratio,\n",
    "                          tol=tol,\n",
    "                          penalty='elasticnet',\n",
    "                          loss='modified_huber',\n",
    "                          random_state=231)\n",
    "    \n",
    "    sampler_model_pipeline = make_pipeline(sampler,\n",
    "                                          model)\n",
    "    \n",
    "    # this trains the classifier on the unbalanced folds\n",
    "    return sum(cross_validate(sampler_model_pipeline, X_train_trust1_prepared, y=y_train_trust1, cv=cv,\n",
    "                              #scoring=\"f1\",\n",
    "                              scoring=profit_scoring,\n",
    "                             )['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_sgd = {\n",
    "    'alpha': (1e-6, 1),\n",
    "    'l1_ratio': (0, 1),\n",
    "    'tol': (1e-9, 1e-1),\n",
    "    'n_neighbors': (2, 20),\n",
    "    #'k_neighbors': (2, 20),\n",
    "    #'m_neighbors': (2, 20)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimization_sgd = BayesianOptimization(evaluateSgd, params_sgd, random_state=231)\n",
    "optimization_sgd.maximize(n_iter=200, init_points=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimization_sgd.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost + Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateAda(C,\n",
    "                n_estimators,\n",
    "                learning_rate,\n",
    "               ):\n",
    "    \n",
    "    \n",
    "    model = AdaBoostClassifier(base_estimator=LogisticRegression(C=C,\n",
    "                                                                 solver='liblinear',\n",
    "                                                                 random_state=42),\n",
    "                               n_estimators=int(n_estimators),\n",
    "                               learning_rate=learning_rate,\n",
    "                               random_state=231)\n",
    "    \n",
    "    # this trains the classifier on the unbalanced folds\n",
    "    return sum(cross_validate(model, X_train_trust1_prepared, y=y_train_trust1, cv=cv,\n",
    "                              #scoring=\"f1\",\n",
    "                              scoring=profit_scoring,\n",
    "                             )['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_ada = {\n",
    "    'C': (1, 100),\n",
    "    'n_estimators': (50, 500),\n",
    "    'learning_rate': (0.01, 1),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimization_ada = BayesianOptimization(evaluateAda, params_ada, random_state=231)\n",
    "optimization_ada.maximize(n_iter=200, init_points=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimization_ada.max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB - booster:'gblinear'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateXGB(reg_alpha,\n",
    "                reg_lambda,\n",
    "                #subsample, colsample_bytree,\n",
    "                #gamma,\n",
    "                #max_depth,\n",
    "                #min_child_weight,\n",
    "                n_estimators,\n",
    "               ):\n",
    "    \n",
    "    model = XGBClassifier(reg_lambda=reg_lambda,\n",
    "                          reg_alpha=reg_alpha,\n",
    "                          updater='coord_descent',\n",
    "                          learning_rate =0.01,\n",
    "                          n_estimators=int(n_estimators),\n",
    "                          \n",
    "                          #max_depth=int(max_depth),\n",
    "                          #min_child_weight=int(min_child_weight),\n",
    "                          #gamma=gamma,\n",
    "                          #subsample=subsample,\n",
    "                          #colsample_bytree=colsample_bytree,\n",
    "                          #reg_alpha=reg_alpha,\n",
    "                          #reg_lambda=reg_lambda,\n",
    "                          \n",
    "                          objective= 'binary:logistic',\n",
    "                          booster='gblinear',\n",
    "                          n_jobs=-1,\n",
    "                          scale_pos_weight=1,\n",
    "                          seed=231)\n",
    "    \n",
    "    return sum(cross_validate(model, X_train_trust1_prepared, y=y_train_trust1, cv=cv,\n",
    "                              scoring=profit_scoring,\n",
    "                              #scoring=\"f1\",\n",
    "                              #scoring=\"precision\"\n",
    "                              n_jobs=-1)['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_XGB = {\n",
    "    'n_estimators': (50,1000),\n",
    "    #'max_depth':(3,10.5),\n",
    "    #'min_child_weight':(1,6.5),\n",
    "    #'gamma': (0,0.6),\n",
    "    #'subsample':(0.6,1),\n",
    "    #'colsample_bytree':(0.6,1),\n",
    "    'reg_alpha':(0, 100),\n",
    "    'reg_lambda':(0, 100)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimization_XGB = BayesianOptimization(evaluateXGB, params_XGB, random_state=42)\n",
    "optimization_XGB.maximize(n_iter=200, init_points=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimization_XGB.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB - booster:'gbtree'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateXGB(reg_alpha,\n",
    "                #reg_lambda,\n",
    "                subsample, colsample_bytree,\n",
    "                gamma,\n",
    "                max_depth,\n",
    "                min_child_weight,\n",
    "                n_estimators,\n",
    "               ):\n",
    "    \n",
    "    model = XGBClassifier(learning_rate =0.01,\n",
    "                          n_estimators=int(n_estimators),\n",
    "                          max_depth=int(max_depth),\n",
    "                          min_child_weight=int(min_child_weight),\n",
    "                          gamma=gamma,\n",
    "                          subsample=subsample,\n",
    "                          colsample_bytree=colsample_bytree,\n",
    "                          reg_alpha=reg_alpha,\n",
    "                          #reg_lambda=reg_lambda,\n",
    "                          objective= 'binary:logistic',\n",
    "                          booster='gbtree',\n",
    "                          n_jobs=-1,\n",
    "                          scale_pos_weight=1,\n",
    "                          seed=231)\n",
    "    \n",
    "    return sum(cross_validate(model, X_train_trust1_prepared, y=y_train_trust1, cv=cv,\n",
    "                              scoring=profit_scoring,\n",
    "                              #scoring=\"f1\",\n",
    "                              #scoring=\"precision\"\n",
    "                              n_jobs=-1)['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_XGB = {\n",
    "    'n_estimators': (1,1000),\n",
    "    'max_depth':(3,10.5),\n",
    "    'min_child_weight':(1,6.5),\n",
    "    'gamma': (0,0.6),\n",
    "    'subsample':(0.6,1),\n",
    "    'colsample_bytree':(0.6,1),\n",
    "    'reg_alpha':(0.0005, 100),\n",
    "    #'reg_lambda':(0.3, 0.7)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimization_XGB = BayesianOptimization(evaluateXGB, params_XGB, random_state=42)\n",
    "optimization_XGB.maximize(n_iter=200, init_points=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimization_XGB.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trustLevel==2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(347, 9)\n",
      "(347,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trustLevel</th>\n",
       "      <th>totalScanTimeInSeconds</th>\n",
       "      <th>grandTotal</th>\n",
       "      <th>lineItemVoids</th>\n",
       "      <th>scansWithoutRegistration</th>\n",
       "      <th>quantityModifications</th>\n",
       "      <th>scannedLineItemsPerSecond</th>\n",
       "      <th>valuePerSecond</th>\n",
       "      <th>lineItemVoidsPerPosition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>1545</td>\n",
       "      <td>22.80</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.006472</td>\n",
       "      <td>0.014757</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>725</td>\n",
       "      <td>41.08</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.037241</td>\n",
       "      <td>0.056662</td>\n",
       "      <td>0.370370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>125</td>\n",
       "      <td>25.50</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.192000</td>\n",
       "      <td>0.204000</td>\n",
       "      <td>0.208333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    trustLevel  totalScanTimeInSeconds  grandTotal  lineItemVoids  \\\n",
       "7            2                    1545       22.80              0   \n",
       "9            2                     725       41.08             10   \n",
       "23           2                     125       25.50              5   \n",
       "\n",
       "    scansWithoutRegistration  quantityModifications  \\\n",
       "7                          8                      4   \n",
       "9                          2                      4   \n",
       "23                         6                      2   \n",
       "\n",
       "    scannedLineItemsPerSecond  valuePerSecond  lineItemVoidsPerPosition  \n",
       "7                    0.006472        0.014757                  0.000000  \n",
       "9                    0.037241        0.056662                  0.370370  \n",
       "23                   0.192000        0.204000                  0.208333  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create X_train trustLevel==2\n",
    "df_train = pd.read_csv('train.csv' ,delimiter=\"|\")\n",
    "\n",
    "is_trust2 = df_train['trustLevel']==2\n",
    "df_train_trust2 = df_train[is_trust2]\n",
    "\n",
    "X_train_trust2, y_train_trust2 = df_train_trust2.drop(columns='fraud'), df_train_trust2['fraud']\n",
    "\n",
    "print(X_train_trust2.shape)\n",
    "print(y_train_trust2.shape)\n",
    "X_train_trust2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data size trustLevel==1: 347\n",
      "[(0, 332), (1, 15)]\n",
      "Max. profit: 75\n"
     ]
    }
   ],
   "source": [
    "# show distribution\n",
    "from collections import Counter\n",
    "\n",
    "print(\"training data size trustLevel==1: {}\".format(len(y_train_trust2)))\n",
    "print(sorted(Counter(y_train_trust2).items()))\n",
    "print(\"Max. profit: {}\".format(15*5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Maximal profit equals **75**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select one or more out of feature list below that will be added in the featureGenerationPipeline\n",
    "feature_list = ['scannedLineItemsTotal',\n",
    "                'valuePerLineItem',\n",
    "                'quantityModificationsPerLineItem',\n",
    "                'lineItemVoids*scansWithoutRegistration',\n",
    "                #'totalScanTimeInSeconds/trustLevel',\n",
    "                #'trustLevel_Log', \n",
    "               ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Only two preprocessing steps at the moment are adding newly designed features (see above) and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureGeneration_pipeline = Pipeline([\n",
    "    (\"attribs_adder\", CustomAttributeAdder(featurelist=feature_list)),                \n",
    "    #(\"RandomAttributeAdder\", RandomAttributeAdder())         #  This class is still void\n",
    "    ])\n",
    "\n",
    "\n",
    "preprocessing_pipeline = Pipeline([\n",
    "    #(\"transformer\", Transformer()),                           # This class is still void\n",
    "    (\"scaler\", Scaling(strategy='Standard')),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roman/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/roman/anaconda3/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "# combine two pipeline into a single data_preparation_pipeline\n",
    "data_preparation_pipeline = Pipeline([\n",
    "    ('feature_generation', featureGeneration_pipeline),\n",
    "    ('preprocessing', preprocessing_pipeline)\n",
    "])\n",
    "\n",
    "X_train_trust2_prepared = data_preparation_pipeline.fit_transform(X_train_trust2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete trust level\n",
    "X_train_trust2_prepared = np.delete(X_train_trust2_prepared, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(347, 12)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_trust2_prepared.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateLogistic(C):\n",
    "    \n",
    "    model = LogisticRegression(C=C, solver='liblinear', random_state=42)\n",
    "    \n",
    "    return np.mean(cross_validate(model, X_train_trust2_prepared, y=y_train_trust2, cv=cv,\n",
    "                              #scoring=profit_scoring,\n",
    "                             scoring=\"precision\",\n",
    "                             )['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_logistic = {\n",
    "    'C': (1,1000),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimization_logistic = BayesianOptimization(evaluateLogistic, params_logistic, random_state=231)\n",
    "optimization_logistic.maximize(n_iter=50, init_points=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimization_logistic.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-55"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(cross_validate(LogisticRegression(C=140.91,\n",
    "                                      solver='liblinear',\n",
    "                                      random_state=42),\n",
    "                   X_train_trust2_prepared,\n",
    "                   y=y_train_trust2,\n",
    "                   cv=cv,\n",
    "                   scoring=profit_scoring)['test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:** For **trustLevel==2** Logistic Regression achieves profit of **-55**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateSgd(alpha, l1_ratio, tol, penalty, loss):\n",
    "    \n",
    "    # 3 options, l1 by default\n",
    "    penalty_str = 'l1'\n",
    "    if int(penalty) == 0:\n",
    "        penalty_str = 'l2'\n",
    "    elif int(penalty) == 1:\n",
    "        penalty_str = 'elasticnet'\n",
    "    \n",
    "    # 3 options, modified_huber by default\n",
    "    loss_str = 'modified_huber'\n",
    "    if int(loss) == 0:\n",
    "        loss_str = 'hinge'\n",
    "    elif int(loss) == 1:\n",
    "        loss_str = 'log'\n",
    "        \n",
    "    \n",
    "    model = SGDClassifier(alpha=alpha, l1_ratio=l1_ratio, tol=tol,\n",
    "                          penalty=penalty_str, loss=loss_str, random_state=231)\n",
    "    \n",
    "    # This integrates sampling into the training. Trains on oversampled data but evaluates on unsampled data\n",
    "    #return cross_val_imbalanced(model, X_train_prepared, y_train, RandomOverSampler(random_state=42))\n",
    "    \n",
    "    # this trains the classifier on the unbalanced folds\n",
    "    return sum(cross_validate(model, X_train_trust2_prepared, y=y_train_trust2, cv=cv,\n",
    "                              scoring=profit_scoring)['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_sgd = {\n",
    "    'alpha': (1e-6, 1),\n",
    "    'l1_ratio': (0, 1),\n",
    "    'tol': (1e-9, 1e-1),\n",
    "    'penalty': (0, 3),\n",
    "    'loss': (0, 3)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimization_sgd = BayesianOptimization(evaluateSgd, params_sgd, random_state=231)\n",
    "optimization_sgd.maximize(n_iter=200, init_points=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimization_sgd.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(cross_validate(SGDClassifier(alpha=0.002964,\n",
    "                                 l1_ratio=0.702337,\n",
    "                                 tol=0.022649,\n",
    "                                 penalty='elasticnet',\n",
    "                                 loss='modified_huber',\n",
    "                                 random_state=231),\n",
    "                   X_train_trust2_prepared,\n",
    "                   y=y_train_trust2,\n",
    "                   cv=cv,\n",
    "                   scoring=profit_scoring)['test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateXGB(reg_alpha,\n",
    "                #reg_lambda,\n",
    "                subsample, colsample_bytree,\n",
    "                gamma,\n",
    "                max_depth,\n",
    "                #min_child_weight,\n",
    "                n_estimators,\n",
    "               ):\n",
    "    \n",
    "    model = XGBClassifier(learning_rate =0.01,\n",
    "                          n_estimators=int(n_estimators),\n",
    "                          max_depth=int(max_depth),\n",
    "                          min_child_weight=1,\n",
    "                          gamma=gamma,\n",
    "                          subsample=subsample,\n",
    "                          colsample_bytree=colsample_bytree,\n",
    "                          reg_alpha=reg_alpha,\n",
    "                          #reg_lambda=reg_lambda,\n",
    "                          objective= 'binary:logistic',\n",
    "                          n_jobs=-1,\n",
    "                          scale_pos_weight=1,\n",
    "                          seed=231)\n",
    "    \n",
    "    return sum(cross_validate(model, X_train_trust2_prepared, y=y_train_trust2, cv=cv,\n",
    "                              scoring=profit_scoring,\n",
    "                              #scoring=\"f1\",\n",
    "                              #scoring=\"precision\"\n",
    "                              n_jobs=-1)['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_XGB = {\n",
    "    'n_estimators': (500,2500),\n",
    "    'max_depth':(7.5,9.5),\n",
    "    #'min_child_weight':(1,7),\n",
    "    'gamma': (0,0.1),\n",
    "    'subsample':(0.85,1),\n",
    "    'colsample_bytree':(0.85,1),\n",
    "    'reg_alpha':(0.001, 1),\n",
    "    #'reg_lambda':(0.3, 0.7)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimization_XGB = BayesianOptimization(evaluateXGB, params_XGB, random_state=42)\n",
    "optimization_XGB.maximize(n_iter=200, init_points=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimization_XGB.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(cross_validate(XGBClassifier(learning_rate =0.1,\n",
    "                          n_estimators=331,\n",
    "                          max_depth=8,\n",
    "                          min_child_weight=1,\n",
    "                          gamma=0.032443,\n",
    "                          subsample=0.905887,\n",
    "                          colsample_bytree=0.93342,\n",
    "                          reg_alpha=0.782748,\n",
    "                          #reg_lambda=0.5123,\n",
    "                          objective= 'binary:logistic',\n",
    "                          n_jobs=-1,\n",
    "                          scale_pos_weight=1,\n",
    "                          seed=231),\n",
    "                   X_train_trust2_prepared,\n",
    "                   y=y_train_trust2,\n",
    "                   cv=cv,\n",
    "                   scoring=profit_scoring)['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trustLevel1 & 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(679, 9)\n",
      "(679,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trustLevel</th>\n",
       "      <th>totalScanTimeInSeconds</th>\n",
       "      <th>grandTotal</th>\n",
       "      <th>lineItemVoids</th>\n",
       "      <th>scansWithoutRegistration</th>\n",
       "      <th>quantityModifications</th>\n",
       "      <th>scannedLineItemsPerSecond</th>\n",
       "      <th>valuePerSecond</th>\n",
       "      <th>lineItemVoidsPerPosition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>770</td>\n",
       "      <td>11.09</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.033766</td>\n",
       "      <td>0.014403</td>\n",
       "      <td>0.423077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>1545</td>\n",
       "      <td>22.80</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.006472</td>\n",
       "      <td>0.014757</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>725</td>\n",
       "      <td>41.08</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.037241</td>\n",
       "      <td>0.056662</td>\n",
       "      <td>0.370370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   trustLevel  totalScanTimeInSeconds  grandTotal  lineItemVoids  \\\n",
       "5           1                     770       11.09             11   \n",
       "7           2                    1545       22.80              0   \n",
       "9           2                     725       41.08             10   \n",
       "\n",
       "   scansWithoutRegistration  quantityModifications  scannedLineItemsPerSecond  \\\n",
       "5                         5                      2                   0.033766   \n",
       "7                         8                      4                   0.006472   \n",
       "9                         2                      4                   0.037241   \n",
       "\n",
       "   valuePerSecond  lineItemVoidsPerPosition  \n",
       "5        0.014403                  0.423077  \n",
       "7        0.014757                  0.000000  \n",
       "9        0.056662                  0.370370  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create X_train trustLevel==1\n",
    "df_train = pd.read_csv('train.csv' ,delimiter=\"|\")\n",
    "\n",
    "is_trust12 = df_train['trustLevel']<=2\n",
    "df_train_trust12 = df_train[is_trust12]\n",
    "\n",
    "X_train_trust12, y_train_trust12 = df_train_trust12.drop(columns='fraud'), df_train_trust12['fraud']\n",
    "\n",
    "print(X_train_trust12.shape)\n",
    "print(y_train_trust12.shape)\n",
    "X_train_trust12.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data size trustLevel==1&2 combined: 679\n",
      "[(0, 575), (1, 104)]\n",
      "Max. Profit: 520\n"
     ]
    }
   ],
   "source": [
    "# show distribution\n",
    "from collections import Counter\n",
    "\n",
    "print(\"training data size trustLevel==1&2 combined: {}\".format(len(y_train_trust12)))\n",
    "print(sorted(Counter(y_train_trust12).items()))\n",
    "print(\"Max. Profit: {}\".format(104*5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Maximal profit equals **520**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep trustLevel as a feature but recode it to be binary [0,1]\n",
    "X_train_trust12['trustLevel'].replace(to_replace=1, value=0, inplace=True)\n",
    "X_train_trust12['trustLevel'].replace(to_replace=2, value=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trustLevel</th>\n",
       "      <th>totalScanTimeInSeconds</th>\n",
       "      <th>grandTotal</th>\n",
       "      <th>lineItemVoids</th>\n",
       "      <th>scansWithoutRegistration</th>\n",
       "      <th>quantityModifications</th>\n",
       "      <th>scannedLineItemsPerSecond</th>\n",
       "      <th>valuePerSecond</th>\n",
       "      <th>lineItemVoidsPerPosition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>770</td>\n",
       "      <td>11.09</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.033766</td>\n",
       "      <td>0.014403</td>\n",
       "      <td>0.423077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1545</td>\n",
       "      <td>22.80</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.006472</td>\n",
       "      <td>0.014757</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>725</td>\n",
       "      <td>41.08</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.037241</td>\n",
       "      <td>0.056662</td>\n",
       "      <td>0.370370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   trustLevel  totalScanTimeInSeconds  grandTotal  lineItemVoids  \\\n",
       "5           0                     770       11.09             11   \n",
       "7           1                    1545       22.80              0   \n",
       "9           1                     725       41.08             10   \n",
       "\n",
       "   scansWithoutRegistration  quantityModifications  scannedLineItemsPerSecond  \\\n",
       "5                         5                      2                   0.033766   \n",
       "7                         8                      4                   0.006472   \n",
       "9                         2                      4                   0.037241   \n",
       "\n",
       "   valuePerSecond  lineItemVoidsPerPosition  \n",
       "5        0.014403                  0.423077  \n",
       "7        0.014757                  0.000000  \n",
       "9        0.056662                  0.370370  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_trust12.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select one or more out of feature list below that will be added in the featureGenerationPipeline\n",
    "feature_list = ['scannedLineItemsTotal',\n",
    "                'valuePerLineItem',\n",
    "                'quantityModificationsPerLineItem',\n",
    "                'lineItemVoids*scansWithoutRegistration',\n",
    "                #'totalScanTimeInSeconds/trustLevel',\n",
    "                #'trustLevel_Log', \n",
    "               ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Only two preprocessing steps at the moment are adding newly designed features (see above) and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureGeneration_pipeline = Pipeline([\n",
    "    (\"attribs_adder\", CustomAttributeAdder(featurelist=feature_list)),                \n",
    "    #(\"RandomAttributeAdder\", RandomAttributeAdder())         #  This class is still void\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** This is a slight change to the preprocesses pipeline to treat trustLevel as a categorical feature and do not apply scaling to it (I'm pretty sure there is a smarter way of achieving this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a class: that will take pandas dataframe select columns and convert to numpy array\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['totalScanTimeInSeconds', 'grandTotal', 'lineItemVoids',\n",
       "       'scansWithoutRegistration', 'quantityModifications',\n",
       "       'scannedLineItemsPerSecond', 'valuePerSecond',\n",
       "       'lineItemVoidsPerPosition'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_trust12_num = X_train_trust12.drop(columns='trustLevel')\n",
    "X_train_trust12_num.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use DataFrameSelector\n",
    "num_attributes = list(X_train_trust12_num)\n",
    "num_attributes.append('scannedLineItemsTotal')\n",
    "num_attributes.append('valuePerLineItem')\n",
    "num_attributes.append('quantityModificationsPerLineItem')\n",
    "num_attributes.append('lineItemVoids*scansWithoutRegistration')\n",
    "cat_attributes = [\"trustLevel\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['totalScanTimeInSeconds',\n",
       " 'grandTotal',\n",
       " 'lineItemVoids',\n",
       " 'scansWithoutRegistration',\n",
       " 'quantityModifications',\n",
       " 'scannedLineItemsPerSecond',\n",
       " 'valuePerSecond',\n",
       " 'lineItemVoidsPerPosition',\n",
       " 'scannedLineItemsTotal',\n",
       " 'valuePerLineItem',\n",
       " 'quantityModificationsPerLineItem',\n",
       " 'lineItemVoids*scansWithoutRegistration']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline([\n",
    "    (\"selector\", DataFrameSelector(num_attributes)),\n",
    "    (\"scaler\", Scaling(strategy='Standard')),\n",
    "    ])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    (\"selector\", DataFrameSelector(cat_attributes)),\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining numeric and categorical preprocessing with FeatureUnion\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "preprocessing_pipeline = FeatureUnion(transformer_list=[\n",
    "    (\"num_pipeline\", num_pipeline),\n",
    "    (\"cat_pipeline\", cat_pipeline),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine two pipeline into a single data_preparation_pipeline\n",
    "data_preparation_pipeline = Pipeline([\n",
    "    ('feature_generation', featureGeneration_pipeline),\n",
    "    ('preprocessing', preprocessing_pipeline)\n",
    "])\n",
    "\n",
    "X_train_trust12_prepared = data_preparation_pipeline.fit_transform(X_train_trust12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(679, 13)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_trust12_prepared.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.26493495, -1.27906871,  1.59381746, ..., -0.42462227,\n",
       "         1.09821241,  0.        ],\n",
       "       [ 1.18451551, -0.8789435 , -1.61919808, ...,  0.05885284,\n",
       "        -1.02185699,  1.        ],\n",
       "       [-0.34909659, -0.25432447,  1.30172513, ..., -0.31803604,\n",
       "        -0.25092266,  1.        ],\n",
       "       ...,\n",
       "       [-1.10468108,  0.93990064,  0.71754049, ..., -0.40960751,\n",
       "         1.13675913,  0.        ],\n",
       "       [-0.96254142, -0.22664715, -0.15873648, ..., -0.53973539,\n",
       "        -0.05818908,  0.        ],\n",
       "       [-0.42390693,  0.4837374 , -1.32710576, ..., -0.41502951,\n",
       "        -0.79057669,  1.        ]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_trust12_prepared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateXGB(reg_alpha,\n",
    "                #reg_lambda,\n",
    "                subsample, colsample_bytree,\n",
    "                gamma,\n",
    "                max_depth,\n",
    "                min_child_weight,\n",
    "                n_estimators,\n",
    "               ):\n",
    "    \n",
    "    model = XGBClassifier(learning_rate =0.1,\n",
    "                          n_estimators=int(n_estimators),\n",
    "                          max_depth=int(max_depth),\n",
    "                          min_child_weight=(min_child_weight),\n",
    "                          gamma=gamma,\n",
    "                          subsample=subsample,\n",
    "                          colsample_bytree=colsample_bytree,\n",
    "                          reg_alpha=reg_alpha,\n",
    "                          #reg_lambda=reg_lambda,\n",
    "                          objective= 'binary:logistic',\n",
    "                          n_jobs=-1,\n",
    "                          scale_pos_weight=1,\n",
    "                          seed=231)\n",
    "    \n",
    "    return sum(cross_validate(model, X_train_trust12_prepared, y=y_train_trust12, cv=cv,\n",
    "                              scoring=profit_scoring,\n",
    "                              #scoring=\"f1\",\n",
    "                              #scoring=\"precision\"\n",
    "                              n_jobs=-1)['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_XGB = {\n",
    "    'n_estimators': (50,500),\n",
    "    'max_depth':(3,10.5),\n",
    "    'min_child_weight':(1,7),\n",
    "    'gamma': (0,1),\n",
    "    'subsample':(0.6,1),\n",
    "    'colsample_bytree':(0.6,1),\n",
    "    'reg_alpha':(0.001, 100),\n",
    "    #'reg_lambda':(0.3, 0.7)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... |   gamma   | max_depth | min_ch... | n_esti... | reg_alpha | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-55.0    \u001b[0m | \u001b[0m 0.7498  \u001b[0m | \u001b[0m 0.9507  \u001b[0m | \u001b[0m 8.49    \u001b[0m | \u001b[0m 4.592   \u001b[0m | \u001b[0m 120.2   \u001b[0m | \u001b[0m 15.6    \u001b[0m | \u001b[0m 0.6232  \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-520.0   \u001b[0m | \u001b[0m 0.9465  \u001b[0m | \u001b[0m 0.6011  \u001b[0m | \u001b[0m 8.311   \u001b[0m | \u001b[0m 1.124   \u001b[0m | \u001b[0m 486.5   \u001b[0m | \u001b[0m 83.24   \u001b[0m | \u001b[0m 0.6849  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-430.0   \u001b[0m | \u001b[0m 0.6727  \u001b[0m | \u001b[0m 0.1834  \u001b[0m | \u001b[0m 5.282   \u001b[0m | \u001b[0m 4.149   \u001b[0m | \u001b[0m 244.4   \u001b[0m | \u001b[0m 29.12   \u001b[0m | \u001b[0m 0.8447  \u001b[0m |\n",
      "| \u001b[95m 4       \u001b[0m | \u001b[95m-45.0    \u001b[0m | \u001b[95m 0.6558  \u001b[0m | \u001b[95m 0.2921  \u001b[0m | \u001b[95m 5.748   \u001b[0m | \u001b[95m 3.736   \u001b[0m | \u001b[95m 403.3   \u001b[0m | \u001b[95m 19.97   \u001b[0m | \u001b[95m 0.8057  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-520.0   \u001b[0m | \u001b[0m 0.837   \u001b[0m | \u001b[0m 0.04645 \u001b[0m | \u001b[0m 7.557   \u001b[0m | \u001b[0m 2.023   \u001b[0m | \u001b[0m 79.27   \u001b[0m | \u001b[0m 94.89   \u001b[0m | \u001b[0m 0.9863  \u001b[0m |\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m 5.0     \u001b[0m | \u001b[95m 0.9234  \u001b[0m | \u001b[95m 0.3046  \u001b[0m | \u001b[95m 3.733   \u001b[0m | \u001b[95m 5.105   \u001b[0m | \u001b[95m 248.1   \u001b[0m | \u001b[95m 12.2    \u001b[0m | \u001b[95m 0.7981  \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-520.0   \u001b[0m | \u001b[0m 0.6138  \u001b[0m | \u001b[0m 0.9093  \u001b[0m | \u001b[0m 4.941   \u001b[0m | \u001b[0m 4.975   \u001b[0m | \u001b[0m 190.3   \u001b[0m | \u001b[0m 52.01   \u001b[0m | \u001b[0m 0.8187  \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-520.0   \u001b[0m | \u001b[0m 0.6739  \u001b[0m | \u001b[0m 0.9696  \u001b[0m | \u001b[0m 8.813   \u001b[0m | \u001b[0m 6.637   \u001b[0m | \u001b[0m 452.7   \u001b[0m | \u001b[0m 59.79   \u001b[0m | \u001b[0m 0.9687  \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-115.0   \u001b[0m | \u001b[0m 0.6354  \u001b[0m | \u001b[0m 0.196   \u001b[0m | \u001b[0m 3.339   \u001b[0m | \u001b[0m 2.952   \u001b[0m | \u001b[0m 224.9   \u001b[0m | \u001b[0m 27.14   \u001b[0m | \u001b[0m 0.9315  \u001b[0m |\n",
      "| \u001b[95m 10      \u001b[0m | \u001b[95m 60.0    \u001b[0m | \u001b[95m 0.7427  \u001b[0m | \u001b[95m 0.2809  \u001b[0m | \u001b[95m 7.07    \u001b[0m | \u001b[95m 1.846   \u001b[0m | \u001b[95m 411.0   \u001b[0m | \u001b[95m 7.456   \u001b[0m | \u001b[95m 0.9948  \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-520.0   \u001b[0m | \u001b[0m 0.9089  \u001b[0m | \u001b[0m 0.1987  \u001b[0m | \u001b[0m 3.041   \u001b[0m | \u001b[0m 5.893   \u001b[0m | \u001b[0m 368.1   \u001b[0m | \u001b[0m 72.9    \u001b[0m | \u001b[0m 0.9085  \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-520.0   \u001b[0m | \u001b[0m 0.6296  \u001b[0m | \u001b[0m 0.3585  \u001b[0m | \u001b[0m 3.869   \u001b[0m | \u001b[0m 6.179   \u001b[0m | \u001b[0m 330.5   \u001b[0m | \u001b[0m 33.09   \u001b[0m | \u001b[0m 0.6254  \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-520.0   \u001b[0m | \u001b[0m 0.7244  \u001b[0m | \u001b[0m 0.3252  \u001b[0m | \u001b[0m 8.472   \u001b[0m | \u001b[0m 4.825   \u001b[0m | \u001b[0m 449.2   \u001b[0m | \u001b[0m 47.22   \u001b[0m | \u001b[0m 0.6478  \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-520.0   \u001b[0m | \u001b[0m 0.8853  \u001b[0m | \u001b[0m 0.7608  \u001b[0m | \u001b[0m 7.21    \u001b[0m | \u001b[0m 5.626   \u001b[0m | \u001b[0m 272.2   \u001b[0m | \u001b[0m 52.27   \u001b[0m | \u001b[0m 0.771   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-520.0   \u001b[0m | \u001b[0m 0.6102  \u001b[0m | \u001b[0m 0.1079  \u001b[0m | \u001b[0m 3.236   \u001b[0m | \u001b[0m 4.818   \u001b[0m | \u001b[0m 191.5   \u001b[0m | \u001b[0m 50.86   \u001b[0m | \u001b[0m 0.963   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-520.0   \u001b[0m | \u001b[0m 0.6997  \u001b[0m | \u001b[0m 0.4104  \u001b[0m | \u001b[0m 8.667   \u001b[0m | \u001b[0m 2.373   \u001b[0m | \u001b[0m 84.64   \u001b[0m | \u001b[0m 28.98   \u001b[0m | \u001b[0m 0.6645  \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-90.0    \u001b[0m | \u001b[0m 0.9719  \u001b[0m | \u001b[0m 0.8081  \u001b[0m | \u001b[0m 7.751   \u001b[0m | \u001b[0m 6.229   \u001b[0m | \u001b[0m 411.7   \u001b[0m | \u001b[0m 18.66   \u001b[0m | \u001b[0m 0.957   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-120.0   \u001b[0m | \u001b[0m 0.8157  \u001b[0m | \u001b[0m 0.8074  \u001b[0m | \u001b[0m 9.721   \u001b[0m | \u001b[0m 2.908   \u001b[0m | \u001b[0m 99.52   \u001b[0m | \u001b[0m 22.79   \u001b[0m | \u001b[0m 0.7708  \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-110.0   \u001b[0m | \u001b[0m 0.9272  \u001b[0m | \u001b[0m 0.8607  \u001b[0m | \u001b[0m 3.052   \u001b[0m | \u001b[0m 4.064   \u001b[0m | \u001b[0m 237.8   \u001b[0m | \u001b[0m 22.21   \u001b[0m | \u001b[0m 0.6479  \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-520.0   \u001b[0m | \u001b[0m 0.735   \u001b[0m | \u001b[0m 0.9429  \u001b[0m | \u001b[0m 5.424   \u001b[0m | \u001b[0m 4.113   \u001b[0m | \u001b[0m 366.4   \u001b[0m | \u001b[0m 36.36   \u001b[0m | \u001b[0m 0.9887  \u001b[0m |\n",
      "| \u001b[95m 21      \u001b[0m | \u001b[95m 135.0   \u001b[0m | \u001b[95m 0.985   \u001b[0m | \u001b[95m 0.2518  \u001b[0m | \u001b[95m 6.729   \u001b[0m | \u001b[95m 2.805   \u001b[0m | \u001b[95m 178.2   \u001b[0m | \u001b[95m 3.69    \u001b[0m | \u001b[95m 0.8438  \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-115.0   \u001b[0m | \u001b[0m 0.8011  \u001b[0m | \u001b[0m 0.05148 \u001b[0m | \u001b[0m 5.09    \u001b[0m | \u001b[0m 6.45    \u001b[0m | \u001b[0m 157.8   \u001b[0m | \u001b[0m 14.49   \u001b[0m | \u001b[0m 0.7958  \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-520.0   \u001b[0m | \u001b[0m 0.9943  \u001b[0m | \u001b[0m 0.2421  \u001b[0m | \u001b[0m 8.041   \u001b[0m | \u001b[0m 5.57    \u001b[0m | \u001b[0m 156.9   \u001b[0m | \u001b[0m 72.82   \u001b[0m | \u001b[0m 0.7471  \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-520.0   \u001b[0m | \u001b[0m 0.8529  \u001b[0m | \u001b[0m 0.6335  \u001b[0m | \u001b[0m 7.018   \u001b[0m | \u001b[0m 1.542   \u001b[0m | \u001b[0m 425.9   \u001b[0m | \u001b[0m 32.08   \u001b[0m | \u001b[0m 0.6746  \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-75.0    \u001b[0m | \u001b[0m 0.6163  \u001b[0m | \u001b[0m 0.5909  \u001b[0m | \u001b[0m 8.082   \u001b[0m | \u001b[0m 1.1     \u001b[0m | \u001b[0m 280.4   \u001b[0m | \u001b[0m 22.65   \u001b[0m | \u001b[0m 0.8581  \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m-520.0   \u001b[0m | \u001b[0m 0.6697  \u001b[0m | \u001b[0m 0.6909  \u001b[0m | \u001b[0m 5.901   \u001b[0m | \u001b[0m 6.62    \u001b[0m | \u001b[0m 111.9   \u001b[0m | \u001b[0m 34.11   \u001b[0m | \u001b[0m 0.6454  \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m-520.0   \u001b[0m | \u001b[0m 0.9699  \u001b[0m | \u001b[0m 0.8773  \u001b[0m | \u001b[0m 4.935   \u001b[0m | \u001b[0m 4.96    \u001b[0m | \u001b[0m 417.7   \u001b[0m | \u001b[0m 55.52   \u001b[0m | \u001b[0m 0.8119  \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m-520.0   \u001b[0m | \u001b[0m 0.6967  \u001b[0m | \u001b[0m 0.0931  \u001b[0m | \u001b[0m 9.729   \u001b[0m | \u001b[0m 6.403   \u001b[0m | \u001b[0m 334.9   \u001b[0m | \u001b[0m 33.9    \u001b[0m | \u001b[0m 0.7397  \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m-45.0    \u001b[0m | \u001b[0m 0.8904  \u001b[0m | \u001b[0m 0.8971  \u001b[0m | \u001b[0m 9.653   \u001b[0m | \u001b[0m 5.679   \u001b[0m | \u001b[0m 338.9   \u001b[0m | \u001b[0m 8.415   \u001b[0m | \u001b[0m 0.6647  \u001b[0m |\n",
      "| \u001b[95m 30      \u001b[0m | \u001b[95m 185.0   \u001b[0m | \u001b[95m 0.9594  \u001b[0m | \u001b[95m 0.6064  \u001b[0m | \u001b[95m 3.069   \u001b[0m | \u001b[95m 1.609   \u001b[0m | \u001b[95m 348.6   \u001b[0m | \u001b[95m 0.5072  \u001b[0m | \u001b[95m 0.6643  \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m-145.0   \u001b[0m | \u001b[0m 0.8195  \u001b[0m | \u001b[0m 0.6919  \u001b[0m | \u001b[0m 7.89    \u001b[0m | \u001b[0m 2.346   \u001b[0m | \u001b[0m 370.5   \u001b[0m | \u001b[0m 23.73   \u001b[0m | \u001b[0m 0.7302  \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m-15.0    \u001b[0m | \u001b[0m 0.8986  \u001b[0m | \u001b[0m 0.6496  \u001b[0m | \u001b[0m 9.369   \u001b[0m | \u001b[0m 4.946   \u001b[0m | \u001b[0m 305.7   \u001b[0m | \u001b[0m 9.368   \u001b[0m | \u001b[0m 0.7471  \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m-520.0   \u001b[0m | \u001b[0m 0.7061  \u001b[0m | \u001b[0m 0.244   \u001b[0m | \u001b[0m 10.3    \u001b[0m | \u001b[0m 3.359   \u001b[0m | \u001b[0m 451.4   \u001b[0m | \u001b[0m 63.11   \u001b[0m | \u001b[0m 0.9179  \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m-520.0   \u001b[0m | \u001b[0m 0.8011  \u001b[0m | \u001b[0m 0.5769  \u001b[0m | \u001b[0m 6.694   \u001b[0m | \u001b[0m 2.171   \u001b[0m | \u001b[0m 375.1   \u001b[0m | \u001b[0m 28.08   \u001b[0m | \u001b[0m 0.6097  \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m-520.0   \u001b[0m | \u001b[0m 0.8582  \u001b[0m | \u001b[0m 0.1771  \u001b[0m | \u001b[0m 10.05   \u001b[0m | \u001b[0m 6.724   \u001b[0m | \u001b[0m 461.7   \u001b[0m | \u001b[0m 37.02   \u001b[0m | \u001b[0m 0.6062  \u001b[0m |\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m-500.0   \u001b[0m | \u001b[0m 0.9713  \u001b[0m | \u001b[0m 0.4282  \u001b[0m | \u001b[0m 10.25   \u001b[0m | \u001b[0m 6.782   \u001b[0m | \u001b[0m 433.9   \u001b[0m | \u001b[0m 29.45   \u001b[0m | \u001b[0m 0.754   \u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m-520.0   \u001b[0m | \u001b[0m 0.9405  \u001b[0m | \u001b[0m 0.3169  \u001b[0m | \u001b[0m 4.271   \u001b[0m | \u001b[0m 4.341   \u001b[0m | \u001b[0m 471.3   \u001b[0m | \u001b[0m 69.6    \u001b[0m | \u001b[0m 0.828   \u001b[0m |\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m-520.0   \u001b[0m | \u001b[0m 0.6389  \u001b[0m | \u001b[0m 0.615   \u001b[0m | \u001b[0m 10.43   \u001b[0m | \u001b[0m 1.841   \u001b[0m | \u001b[0m 283.2   \u001b[0m | \u001b[0m 87.74   \u001b[0m | \u001b[0m 0.8963  \u001b[0m |\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m-520.0   \u001b[0m | \u001b[0m 0.8788  \u001b[0m | \u001b[0m 0.7025  \u001b[0m | \u001b[0m 5.696   \u001b[0m | \u001b[0m 2.762   \u001b[0m | \u001b[0m 414.2   \u001b[0m | \u001b[0m 81.01   \u001b[0m | \u001b[0m 0.9468  \u001b[0m |\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m-520.0   \u001b[0m | \u001b[0m 0.9653  \u001b[0m | \u001b[0m 0.5113  \u001b[0m | \u001b[0m 6.761   \u001b[0m | \u001b[0m 5.79    \u001b[0m | \u001b[0m 342.5   \u001b[0m | \u001b[0m 70.2    \u001b[0m | \u001b[0m 0.9183  \u001b[0m |\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m 185.0   \u001b[0m | \u001b[0m 0.956   \u001b[0m | \u001b[0m 0.338   \u001b[0m | \u001b[0m 5.817   \u001b[0m | \u001b[0m 1.564   \u001b[0m | \u001b[0m 310.2   \u001b[0m | \u001b[0m 3.595   \u001b[0m | \u001b[0m 0.7862  \u001b[0m |\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m-520.0   \u001b[0m | \u001b[0m 0.8171  \u001b[0m | \u001b[0m 0.2865  \u001b[0m | \u001b[0m 7.431   \u001b[0m | \u001b[0m 1.183   \u001b[0m | \u001b[0m 66.81   \u001b[0m | \u001b[0m 82.26   \u001b[0m | \u001b[0m 0.7441  \u001b[0m |\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m 55.0    \u001b[0m | \u001b[0m 0.6508  \u001b[0m | \u001b[0m 0.5222  \u001b[0m | \u001b[0m 8.775   \u001b[0m | \u001b[0m 2.295   \u001b[0m | \u001b[0m 330.3   \u001b[0m | \u001b[0m 8.536   \u001b[0m | \u001b[0m 0.6207  \u001b[0m |\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m-520.0   \u001b[0m | \u001b[0m 0.8125  \u001b[0m | \u001b[0m 0.5406  \u001b[0m | \u001b[0m 7.781   \u001b[0m | \u001b[0m 5.357   \u001b[0m | \u001b[0m 489.1   \u001b[0m | \u001b[0m 51.63   \u001b[0m | \u001b[0m 0.7292  \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 45      \u001b[0m | \u001b[0m-520.0   \u001b[0m | \u001b[0m 0.9181  \u001b[0m | \u001b[0m 0.2708  \u001b[0m | \u001b[0m 6.292   \u001b[0m | \u001b[0m 1.471   \u001b[0m | \u001b[0m 61.41   \u001b[0m | \u001b[0m 96.26   \u001b[0m | \u001b[0m 0.9344  \u001b[0m |\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m-520.0   \u001b[0m | \u001b[0m 0.8784  \u001b[0m | \u001b[0m 0.409   \u001b[0m | \u001b[0m 4.3     \u001b[0m | \u001b[0m 1.939   \u001b[0m | \u001b[0m 162.6   \u001b[0m | \u001b[0m 54.92   \u001b[0m | \u001b[0m 0.8858  \u001b[0m |\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m-520.0   \u001b[0m | \u001b[0m 0.8641  \u001b[0m | \u001b[0m 0.2799  \u001b[0m | \u001b[0m 10.16   \u001b[0m | \u001b[0m 5.427   \u001b[0m | \u001b[0m 299.5   \u001b[0m | \u001b[0m 61.17   \u001b[0m | \u001b[0m 0.7678  \u001b[0m |\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m 40.0    \u001b[0m | \u001b[0m 0.6991  \u001b[0m | \u001b[0m 0.356   \u001b[0m | \u001b[0m 8.684   \u001b[0m | \u001b[0m 1.086   \u001b[0m | \u001b[0m 102.2   \u001b[0m | \u001b[0m 4.601   \u001b[0m | \u001b[0m 0.6163  \u001b[0m |\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m-520.0   \u001b[0m | \u001b[0m 0.9422  \u001b[0m | \u001b[0m 0.7037  \u001b[0m | \u001b[0m 6.556   \u001b[0m | \u001b[0m 1.587   \u001b[0m | \u001b[0m 271.2   \u001b[0m | \u001b[0m 47.35   \u001b[0m | \u001b[0m 0.6693  \u001b[0m |\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m-520.0   \u001b[0m | \u001b[0m 0.7735  \u001b[0m | \u001b[0m 0.3985  \u001b[0m | \u001b[0m 7.619   \u001b[0m | \u001b[0m 4.811   \u001b[0m | \u001b[0m 70.39   \u001b[0m | \u001b[0m 37.46   \u001b[0m | \u001b[0m 0.8503  \u001b[0m |\n",
      "| \u001b[0m 51      \u001b[0m | \u001b[0m 140.0   \u001b[0m | \u001b[0m 0.94    \u001b[0m | \u001b[0m 0.3399  \u001b[0m | \u001b[0m 5.868   \u001b[0m | \u001b[0m 1.482   \u001b[0m | \u001b[0m 311.5   \u001b[0m | \u001b[0m 3.662   \u001b[0m | \u001b[0m 0.7781  \u001b[0m |\n",
      "| \u001b[0m 52      \u001b[0m | \u001b[0m 140.0   \u001b[0m | \u001b[0m 0.9864  \u001b[0m | \u001b[0m 0.3304  \u001b[0m | \u001b[0m 5.678   \u001b[0m | \u001b[0m 1.675   \u001b[0m | \u001b[0m 308.0   \u001b[0m | \u001b[0m 3.413   \u001b[0m | \u001b[0m 0.8018  \u001b[0m |\n",
      "| \u001b[0m 53      \u001b[0m | \u001b[0m 130.0   \u001b[0m | \u001b[0m 0.9533  \u001b[0m | \u001b[0m 0.3646  \u001b[0m | \u001b[0m 6.115   \u001b[0m | \u001b[0m 1.865   \u001b[0m | \u001b[0m 309.7   \u001b[0m | \u001b[0m 4.068   \u001b[0m | \u001b[0m 0.7838  \u001b[0m |\n",
      "| \u001b[0m 54      \u001b[0m | \u001b[0m 185.0   \u001b[0m | \u001b[0m 0.981   \u001b[0m | \u001b[0m 0.2766  \u001b[0m | \u001b[0m 5.094   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 309.9   \u001b[0m | \u001b[0m 2.474   \u001b[0m | \u001b[0m 0.8013  \u001b[0m |\n",
      "| \u001b[0m 55      \u001b[0m | \u001b[0m 150.0   \u001b[0m | \u001b[0m 0.9686  \u001b[0m | \u001b[0m 0.3088  \u001b[0m | \u001b[0m 5.472   \u001b[0m | \u001b[0m 1.29    \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.061   \u001b[0m | \u001b[0m 0.7938  \u001b[0m |\n",
      "| \u001b[0m 56      \u001b[0m | \u001b[0m 175.0   \u001b[0m | \u001b[0m 0.9499  \u001b[0m | \u001b[0m 0.3437  \u001b[0m | \u001b[0m 5.891   \u001b[0m | \u001b[0m 1.616   \u001b[0m | \u001b[0m 310.6   \u001b[0m | \u001b[0m 3.706   \u001b[0m | \u001b[0m 0.7829  \u001b[0m |\n",
      "| \u001b[0m 57      \u001b[0m | \u001b[0m 160.0   \u001b[0m | \u001b[0m 0.9558  \u001b[0m | \u001b[0m 0.3405  \u001b[0m | \u001b[0m 5.845   \u001b[0m | \u001b[0m 1.557   \u001b[0m | \u001b[0m 310.2   \u001b[0m | \u001b[0m 3.641   \u001b[0m | \u001b[0m 0.786   \u001b[0m |\n",
      "| \u001b[0m 58      \u001b[0m | \u001b[0m 160.0   \u001b[0m | \u001b[0m 0.9574  \u001b[0m | \u001b[0m 0.3239  \u001b[0m | \u001b[0m 5.656   \u001b[0m | \u001b[0m 1.667   \u001b[0m | \u001b[0m 310.5   \u001b[0m | \u001b[0m 3.338   \u001b[0m | \u001b[0m 0.7876  \u001b[0m |\n",
      "| \u001b[0m 59      \u001b[0m | \u001b[0m 150.0   \u001b[0m | \u001b[0m 0.9561  \u001b[0m | \u001b[0m 0.3325  \u001b[0m | \u001b[0m 5.756   \u001b[0m | \u001b[0m 1.533   \u001b[0m | \u001b[0m 310.4   \u001b[0m | \u001b[0m 3.498   \u001b[0m | \u001b[0m 0.7865  \u001b[0m |\n",
      "| \u001b[0m 60      \u001b[0m | \u001b[0m 185.0   \u001b[0m | \u001b[0m 0.9557  \u001b[0m | \u001b[0m 0.3363  \u001b[0m | \u001b[0m 5.796   \u001b[0m | \u001b[0m 1.791   \u001b[0m | \u001b[0m 310.3   \u001b[0m | \u001b[0m 3.558   \u001b[0m | \u001b[0m 0.7862  \u001b[0m |\n",
      "| \u001b[0m 61      \u001b[0m | \u001b[0m 25.0    \u001b[0m | \u001b[0m 0.6992  \u001b[0m | \u001b[0m 0.3557  \u001b[0m | \u001b[0m 8.682   \u001b[0m | \u001b[0m 1.089   \u001b[0m | \u001b[0m 102.2   \u001b[0m | \u001b[0m 4.601   \u001b[0m | \u001b[0m 0.6163  \u001b[0m |\n",
      "| \u001b[0m 62      \u001b[0m | \u001b[0m 115.0   \u001b[0m | \u001b[0m 0.7751  \u001b[0m | \u001b[0m 0.1259  \u001b[0m | \u001b[0m 5.503   \u001b[0m | \u001b[0m 2.016   \u001b[0m | \u001b[0m 308.1   \u001b[0m | \u001b[0m 3.889   \u001b[0m | \u001b[0m 0.9224  \u001b[0m |\n",
      "| \u001b[0m 63      \u001b[0m | \u001b[0m 100.0   \u001b[0m | \u001b[0m 0.9017  \u001b[0m | \u001b[0m 0.4059  \u001b[0m | \u001b[0m 6.728   \u001b[0m | \u001b[0m 2.052   \u001b[0m | \u001b[0m 410.3   \u001b[0m | \u001b[0m 7.157   \u001b[0m | \u001b[0m 0.7358  \u001b[0m |\n",
      "| \u001b[0m 64      \u001b[0m | \u001b[0m 80.0    \u001b[0m | \u001b[0m 0.7084  \u001b[0m | \u001b[0m 0.8982  \u001b[0m | \u001b[0m 5.921   \u001b[0m | \u001b[0m 1.422   \u001b[0m | \u001b[0m 310.7   \u001b[0m | \u001b[0m 3.188   \u001b[0m | \u001b[0m 0.6532  \u001b[0m |\n",
      "| \u001b[0m 65      \u001b[0m | \u001b[0m 120.0   \u001b[0m | \u001b[0m 0.7009  \u001b[0m | \u001b[0m 0.6816  \u001b[0m | \u001b[0m 4.92    \u001b[0m | \u001b[0m 1.118   \u001b[0m | \u001b[0m 309.8   \u001b[0m | \u001b[0m 2.257   \u001b[0m | \u001b[0m 0.7404  \u001b[0m |\n",
      "| \u001b[0m 66      \u001b[0m | \u001b[0m 40.0    \u001b[0m | \u001b[0m 0.9012  \u001b[0m | \u001b[0m 0.4961  \u001b[0m | \u001b[0m 4.308   \u001b[0m | \u001b[0m 5.232   \u001b[0m | \u001b[0m 248.1   \u001b[0m | \u001b[0m 11.78   \u001b[0m | \u001b[0m 0.9853  \u001b[0m |\n",
      "| \u001b[0m 67      \u001b[0m | \u001b[0m 80.0    \u001b[0m | \u001b[0m 0.7251  \u001b[0m | \u001b[0m 0.4571  \u001b[0m | \u001b[0m 5.937   \u001b[0m | \u001b[0m 1.682   \u001b[0m | \u001b[0m 308.0   \u001b[0m | \u001b[0m 4.541   \u001b[0m | \u001b[0m 0.848   \u001b[0m |\n",
      "| \u001b[0m 68      \u001b[0m | \u001b[0m 20.0    \u001b[0m | \u001b[0m 0.7633  \u001b[0m | \u001b[0m 0.4465  \u001b[0m | \u001b[0m 3.958   \u001b[0m | \u001b[0m 5.045   \u001b[0m | \u001b[0m 247.5   \u001b[0m | \u001b[0m 12.28   \u001b[0m | \u001b[0m 0.9775  \u001b[0m |\n",
      "| \u001b[0m 69      \u001b[0m | \u001b[0m-55.0    \u001b[0m | \u001b[0m 0.7501  \u001b[0m | \u001b[0m 0.9499  \u001b[0m | \u001b[0m 8.49    \u001b[0m | \u001b[0m 4.592   \u001b[0m | \u001b[0m 120.2   \u001b[0m | \u001b[0m 15.6    \u001b[0m | \u001b[0m 0.6232  \u001b[0m |\n",
      "| \u001b[0m 70      \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.6461  \u001b[0m | \u001b[0m 0.7525  \u001b[0m | \u001b[0m 3.629   \u001b[0m | \u001b[0m 4.473   \u001b[0m | \u001b[0m 247.6   \u001b[0m | \u001b[0m 12.53   \u001b[0m | \u001b[0m 0.8007  \u001b[0m |\n",
      "| \u001b[0m 71      \u001b[0m | \u001b[0m 130.0   \u001b[0m | \u001b[0m 0.6936  \u001b[0m | \u001b[0m 0.7679  \u001b[0m | \u001b[0m 5.829   \u001b[0m | \u001b[0m 1.827   \u001b[0m | \u001b[0m 309.7   \u001b[0m | \u001b[0m 3.787   \u001b[0m | \u001b[0m 0.8983  \u001b[0m |\n",
      "| \u001b[0m 72      \u001b[0m | \u001b[0m 90.0    \u001b[0m | \u001b[0m 0.6805  \u001b[0m | \u001b[0m 0.8424  \u001b[0m | \u001b[0m 5.293   \u001b[0m | \u001b[0m 1.448   \u001b[0m | \u001b[0m 310.8   \u001b[0m | \u001b[0m 3.104   \u001b[0m | \u001b[0m 0.8643  \u001b[0m |\n",
      "| \u001b[0m 73      \u001b[0m | \u001b[0m 165.0   \u001b[0m | \u001b[0m 0.8234  \u001b[0m | \u001b[0m 0.6259  \u001b[0m | \u001b[0m 3.103   \u001b[0m | \u001b[0m 1.443   \u001b[0m | \u001b[0m 349.2   \u001b[0m | \u001b[0m 0.1934  \u001b[0m | \u001b[0m 0.9369  \u001b[0m |\n",
      "| \u001b[0m 74      \u001b[0m | \u001b[0m-125.0   \u001b[0m | \u001b[0m 0.8839  \u001b[0m | \u001b[0m 0.8081  \u001b[0m | \u001b[0m 7.617   \u001b[0m | \u001b[0m 6.545   \u001b[0m | \u001b[0m 411.7   \u001b[0m | \u001b[0m 18.51   \u001b[0m | \u001b[0m 0.9909  \u001b[0m |\n",
      "| \u001b[0m 75      \u001b[0m | \u001b[0m 130.0   \u001b[0m | \u001b[0m 0.8871  \u001b[0m | \u001b[0m 0.3594  \u001b[0m | \u001b[0m 5.434   \u001b[0m | \u001b[0m 1.451   \u001b[0m | \u001b[0m 307.6   \u001b[0m | \u001b[0m 3.369   \u001b[0m | \u001b[0m 0.6354  \u001b[0m |\n",
      "| \u001b[0m 76      \u001b[0m | \u001b[0m 70.0    \u001b[0m | \u001b[0m 0.7869  \u001b[0m | \u001b[0m 0.7983  \u001b[0m | \u001b[0m 8.468   \u001b[0m | \u001b[0m 2.004   \u001b[0m | \u001b[0m 329.6   \u001b[0m | \u001b[0m 8.493   \u001b[0m | \u001b[0m 0.7413  \u001b[0m |\n",
      "| \u001b[0m 77      \u001b[0m | \u001b[0m 70.0    \u001b[0m | \u001b[0m 0.8999  \u001b[0m | \u001b[0m 0.5455  \u001b[0m | \u001b[0m 8.455   \u001b[0m | \u001b[0m 1.687   \u001b[0m | \u001b[0m 329.6   \u001b[0m | \u001b[0m 8.776   \u001b[0m | \u001b[0m 0.9715  \u001b[0m |\n",
      "| \u001b[0m 78      \u001b[0m | \u001b[0m 125.0   \u001b[0m | \u001b[0m 0.9608  \u001b[0m | \u001b[0m 0.1565  \u001b[0m | \u001b[0m 5.122   \u001b[0m | \u001b[0m 1.363   \u001b[0m | \u001b[0m 308.1   \u001b[0m | \u001b[0m 3.399   \u001b[0m | \u001b[0m 0.8833  \u001b[0m |\n",
      "| \u001b[0m 79      \u001b[0m | \u001b[0m 70.0    \u001b[0m | \u001b[0m 0.7323  \u001b[0m | \u001b[0m 0.6572  \u001b[0m | \u001b[0m 5.819   \u001b[0m | \u001b[0m 1.986   \u001b[0m | \u001b[0m 307.7   \u001b[0m | \u001b[0m 4.843   \u001b[0m | \u001b[0m 0.7811  \u001b[0m |\n",
      "| \u001b[0m 80      \u001b[0m | \u001b[0m 65.0    \u001b[0m | \u001b[0m 0.987   \u001b[0m | \u001b[0m 0.8339  \u001b[0m | \u001b[0m 9.091   \u001b[0m | \u001b[0m 2.372   \u001b[0m | \u001b[0m 330.7   \u001b[0m | \u001b[0m 8.449   \u001b[0m | \u001b[0m 0.8513  \u001b[0m |\n",
      "| \u001b[0m 81      \u001b[0m | \u001b[0m-470.0   \u001b[0m | \u001b[0m 0.7036  \u001b[0m | \u001b[0m 0.2261  \u001b[0m | \u001b[0m 3.208   \u001b[0m | \u001b[0m 2.8     \u001b[0m | \u001b[0m 224.9   \u001b[0m | \u001b[0m 26.92   \u001b[0m | \u001b[0m 0.7006  \u001b[0m |\n",
      "| \u001b[0m 82      \u001b[0m | \u001b[0m 135.0   \u001b[0m | \u001b[0m 0.7724  \u001b[0m | \u001b[0m 0.2219  \u001b[0m | \u001b[0m 6.513   \u001b[0m | \u001b[0m 2.238   \u001b[0m | \u001b[0m 309.6   \u001b[0m | \u001b[0m 3.798   \u001b[0m | \u001b[0m 0.7822  \u001b[0m |\n",
      "| \u001b[0m 83      \u001b[0m | \u001b[0m 160.0   \u001b[0m | \u001b[0m 0.959   \u001b[0m | \u001b[0m 0.3567  \u001b[0m | \u001b[0m 4.691   \u001b[0m | \u001b[0m 1.825   \u001b[0m | \u001b[0m 309.9   \u001b[0m | \u001b[0m 2.269   \u001b[0m | \u001b[0m 0.8277  \u001b[0m |\n",
      "| \u001b[0m 84      \u001b[0m | \u001b[0m-140.0   \u001b[0m | \u001b[0m 0.6023  \u001b[0m | \u001b[0m 0.5448  \u001b[0m | \u001b[0m 5.297   \u001b[0m | \u001b[0m 3.751   \u001b[0m | \u001b[0m 403.2   \u001b[0m | \u001b[0m 19.89   \u001b[0m | \u001b[0m 0.9936  \u001b[0m |\n",
      "| \u001b[0m 85      \u001b[0m | \u001b[0m 115.0   \u001b[0m | \u001b[0m 0.759   \u001b[0m | \u001b[0m 0.154   \u001b[0m | \u001b[0m 5.979   \u001b[0m | \u001b[0m 2.767   \u001b[0m | \u001b[0m 308.6   \u001b[0m | \u001b[0m 4.359   \u001b[0m | \u001b[0m 0.7451  \u001b[0m |\n",
      "| \u001b[0m 86      \u001b[0m | \u001b[0m-40.0    \u001b[0m | \u001b[0m 0.8065  \u001b[0m | \u001b[0m 0.8022  \u001b[0m | \u001b[0m 8.701   \u001b[0m | \u001b[0m 4.238   \u001b[0m | \u001b[0m 120.1   \u001b[0m | \u001b[0m 16.19   \u001b[0m | \u001b[0m 0.9304  \u001b[0m |\n",
      "| \u001b[0m 87      \u001b[0m | \u001b[0m 70.0    \u001b[0m | \u001b[0m 0.8175  \u001b[0m | \u001b[0m 0.5585  \u001b[0m | \u001b[0m 9.055   \u001b[0m | \u001b[0m 2.02    \u001b[0m | \u001b[0m 330.3   \u001b[0m | \u001b[0m 8.66    \u001b[0m | \u001b[0m 0.8097  \u001b[0m |\n",
      "| \u001b[0m 88      \u001b[0m | \u001b[0m-175.0   \u001b[0m | \u001b[0m 0.8103  \u001b[0m | \u001b[0m 0.7569  \u001b[0m | \u001b[0m 7.802   \u001b[0m | \u001b[0m 2.152   \u001b[0m | \u001b[0m 370.9   \u001b[0m | \u001b[0m 23.78   \u001b[0m | \u001b[0m 0.9944  \u001b[0m |\n",
      "| \u001b[95m 89      \u001b[0m | \u001b[95m 200.0   \u001b[0m | \u001b[95m 0.8853  \u001b[0m | \u001b[95m 0.2914  \u001b[0m | \u001b[95m 4.77    \u001b[0m | \u001b[95m 1.356   \u001b[0m | \u001b[95m 308.3   \u001b[0m | \u001b[95m 3.032   \u001b[0m | \u001b[95m 0.9168  \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[95m 90      \u001b[0m | \u001b[95m 220.0   \u001b[0m | \u001b[95m 0.6059  \u001b[0m | \u001b[95m 0.3272  \u001b[0m | \u001b[95m 4.661   \u001b[0m | \u001b[95m 1.751   \u001b[0m | \u001b[95m 309.9   \u001b[0m | \u001b[95m 1.691   \u001b[0m | \u001b[95m 0.725   \u001b[0m |\n",
      "| \u001b[0m 91      \u001b[0m | \u001b[0m 125.0   \u001b[0m | \u001b[0m 0.8519  \u001b[0m | \u001b[0m 0.868   \u001b[0m | \u001b[0m 5.43    \u001b[0m | \u001b[0m 2.008   \u001b[0m | \u001b[0m 311.1   \u001b[0m | \u001b[0m 2.506   \u001b[0m | \u001b[0m 0.8394  \u001b[0m |\n",
      "| \u001b[0m 92      \u001b[0m | \u001b[0m 130.0   \u001b[0m | \u001b[0m 0.6112  \u001b[0m | \u001b[0m 0.1496  \u001b[0m | \u001b[0m 7.16    \u001b[0m | \u001b[0m 2.314   \u001b[0m | \u001b[0m 177.8   \u001b[0m | \u001b[0m 3.797   \u001b[0m | \u001b[0m 0.8792  \u001b[0m |\n",
      "| \u001b[0m 93      \u001b[0m | \u001b[0m 90.0    \u001b[0m | \u001b[0m 0.6975  \u001b[0m | \u001b[0m 0.2712  \u001b[0m | \u001b[0m 6.944   \u001b[0m | \u001b[0m 1.835   \u001b[0m | \u001b[0m 410.4   \u001b[0m | \u001b[0m 7.285   \u001b[0m | \u001b[0m 0.9336  \u001b[0m |\n",
      "| \u001b[0m 94      \u001b[0m | \u001b[0m 130.0   \u001b[0m | \u001b[0m 0.9319  \u001b[0m | \u001b[0m 0.08713 \u001b[0m | \u001b[0m 6.282   \u001b[0m | \u001b[0m 1.712   \u001b[0m | \u001b[0m 309.9   \u001b[0m | \u001b[0m 4.19    \u001b[0m | \u001b[0m 0.6807  \u001b[0m |\n",
      "| \u001b[0m 95      \u001b[0m | \u001b[0m-30.0    \u001b[0m | \u001b[0m 0.8335  \u001b[0m | \u001b[0m 0.9356  \u001b[0m | \u001b[0m 7.779   \u001b[0m | \u001b[0m 6.714   \u001b[0m | \u001b[0m 411.5   \u001b[0m | \u001b[0m 18.79   \u001b[0m | \u001b[0m 0.9511  \u001b[0m |\n",
      "| \u001b[0m 96      \u001b[0m | \u001b[0m 70.0    \u001b[0m | \u001b[0m 0.7093  \u001b[0m | \u001b[0m 0.338   \u001b[0m | \u001b[0m 6.084   \u001b[0m | \u001b[0m 2.088   \u001b[0m | \u001b[0m 308.0   \u001b[0m | \u001b[0m 4.435   \u001b[0m | \u001b[0m 0.7411  \u001b[0m |\n",
      "| \u001b[0m 97      \u001b[0m | \u001b[0m 130.0   \u001b[0m | \u001b[0m 0.8635  \u001b[0m | \u001b[0m 0.2412  \u001b[0m | \u001b[0m 5.088   \u001b[0m | \u001b[0m 1.238   \u001b[0m | \u001b[0m 308.0   \u001b[0m | \u001b[0m 3.509   \u001b[0m | \u001b[0m 0.674   \u001b[0m |\n",
      "| \u001b[0m 98      \u001b[0m | \u001b[0m 185.0   \u001b[0m | \u001b[0m 0.8809  \u001b[0m | \u001b[0m 0.4064  \u001b[0m | \u001b[0m 5.09    \u001b[0m | \u001b[0m 1.87    \u001b[0m | \u001b[0m 307.9   \u001b[0m | \u001b[0m 3.043   \u001b[0m | \u001b[0m 0.8532  \u001b[0m |\n",
      "| \u001b[0m 99      \u001b[0m | \u001b[0m 45.0    \u001b[0m | \u001b[0m 0.8584  \u001b[0m | \u001b[0m 0.742   \u001b[0m | \u001b[0m 6.107   \u001b[0m | \u001b[0m 1.649   \u001b[0m | \u001b[0m 311.8   \u001b[0m | \u001b[0m 3.902   \u001b[0m | \u001b[0m 0.9838  \u001b[0m |\n",
      "| \u001b[0m 100     \u001b[0m | \u001b[0m 45.0    \u001b[0m | \u001b[0m 0.7005  \u001b[0m | \u001b[0m 0.5536  \u001b[0m | \u001b[0m 9.269   \u001b[0m | \u001b[0m 1.95    \u001b[0m | \u001b[0m 331.0   \u001b[0m | \u001b[0m 8.681   \u001b[0m | \u001b[0m 0.6893  \u001b[0m |\n",
      "| \u001b[0m 101     \u001b[0m | \u001b[0m 135.0   \u001b[0m | \u001b[0m 0.6275  \u001b[0m | \u001b[0m 0.07508 \u001b[0m | \u001b[0m 5.789   \u001b[0m | \u001b[0m 1.854   \u001b[0m | \u001b[0m 310.2   \u001b[0m | \u001b[0m 3.833   \u001b[0m | \u001b[0m 0.8649  \u001b[0m |\n",
      "| \u001b[0m 102     \u001b[0m | \u001b[0m-65.0    \u001b[0m | \u001b[0m 0.7623  \u001b[0m | \u001b[0m 0.8552  \u001b[0m | \u001b[0m 3.497   \u001b[0m | \u001b[0m 4.456   \u001b[0m | \u001b[0m 247.3   \u001b[0m | \u001b[0m 12.59   \u001b[0m | \u001b[0m 0.6508  \u001b[0m |\n",
      "| \u001b[0m 103     \u001b[0m | \u001b[0m 195.0   \u001b[0m | \u001b[0m 0.6695  \u001b[0m | \u001b[0m 0.3194  \u001b[0m | \u001b[0m 5.011   \u001b[0m | \u001b[0m 1.231   \u001b[0m | \u001b[0m 309.5   \u001b[0m | \u001b[0m 1.793   \u001b[0m | \u001b[0m 0.9934  \u001b[0m |\n",
      "| \u001b[0m 104     \u001b[0m | \u001b[0m 210.0   \u001b[0m | \u001b[0m 0.9315  \u001b[0m | \u001b[0m 0.0948  \u001b[0m | \u001b[0m 5.295   \u001b[0m | \u001b[0m 1.315   \u001b[0m | \u001b[0m 309.7   \u001b[0m | \u001b[0m 1.768   \u001b[0m | \u001b[0m 0.716   \u001b[0m |\n",
      "| \u001b[0m 105     \u001b[0m | \u001b[0m 80.0    \u001b[0m | \u001b[0m 0.6529  \u001b[0m | \u001b[0m 0.7353  \u001b[0m | \u001b[0m 8.097   \u001b[0m | \u001b[0m 1.764   \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 8.735   \u001b[0m | \u001b[0m 0.897   \u001b[0m |\n",
      "| \u001b[0m 106     \u001b[0m | \u001b[0m 165.0   \u001b[0m | \u001b[0m 0.9676  \u001b[0m | \u001b[0m 0.2096  \u001b[0m | \u001b[0m 5.093   \u001b[0m | \u001b[0m 1.153   \u001b[0m | \u001b[0m 308.7   \u001b[0m | \u001b[0m 2.755   \u001b[0m | \u001b[0m 0.7103  \u001b[0m |\n",
      "| \u001b[0m 107     \u001b[0m | \u001b[0m 130.0   \u001b[0m | \u001b[0m 0.7736  \u001b[0m | \u001b[0m 0.08249 \u001b[0m | \u001b[0m 9.113   \u001b[0m | \u001b[0m 2.443   \u001b[0m | \u001b[0m 331.3   \u001b[0m | \u001b[0m 8.898   \u001b[0m | \u001b[0m 0.744   \u001b[0m |\n",
      "| \u001b[0m 108     \u001b[0m | \u001b[0m 155.0   \u001b[0m | \u001b[0m 0.8385  \u001b[0m | \u001b[0m 0.2972  \u001b[0m | \u001b[0m 4.714   \u001b[0m | \u001b[0m 1.513   \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 1.818   \u001b[0m | \u001b[0m 0.6916  \u001b[0m |\n",
      "| \u001b[0m 109     \u001b[0m | \u001b[0m 50.0    \u001b[0m | \u001b[0m 0.6786  \u001b[0m | \u001b[0m 0.9919  \u001b[0m | \u001b[0m 8.849   \u001b[0m | \u001b[0m 1.842   \u001b[0m | \u001b[0m 329.3   \u001b[0m | \u001b[0m 8.736   \u001b[0m | \u001b[0m 0.9596  \u001b[0m |\n",
      "| \u001b[0m 110     \u001b[0m | \u001b[0m 45.0    \u001b[0m | \u001b[0m 0.6213  \u001b[0m | \u001b[0m 0.46    \u001b[0m | \u001b[0m 7.301   \u001b[0m | \u001b[0m 1.401   \u001b[0m | \u001b[0m 410.1   \u001b[0m | \u001b[0m 7.03    \u001b[0m | \u001b[0m 0.9705  \u001b[0m |\n",
      "| \u001b[0m 111     \u001b[0m | \u001b[0m 155.0   \u001b[0m | \u001b[0m 0.6187  \u001b[0m | \u001b[0m 0.141   \u001b[0m | \u001b[0m 5.13    \u001b[0m | \u001b[0m 1.028   \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 2.417   \u001b[0m | \u001b[0m 0.9556  \u001b[0m |\n",
      "| \u001b[0m 112     \u001b[0m | \u001b[0m 80.0    \u001b[0m | \u001b[0m 0.7633  \u001b[0m | \u001b[0m 0.4238  \u001b[0m | \u001b[0m 6.799   \u001b[0m | \u001b[0m 1.575   \u001b[0m | \u001b[0m 410.7   \u001b[0m | \u001b[0m 7.125   \u001b[0m | \u001b[0m 0.905   \u001b[0m |\n",
      "| \u001b[0m 113     \u001b[0m | \u001b[0m 180.0   \u001b[0m | \u001b[0m 0.6625  \u001b[0m | \u001b[0m 0.4561  \u001b[0m | \u001b[0m 4.719   \u001b[0m | \u001b[0m 1.869   \u001b[0m | \u001b[0m 310.3   \u001b[0m | \u001b[0m 1.22    \u001b[0m | \u001b[0m 0.7593  \u001b[0m |\n",
      "| \u001b[0m 114     \u001b[0m | \u001b[0m 155.0   \u001b[0m | \u001b[0m 0.8883  \u001b[0m | \u001b[0m 0.3356  \u001b[0m | \u001b[0m 5.04    \u001b[0m | \u001b[0m 1.562   \u001b[0m | \u001b[0m 308.1   \u001b[0m | \u001b[0m 3.133   \u001b[0m | \u001b[0m 0.8361  \u001b[0m |\n",
      "| \u001b[0m 115     \u001b[0m | \u001b[0m 140.0   \u001b[0m | \u001b[0m 0.7498  \u001b[0m | \u001b[0m 0.4769  \u001b[0m | \u001b[0m 5.685   \u001b[0m | \u001b[0m 3.071   \u001b[0m | \u001b[0m 308.6   \u001b[0m | \u001b[0m 4.312   \u001b[0m | \u001b[0m 0.6783  \u001b[0m |\n",
      "| \u001b[0m 116     \u001b[0m | \u001b[0m 70.0    \u001b[0m | \u001b[0m 0.6391  \u001b[0m | \u001b[0m 0.6119  \u001b[0m | \u001b[0m 9.042   \u001b[0m | \u001b[0m 1.528   \u001b[0m | \u001b[0m 331.0   \u001b[0m | \u001b[0m 9.191   \u001b[0m | \u001b[0m 0.8759  \u001b[0m |\n",
      "| \u001b[0m 117     \u001b[0m | \u001b[0m 85.0    \u001b[0m | \u001b[0m 0.9532  \u001b[0m | \u001b[0m 0.1008  \u001b[0m | \u001b[0m 9.16    \u001b[0m | \u001b[0m 2.88    \u001b[0m | \u001b[0m 331.3   \u001b[0m | \u001b[0m 9.13    \u001b[0m | \u001b[0m 0.6373  \u001b[0m |\n",
      "| \u001b[0m 118     \u001b[0m | \u001b[0m 110.0   \u001b[0m | \u001b[0m 0.7776  \u001b[0m | \u001b[0m 0.2246  \u001b[0m | \u001b[0m 6.499   \u001b[0m | \u001b[0m 2.223   \u001b[0m | \u001b[0m 309.6   \u001b[0m | \u001b[0m 3.808   \u001b[0m | \u001b[0m 0.7816  \u001b[0m |\n",
      "| \u001b[0m 119     \u001b[0m | \u001b[0m 190.0   \u001b[0m | \u001b[0m 0.7476  \u001b[0m | \u001b[0m 0.3401  \u001b[0m | \u001b[0m 4.227   \u001b[0m | \u001b[0m 1.496   \u001b[0m | \u001b[0m 309.6   \u001b[0m | \u001b[0m 2.558   \u001b[0m | \u001b[0m 0.8972  \u001b[0m |\n",
      "| \u001b[0m 120     \u001b[0m | \u001b[0m 185.0   \u001b[0m | \u001b[0m 0.7653  \u001b[0m | \u001b[0m 0.8063  \u001b[0m | \u001b[0m 4.859   \u001b[0m | \u001b[0m 2.062   \u001b[0m | \u001b[0m 311.6   \u001b[0m | \u001b[0m 2.448   \u001b[0m | \u001b[0m 0.6637  \u001b[0m |\n",
      "| \u001b[0m 121     \u001b[0m | \u001b[0m 135.0   \u001b[0m | \u001b[0m 0.8895  \u001b[0m | \u001b[0m 0.5993  \u001b[0m | \u001b[0m 5.448   \u001b[0m | \u001b[0m 1.215   \u001b[0m | \u001b[0m 307.3   \u001b[0m | \u001b[0m 3.302   \u001b[0m | \u001b[0m 0.7198  \u001b[0m |\n",
      "| \u001b[0m 122     \u001b[0m | \u001b[0m 35.0    \u001b[0m | \u001b[0m 0.6299  \u001b[0m | \u001b[0m 0.556   \u001b[0m | \u001b[0m 8.854   \u001b[0m | \u001b[0m 1.931   \u001b[0m | \u001b[0m 331.0   \u001b[0m | \u001b[0m 9.298   \u001b[0m | \u001b[0m 0.785   \u001b[0m |\n",
      "| \u001b[0m 123     \u001b[0m | \u001b[0m 215.0   \u001b[0m | \u001b[0m 0.6524  \u001b[0m | \u001b[0m 0.3703  \u001b[0m | \u001b[0m 3.455   \u001b[0m | \u001b[0m 1.282   \u001b[0m | \u001b[0m 349.5   \u001b[0m | \u001b[0m 0.03657 \u001b[0m | \u001b[0m 0.8889  \u001b[0m |\n",
      "| \u001b[0m 124     \u001b[0m | \u001b[0m 20.0    \u001b[0m | \u001b[0m 0.6416  \u001b[0m | \u001b[0m 0.4779  \u001b[0m | \u001b[0m 9.414   \u001b[0m | \u001b[0m 1.933   \u001b[0m | \u001b[0m 331.2   \u001b[0m | \u001b[0m 8.089   \u001b[0m | \u001b[0m 0.7873  \u001b[0m |\n",
      "| \u001b[0m 125     \u001b[0m | \u001b[0m 105.0   \u001b[0m | \u001b[0m 0.7031  \u001b[0m | \u001b[0m 0.3754  \u001b[0m | \u001b[0m 7.336   \u001b[0m | \u001b[0m 2.391   \u001b[0m | \u001b[0m 178.2   \u001b[0m | \u001b[0m 3.627   \u001b[0m | \u001b[0m 0.9266  \u001b[0m |\n",
      "| \u001b[0m 126     \u001b[0m | \u001b[0m-110.0   \u001b[0m | \u001b[0m 0.6968  \u001b[0m | \u001b[0m 0.5209  \u001b[0m | \u001b[0m 5.659   \u001b[0m | \u001b[0m 4.416   \u001b[0m | \u001b[0m 403.3   \u001b[0m | \u001b[0m 19.83   \u001b[0m | \u001b[0m 0.637   \u001b[0m |\n",
      "| \u001b[0m 127     \u001b[0m | \u001b[0m-15.0    \u001b[0m | \u001b[0m 0.621   \u001b[0m | \u001b[0m 0.5237  \u001b[0m | \u001b[0m 8.512   \u001b[0m | \u001b[0m 1.043   \u001b[0m | \u001b[0m 102.8   \u001b[0m | \u001b[0m 4.799   \u001b[0m | \u001b[0m 0.8458  \u001b[0m |\n",
      "| \u001b[0m 128     \u001b[0m | \u001b[0m 175.0   \u001b[0m | \u001b[0m 0.9515  \u001b[0m | \u001b[0m 0.2332  \u001b[0m | \u001b[0m 5.571   \u001b[0m | \u001b[0m 1.611   \u001b[0m | \u001b[0m 309.8   \u001b[0m | \u001b[0m 1.906   \u001b[0m | \u001b[0m 0.7503  \u001b[0m |\n",
      "| \u001b[0m 129     \u001b[0m | \u001b[0m 95.0    \u001b[0m | \u001b[0m 0.7183  \u001b[0m | \u001b[0m 0.2347  \u001b[0m | \u001b[0m 6.469   \u001b[0m | \u001b[0m 2.42    \u001b[0m | \u001b[0m 309.5   \u001b[0m | \u001b[0m 4.501   \u001b[0m | \u001b[0m 0.7653  \u001b[0m |\n",
      "| \u001b[0m 130     \u001b[0m | \u001b[0m 60.0    \u001b[0m | \u001b[0m 0.6099  \u001b[0m | \u001b[0m 0.3438  \u001b[0m | \u001b[0m 9.265   \u001b[0m | \u001b[0m 2.809   \u001b[0m | \u001b[0m 331.3   \u001b[0m | \u001b[0m 9.564   \u001b[0m | \u001b[0m 0.8484  \u001b[0m |\n",
      "| \u001b[0m 131     \u001b[0m | \u001b[0m-190.0   \u001b[0m | \u001b[0m 0.7907  \u001b[0m | \u001b[0m 0.6657  \u001b[0m | \u001b[0m 7.862   \u001b[0m | \u001b[0m 6.693   \u001b[0m | \u001b[0m 411.5   \u001b[0m | \u001b[0m 18.77   \u001b[0m | \u001b[0m 0.6494  \u001b[0m |\n",
      "| \u001b[0m 132     \u001b[0m | \u001b[0m 145.0   \u001b[0m | \u001b[0m 0.8252  \u001b[0m | \u001b[0m 0.3403  \u001b[0m | \u001b[0m 4.876   \u001b[0m | \u001b[0m 2.276   \u001b[0m | \u001b[0m 308.2   \u001b[0m | \u001b[0m 2.979   \u001b[0m | \u001b[0m 0.811   \u001b[0m |\n",
      "| \u001b[0m 133     \u001b[0m | \u001b[0m 105.0   \u001b[0m | \u001b[0m 0.8771  \u001b[0m | \u001b[0m 0.5684  \u001b[0m | \u001b[0m 6.353   \u001b[0m | \u001b[0m 2.694   \u001b[0m | \u001b[0m 309.5   \u001b[0m | \u001b[0m 4.333   \u001b[0m | \u001b[0m 0.8319  \u001b[0m |\n",
      "| \u001b[0m 134     \u001b[0m | \u001b[0m 185.0   \u001b[0m | \u001b[0m 0.7314  \u001b[0m | \u001b[0m 0.137   \u001b[0m | \u001b[0m 5.12    \u001b[0m | \u001b[0m 2.664   \u001b[0m | \u001b[0m 307.8   \u001b[0m | \u001b[0m 3.027   \u001b[0m | \u001b[0m 0.6725  \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 135     \u001b[0m | \u001b[0m 145.0   \u001b[0m | \u001b[0m 0.7764  \u001b[0m | \u001b[0m 0.3223  \u001b[0m | \u001b[0m 6.079   \u001b[0m | \u001b[0m 1.907   \u001b[0m | \u001b[0m 310.5   \u001b[0m | \u001b[0m 3.051   \u001b[0m | \u001b[0m 0.7077  \u001b[0m |\n",
      "| \u001b[0m 136     \u001b[0m | \u001b[0m 185.0   \u001b[0m | \u001b[0m 0.7603  \u001b[0m | \u001b[0m 0.5984  \u001b[0m | \u001b[0m 5.047   \u001b[0m | \u001b[0m 2.824   \u001b[0m | \u001b[0m 308.0   \u001b[0m | \u001b[0m 2.715   \u001b[0m | \u001b[0m 0.6808  \u001b[0m |\n",
      "| \u001b[0m 137     \u001b[0m | \u001b[0m 160.0   \u001b[0m | \u001b[0m 0.987   \u001b[0m | \u001b[0m 0.167   \u001b[0m | \u001b[0m 6.088   \u001b[0m | \u001b[0m 2.699   \u001b[0m | \u001b[0m 308.4   \u001b[0m | \u001b[0m 3.897   \u001b[0m | \u001b[0m 0.6173  \u001b[0m |\n",
      "| \u001b[0m 138     \u001b[0m | \u001b[0m 105.0   \u001b[0m | \u001b[0m 0.7919  \u001b[0m | \u001b[0m 0.7134  \u001b[0m | \u001b[0m 4.591   \u001b[0m | \u001b[0m 1.247   \u001b[0m | \u001b[0m 307.6   \u001b[0m | \u001b[0m 3.775   \u001b[0m | \u001b[0m 0.7924  \u001b[0m |\n",
      "| \u001b[0m 139     \u001b[0m | \u001b[0m 100.0   \u001b[0m | \u001b[0m 0.8339  \u001b[0m | \u001b[0m 0.5315  \u001b[0m | \u001b[0m 6.04    \u001b[0m | \u001b[0m 1.239   \u001b[0m | \u001b[0m 311.2   \u001b[0m | \u001b[0m 3.935   \u001b[0m | \u001b[0m 0.7476  \u001b[0m |\n",
      "| \u001b[0m 140     \u001b[0m | \u001b[0m 90.0    \u001b[0m | \u001b[0m 0.6314  \u001b[0m | \u001b[0m 0.2532  \u001b[0m | \u001b[0m 6.746   \u001b[0m | \u001b[0m 1.454   \u001b[0m | \u001b[0m 410.9   \u001b[0m | \u001b[0m 7.513   \u001b[0m | \u001b[0m 0.9573  \u001b[0m |\n",
      "| \u001b[0m 141     \u001b[0m | \u001b[0m 40.0    \u001b[0m | \u001b[0m 0.8412  \u001b[0m | \u001b[0m 0.6673  \u001b[0m | \u001b[0m 3.964   \u001b[0m | \u001b[0m 5.093   \u001b[0m | \u001b[0m 247.2   \u001b[0m | \u001b[0m 12.06   \u001b[0m | \u001b[0m 0.9585  \u001b[0m |\n",
      "| \u001b[0m 142     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.8888  \u001b[0m | \u001b[0m 0.9745  \u001b[0m | \u001b[0m 3.412   \u001b[0m | \u001b[0m 4.543   \u001b[0m | \u001b[0m 247.6   \u001b[0m | \u001b[0m 12.83   \u001b[0m | \u001b[0m 0.847   \u001b[0m |\n",
      "| \u001b[0m 143     \u001b[0m | \u001b[0m 185.0   \u001b[0m | \u001b[0m 0.953   \u001b[0m | \u001b[0m 0.3401  \u001b[0m | \u001b[0m 5.722   \u001b[0m | \u001b[0m 1.756   \u001b[0m | \u001b[0m 310.8   \u001b[0m | \u001b[0m 2.204   \u001b[0m | \u001b[0m 0.7383  \u001b[0m |\n",
      "| \u001b[0m 144     \u001b[0m | \u001b[0m 115.0   \u001b[0m | \u001b[0m 0.6875  \u001b[0m | \u001b[0m 0.5314  \u001b[0m | \u001b[0m 6.744   \u001b[0m | \u001b[0m 3.054   \u001b[0m | \u001b[0m 178.4   \u001b[0m | \u001b[0m 3.786   \u001b[0m | \u001b[0m 0.8767  \u001b[0m |\n",
      "| \u001b[0m 145     \u001b[0m | \u001b[0m 145.0   \u001b[0m | \u001b[0m 0.6625  \u001b[0m | \u001b[0m 0.8846  \u001b[0m | \u001b[0m 5.409   \u001b[0m | \u001b[0m 1.786   \u001b[0m | \u001b[0m 311.1   \u001b[0m | \u001b[0m 2.769   \u001b[0m | \u001b[0m 0.6853  \u001b[0m |\n",
      "| \u001b[0m 146     \u001b[0m | \u001b[0m 90.0    \u001b[0m | \u001b[0m 0.916   \u001b[0m | \u001b[0m 0.8174  \u001b[0m | \u001b[0m 6.304   \u001b[0m | \u001b[0m 2.004   \u001b[0m | \u001b[0m 309.6   \u001b[0m | \u001b[0m 3.532   \u001b[0m | \u001b[0m 0.934   \u001b[0m |\n",
      "| \u001b[0m 147     \u001b[0m | \u001b[0m 105.0   \u001b[0m | \u001b[0m 0.8707  \u001b[0m | \u001b[0m 0.7075  \u001b[0m | \u001b[0m 6.087   \u001b[0m | \u001b[0m 2.279   \u001b[0m | \u001b[0m 310.5   \u001b[0m | \u001b[0m 3.444   \u001b[0m | \u001b[0m 0.8928  \u001b[0m |\n",
      "| \u001b[0m 148     \u001b[0m | \u001b[0m 135.0   \u001b[0m | \u001b[0m 0.6768  \u001b[0m | \u001b[0m 0.66    \u001b[0m | \u001b[0m 5.723   \u001b[0m | \u001b[0m 1.683   \u001b[0m | \u001b[0m 309.5   \u001b[0m | \u001b[0m 3.658   \u001b[0m | \u001b[0m 0.9079  \u001b[0m |\n",
      "| \u001b[0m 149     \u001b[0m | \u001b[0m 30.0    \u001b[0m | \u001b[0m 0.6514  \u001b[0m | \u001b[0m 0.1096  \u001b[0m | \u001b[0m 7.278   \u001b[0m | \u001b[0m 1.93    \u001b[0m | \u001b[0m 410.0   \u001b[0m | \u001b[0m 7.633   \u001b[0m | \u001b[0m 0.8394  \u001b[0m |\n",
      "| \u001b[0m 150     \u001b[0m | \u001b[0m 105.0   \u001b[0m | \u001b[0m 0.6265  \u001b[0m | \u001b[0m 0.4058  \u001b[0m | \u001b[0m 5.773   \u001b[0m | \u001b[0m 2.344   \u001b[0m | \u001b[0m 308.6   \u001b[0m | \u001b[0m 4.533   \u001b[0m | \u001b[0m 0.9009  \u001b[0m |\n",
      "| \u001b[0m 151     \u001b[0m | \u001b[0m 120.0   \u001b[0m | \u001b[0m 0.8589  \u001b[0m | \u001b[0m 0.405   \u001b[0m | \u001b[0m 5.729   \u001b[0m | \u001b[0m 1.731   \u001b[0m | \u001b[0m 307.9   \u001b[0m | \u001b[0m 3.749   \u001b[0m | \u001b[0m 0.8154  \u001b[0m |\n",
      "| \u001b[0m 152     \u001b[0m | \u001b[0m 70.0    \u001b[0m | \u001b[0m 0.9051  \u001b[0m | \u001b[0m 0.07682 \u001b[0m | \u001b[0m 8.673   \u001b[0m | \u001b[0m 2.434   \u001b[0m | \u001b[0m 331.2   \u001b[0m | \u001b[0m 9.126   \u001b[0m | \u001b[0m 0.6932  \u001b[0m |\n",
      "| \u001b[0m 153     \u001b[0m | \u001b[0m 115.0   \u001b[0m | \u001b[0m 0.7008  \u001b[0m | \u001b[0m 0.2665  \u001b[0m | \u001b[0m 6.466   \u001b[0m | \u001b[0m 2.762   \u001b[0m | \u001b[0m 178.0   \u001b[0m | \u001b[0m 3.88    \u001b[0m | \u001b[0m 0.6691  \u001b[0m |\n",
      "| \u001b[0m 154     \u001b[0m | \u001b[0m 205.0   \u001b[0m | \u001b[0m 0.9354  \u001b[0m | \u001b[0m 0.7083  \u001b[0m | \u001b[0m 6.196   \u001b[0m | \u001b[0m 1.648   \u001b[0m | \u001b[0m 309.6   \u001b[0m | \u001b[0m 3.141   \u001b[0m | \u001b[0m 0.6057  \u001b[0m |\n",
      "| \u001b[0m 155     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 0.7949  \u001b[0m | \u001b[0m 0.5039  \u001b[0m | \u001b[0m 8.669   \u001b[0m | \u001b[0m 2.221   \u001b[0m | \u001b[0m 330.3   \u001b[0m | \u001b[0m 9.212   \u001b[0m | \u001b[0m 0.6355  \u001b[0m |\n",
      "| \u001b[0m 156     \u001b[0m | \u001b[0m 165.0   \u001b[0m | \u001b[0m 0.6109  \u001b[0m | \u001b[0m 0.4047  \u001b[0m | \u001b[0m 4.992   \u001b[0m | \u001b[0m 1.377   \u001b[0m | \u001b[0m 308.4   \u001b[0m | \u001b[0m 3.467   \u001b[0m | \u001b[0m 0.9864  \u001b[0m |\n",
      "| \u001b[0m 157     \u001b[0m | \u001b[0m 55.0    \u001b[0m | \u001b[0m 0.7306  \u001b[0m | \u001b[0m 0.3095  \u001b[0m | \u001b[0m 3.626   \u001b[0m | \u001b[0m 5.012   \u001b[0m | \u001b[0m 248.2   \u001b[0m | \u001b[0m 12.15   \u001b[0m | \u001b[0m 0.8921  \u001b[0m |\n",
      "| \u001b[0m 158     \u001b[0m | \u001b[0m 185.0   \u001b[0m | \u001b[0m 0.6381  \u001b[0m | \u001b[0m 0.3264  \u001b[0m | \u001b[0m 4.676   \u001b[0m | \u001b[0m 1.723   \u001b[0m | \u001b[0m 309.9   \u001b[0m | \u001b[0m 1.709   \u001b[0m | \u001b[0m 0.7278  \u001b[0m |\n",
      "| \u001b[0m 159     \u001b[0m | \u001b[0m 170.0   \u001b[0m | \u001b[0m 0.6221  \u001b[0m | \u001b[0m 0.1164  \u001b[0m | \u001b[0m 6.23    \u001b[0m | \u001b[0m 2.434   \u001b[0m | \u001b[0m 308.1   \u001b[0m | \u001b[0m 3.924   \u001b[0m | \u001b[0m 0.6296  \u001b[0m |\n",
      "| \u001b[0m 160     \u001b[0m | \u001b[0m 115.0   \u001b[0m | \u001b[0m 0.7765  \u001b[0m | \u001b[0m 0.4131  \u001b[0m | \u001b[0m 5.444   \u001b[0m | \u001b[0m 1.399   \u001b[0m | \u001b[0m 308.3   \u001b[0m | \u001b[0m 3.439   \u001b[0m | \u001b[0m 0.9194  \u001b[0m |\n",
      "| \u001b[0m 161     \u001b[0m | \u001b[0m 125.0   \u001b[0m | \u001b[0m 0.6777  \u001b[0m | \u001b[0m 0.7382  \u001b[0m | \u001b[0m 4.889   \u001b[0m | \u001b[0m 2.27    \u001b[0m | \u001b[0m 311.8   \u001b[0m | \u001b[0m 1.94    \u001b[0m | \u001b[0m 0.6025  \u001b[0m |\n",
      "| \u001b[0m 162     \u001b[0m | \u001b[0m 120.0   \u001b[0m | \u001b[0m 0.7866  \u001b[0m | \u001b[0m 0.7976  \u001b[0m | \u001b[0m 5.816   \u001b[0m | \u001b[0m 1.51    \u001b[0m | \u001b[0m 307.8   \u001b[0m | \u001b[0m 3.509   \u001b[0m | \u001b[0m 0.6253  \u001b[0m |\n",
      "| \u001b[0m 163     \u001b[0m | \u001b[0m 170.0   \u001b[0m | \u001b[0m 0.8776  \u001b[0m | \u001b[0m 0.3521  \u001b[0m | \u001b[0m 5.209   \u001b[0m | \u001b[0m 2.6     \u001b[0m | \u001b[0m 307.8   \u001b[0m | \u001b[0m 3.293   \u001b[0m | \u001b[0m 0.8173  \u001b[0m |\n",
      "| \u001b[0m 164     \u001b[0m | \u001b[0m 100.0   \u001b[0m | \u001b[0m 0.8162  \u001b[0m | \u001b[0m 0.9416  \u001b[0m | \u001b[0m 4.642   \u001b[0m | \u001b[0m 1.557   \u001b[0m | \u001b[0m 311.1   \u001b[0m | \u001b[0m 2.597   \u001b[0m | \u001b[0m 0.9242  \u001b[0m |\n",
      "| \u001b[0m 165     \u001b[0m | \u001b[0m 125.0   \u001b[0m | \u001b[0m 0.8026  \u001b[0m | \u001b[0m 0.2594  \u001b[0m | \u001b[0m 5.714   \u001b[0m | \u001b[0m 1.586   \u001b[0m | \u001b[0m 307.6   \u001b[0m | \u001b[0m 4.549   \u001b[0m | \u001b[0m 0.6702  \u001b[0m |\n",
      "| \u001b[0m 166     \u001b[0m | \u001b[0m 35.0    \u001b[0m | \u001b[0m 0.7771  \u001b[0m | \u001b[0m 0.2198  \u001b[0m | \u001b[0m 4.466   \u001b[0m | \u001b[0m 4.641   \u001b[0m | \u001b[0m 247.5   \u001b[0m | \u001b[0m 12.6    \u001b[0m | \u001b[0m 0.7242  \u001b[0m |\n",
      "| \u001b[0m 167     \u001b[0m | \u001b[0m 75.0    \u001b[0m | \u001b[0m 0.7416  \u001b[0m | \u001b[0m 0.7214  \u001b[0m | \u001b[0m 6.8     \u001b[0m | \u001b[0m 3.247   \u001b[0m | \u001b[0m 178.1   \u001b[0m | \u001b[0m 4.038   \u001b[0m | \u001b[0m 0.9857  \u001b[0m |\n",
      "| \u001b[0m 168     \u001b[0m | \u001b[0m 105.0   \u001b[0m | \u001b[0m 0.902   \u001b[0m | \u001b[0m 0.1372  \u001b[0m | \u001b[0m 7.338   \u001b[0m | \u001b[0m 2.615   \u001b[0m | \u001b[0m 309.7   \u001b[0m | \u001b[0m 4.537   \u001b[0m | \u001b[0m 0.8837  \u001b[0m |\n",
      "| \u001b[0m 169     \u001b[0m | \u001b[0m 140.0   \u001b[0m | \u001b[0m 0.9212  \u001b[0m | \u001b[0m 0.3715  \u001b[0m | \u001b[0m 6.903   \u001b[0m | \u001b[0m 3.762   \u001b[0m | \u001b[0m 178.6   \u001b[0m | \u001b[0m 3.881   \u001b[0m | \u001b[0m 0.7697  \u001b[0m |\n",
      "| \u001b[0m 170     \u001b[0m | \u001b[0m 55.0    \u001b[0m | \u001b[0m 0.9208  \u001b[0m | \u001b[0m 0.5555  \u001b[0m | \u001b[0m 9.33    \u001b[0m | \u001b[0m 5.298   \u001b[0m | \u001b[0m 305.8   \u001b[0m | \u001b[0m 8.935   \u001b[0m | \u001b[0m 0.8167  \u001b[0m |\n",
      "| \u001b[0m 171     \u001b[0m | \u001b[0m 55.0    \u001b[0m | \u001b[0m 0.8881  \u001b[0m | \u001b[0m 0.5286  \u001b[0m | \u001b[0m 9.032   \u001b[0m | \u001b[0m 1.929   \u001b[0m | \u001b[0m 331.5   \u001b[0m | \u001b[0m 8.316   \u001b[0m | \u001b[0m 0.6892  \u001b[0m |\n",
      "| \u001b[0m 172     \u001b[0m | \u001b[0m 30.0    \u001b[0m | \u001b[0m 0.7976  \u001b[0m | \u001b[0m 0.428   \u001b[0m | \u001b[0m 7.253   \u001b[0m | \u001b[0m 1.185   \u001b[0m | \u001b[0m 409.9   \u001b[0m | \u001b[0m 7.274   \u001b[0m | \u001b[0m 0.8573  \u001b[0m |\n",
      "| \u001b[0m 173     \u001b[0m | \u001b[0m 80.0    \u001b[0m | \u001b[0m 0.7302  \u001b[0m | \u001b[0m 0.3167  \u001b[0m | \u001b[0m 7.263   \u001b[0m | \u001b[0m 1.183   \u001b[0m | \u001b[0m 409.9   \u001b[0m | \u001b[0m 7.387   \u001b[0m | \u001b[0m 0.6092  \u001b[0m |\n",
      "| \u001b[0m 174     \u001b[0m | \u001b[0m 120.0   \u001b[0m | \u001b[0m 0.6696  \u001b[0m | \u001b[0m 0.8034  \u001b[0m | \u001b[0m 6.346   \u001b[0m | \u001b[0m 3.115   \u001b[0m | \u001b[0m 309.4   \u001b[0m | \u001b[0m 4.685   \u001b[0m | \u001b[0m 0.6715  \u001b[0m |\n",
      "| \u001b[0m 175     \u001b[0m | \u001b[0m 105.0   \u001b[0m | \u001b[0m 0.8426  \u001b[0m | \u001b[0m 0.8558  \u001b[0m | \u001b[0m 9.408   \u001b[0m | \u001b[0m 2.411   \u001b[0m | \u001b[0m 330.7   \u001b[0m | \u001b[0m 8.237   \u001b[0m | \u001b[0m 0.7227  \u001b[0m |\n",
      "| \u001b[0m 176     \u001b[0m | \u001b[0m 60.0    \u001b[0m | \u001b[0m 0.8361  \u001b[0m | \u001b[0m 0.4204  \u001b[0m | \u001b[0m 6.426   \u001b[0m | \u001b[0m 3.363   \u001b[0m | \u001b[0m 309.3   \u001b[0m | \u001b[0m 4.719   \u001b[0m | \u001b[0m 0.8634  \u001b[0m |\n",
      "| \u001b[0m 177     \u001b[0m | \u001b[0m 150.0   \u001b[0m | \u001b[0m 0.6975  \u001b[0m | \u001b[0m 0.5137  \u001b[0m | \u001b[0m 5.373   \u001b[0m | \u001b[0m 1.456   \u001b[0m | \u001b[0m 310.7   \u001b[0m | \u001b[0m 3.056   \u001b[0m | \u001b[0m 0.6696  \u001b[0m |\n",
      "| \u001b[0m 178     \u001b[0m | \u001b[0m 90.0    \u001b[0m | \u001b[0m 0.7439  \u001b[0m | \u001b[0m 0.9281  \u001b[0m | \u001b[0m 5.424   \u001b[0m | \u001b[0m 1.549   \u001b[0m | \u001b[0m 310.9   \u001b[0m | \u001b[0m 3.546   \u001b[0m | \u001b[0m 0.7587  \u001b[0m |\n",
      "| \u001b[0m 179     \u001b[0m | \u001b[0m 110.0   \u001b[0m | \u001b[0m 0.9434  \u001b[0m | \u001b[0m 0.6234  \u001b[0m | \u001b[0m 5.768   \u001b[0m | \u001b[0m 2.342   \u001b[0m | \u001b[0m 309.6   \u001b[0m | \u001b[0m 3.766   \u001b[0m | \u001b[0m 0.9363  \u001b[0m |\n",
      "| \u001b[0m 180     \u001b[0m | \u001b[0m 110.0   \u001b[0m | \u001b[0m 0.7577  \u001b[0m | \u001b[0m 0.8185  \u001b[0m | \u001b[0m 5.516   \u001b[0m | \u001b[0m 2.037   \u001b[0m | \u001b[0m 309.0   \u001b[0m | \u001b[0m 3.824   \u001b[0m | \u001b[0m 0.6659  \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 181     \u001b[0m | \u001b[0m 195.0   \u001b[0m | \u001b[0m 0.981   \u001b[0m | \u001b[0m 0.6171  \u001b[0m | \u001b[0m 3.425   \u001b[0m | \u001b[0m 1.313   \u001b[0m | \u001b[0m 348.5   \u001b[0m | \u001b[0m 0.2262  \u001b[0m | \u001b[0m 0.6899  \u001b[0m |\n",
      "| \u001b[0m 182     \u001b[0m | \u001b[0m 120.0   \u001b[0m | \u001b[0m 0.784   \u001b[0m | \u001b[0m 0.1646  \u001b[0m | \u001b[0m 4.352   \u001b[0m | \u001b[0m 2.026   \u001b[0m | \u001b[0m 308.2   \u001b[0m | \u001b[0m 3.033   \u001b[0m | \u001b[0m 0.853   \u001b[0m |\n",
      "| \u001b[0m 183     \u001b[0m | \u001b[0m 160.0   \u001b[0m | \u001b[0m 0.9453  \u001b[0m | \u001b[0m 0.1447  \u001b[0m | \u001b[0m 5.113   \u001b[0m | \u001b[0m 2.174   \u001b[0m | \u001b[0m 308.3   \u001b[0m | \u001b[0m 2.996   \u001b[0m | \u001b[0m 0.7827  \u001b[0m |\n",
      "| \u001b[0m 184     \u001b[0m | \u001b[0m 85.0    \u001b[0m | \u001b[0m 0.6544  \u001b[0m | \u001b[0m 0.4095  \u001b[0m | \u001b[0m 5.977   \u001b[0m | \u001b[0m 2.512   \u001b[0m | \u001b[0m 309.7   \u001b[0m | \u001b[0m 4.166   \u001b[0m | \u001b[0m 0.9882  \u001b[0m |\n",
      "| \u001b[0m 185     \u001b[0m | \u001b[0m 45.0    \u001b[0m | \u001b[0m 0.7856  \u001b[0m | \u001b[0m 0.3149  \u001b[0m | \u001b[0m 8.884   \u001b[0m | \u001b[0m 2.497   \u001b[0m | \u001b[0m 330.5   \u001b[0m | \u001b[0m 9.278   \u001b[0m | \u001b[0m 0.89    \u001b[0m |\n",
      "| \u001b[0m 186     \u001b[0m | \u001b[0m 120.0   \u001b[0m | \u001b[0m 0.9978  \u001b[0m | \u001b[0m 0.8345  \u001b[0m | \u001b[0m 4.672   \u001b[0m | \u001b[0m 2.575   \u001b[0m | \u001b[0m 307.9   \u001b[0m | \u001b[0m 2.441   \u001b[0m | \u001b[0m 0.8585  \u001b[0m |\n",
      "| \u001b[0m 187     \u001b[0m | \u001b[0m-65.0    \u001b[0m | \u001b[0m 0.8668  \u001b[0m | \u001b[0m 0.5888  \u001b[0m | \u001b[0m 3.481   \u001b[0m | \u001b[0m 4.575   \u001b[0m | \u001b[0m 247.8   \u001b[0m | \u001b[0m 13.25   \u001b[0m | \u001b[0m 0.664   \u001b[0m |\n",
      "| \u001b[0m 188     \u001b[0m | \u001b[0m 65.0    \u001b[0m | \u001b[0m 0.6208  \u001b[0m | \u001b[0m 0.4166  \u001b[0m | \u001b[0m 5.977   \u001b[0m | \u001b[0m 1.658   \u001b[0m | \u001b[0m 307.5   \u001b[0m | \u001b[0m 4.397   \u001b[0m | \u001b[0m 0.731   \u001b[0m |\n",
      "| \u001b[0m 189     \u001b[0m | \u001b[0m 60.0    \u001b[0m | \u001b[0m 0.9242  \u001b[0m | \u001b[0m 0.2185  \u001b[0m | \u001b[0m 4.08    \u001b[0m | \u001b[0m 5.15    \u001b[0m | \u001b[0m 248.4   \u001b[0m | \u001b[0m 11.53   \u001b[0m | \u001b[0m 0.9893  \u001b[0m |\n",
      "| \u001b[0m 190     \u001b[0m | \u001b[0m-105.0   \u001b[0m | \u001b[0m 0.7873  \u001b[0m | \u001b[0m 0.4368  \u001b[0m | \u001b[0m 3.828   \u001b[0m | \u001b[0m 5.517   \u001b[0m | \u001b[0m 247.7   \u001b[0m | \u001b[0m 12.17   \u001b[0m | \u001b[0m 0.6041  \u001b[0m |\n",
      "| \u001b[0m 191     \u001b[0m | \u001b[0m 160.0   \u001b[0m | \u001b[0m 0.639   \u001b[0m | \u001b[0m 0.5845  \u001b[0m | \u001b[0m 5.046   \u001b[0m | \u001b[0m 2.06    \u001b[0m | \u001b[0m 309.8   \u001b[0m | \u001b[0m 2.017   \u001b[0m | \u001b[0m 0.854   \u001b[0m |\n",
      "| \u001b[0m 192     \u001b[0m | \u001b[0m 140.0   \u001b[0m | \u001b[0m 0.981   \u001b[0m | \u001b[0m 0.1317  \u001b[0m | \u001b[0m 6.033   \u001b[0m | \u001b[0m 2.068   \u001b[0m | \u001b[0m 309.5   \u001b[0m | \u001b[0m 4.051   \u001b[0m | \u001b[0m 0.9135  \u001b[0m |\n",
      "| \u001b[0m 193     \u001b[0m | \u001b[0m 95.0    \u001b[0m | \u001b[0m 0.8286  \u001b[0m | \u001b[0m 0.5043  \u001b[0m | \u001b[0m 6.096   \u001b[0m | \u001b[0m 1.975   \u001b[0m | \u001b[0m 307.9   \u001b[0m | \u001b[0m 4.03    \u001b[0m | \u001b[0m 0.9276  \u001b[0m |\n",
      "| \u001b[0m 194     \u001b[0m | \u001b[0m 170.0   \u001b[0m | \u001b[0m 0.7523  \u001b[0m | \u001b[0m 0.003779\u001b[0m | \u001b[0m 6.108   \u001b[0m | \u001b[0m 2.244   \u001b[0m | \u001b[0m 309.2   \u001b[0m | \u001b[0m 4.383   \u001b[0m | \u001b[0m 0.8098  \u001b[0m |\n",
      "| \u001b[0m 195     \u001b[0m | \u001b[0m 100.0   \u001b[0m | \u001b[0m 0.7454  \u001b[0m | \u001b[0m 0.3974  \u001b[0m | \u001b[0m 6.054   \u001b[0m | \u001b[0m 1.466   \u001b[0m | \u001b[0m 310.3   \u001b[0m | \u001b[0m 4.108   \u001b[0m | \u001b[0m 0.7341  \u001b[0m |\n",
      "| \u001b[0m 196     \u001b[0m | \u001b[0m 110.0   \u001b[0m | \u001b[0m 0.8657  \u001b[0m | \u001b[0m 0.01882 \u001b[0m | \u001b[0m 5.193   \u001b[0m | \u001b[0m 2.514   \u001b[0m | \u001b[0m 307.5   \u001b[0m | \u001b[0m 3.741   \u001b[0m | \u001b[0m 0.8516  \u001b[0m |\n",
      "| \u001b[0m 197     \u001b[0m | \u001b[0m 80.0    \u001b[0m | \u001b[0m 0.6515  \u001b[0m | \u001b[0m 0.1571  \u001b[0m | \u001b[0m 7.242   \u001b[0m | \u001b[0m 1.634   \u001b[0m | \u001b[0m 410.4   \u001b[0m | \u001b[0m 7.554   \u001b[0m | \u001b[0m 0.6892  \u001b[0m |\n",
      "| \u001b[0m 198     \u001b[0m | \u001b[0m 50.0    \u001b[0m | \u001b[0m 0.7588  \u001b[0m | \u001b[0m 0.3355  \u001b[0m | \u001b[0m 8.846   \u001b[0m | \u001b[0m 3.01    \u001b[0m | \u001b[0m 331.2   \u001b[0m | \u001b[0m 9.715   \u001b[0m | \u001b[0m 0.7883  \u001b[0m |\n",
      "| \u001b[0m 199     \u001b[0m | \u001b[0m 75.0    \u001b[0m | \u001b[0m 0.9385  \u001b[0m | \u001b[0m 0.8103  \u001b[0m | \u001b[0m 5.989   \u001b[0m | \u001b[0m 1.869   \u001b[0m | \u001b[0m 312.1   \u001b[0m | \u001b[0m 3.974   \u001b[0m | \u001b[0m 0.7028  \u001b[0m |\n",
      "| \u001b[0m 200     \u001b[0m | \u001b[0m 85.0    \u001b[0m | \u001b[0m 0.9546  \u001b[0m | \u001b[0m 0.2379  \u001b[0m | \u001b[0m 9.004   \u001b[0m | \u001b[0m 3.27    \u001b[0m | \u001b[0m 331.5   \u001b[0m | \u001b[0m 9.553   \u001b[0m | \u001b[0m 0.7074  \u001b[0m |\n",
      "| \u001b[0m 201     \u001b[0m | \u001b[0m 70.0    \u001b[0m | \u001b[0m 0.8343  \u001b[0m | \u001b[0m 0.5088  \u001b[0m | \u001b[0m 6.445   \u001b[0m | \u001b[0m 3.918   \u001b[0m | \u001b[0m 179.1   \u001b[0m | \u001b[0m 3.986   \u001b[0m | \u001b[0m 0.9183  \u001b[0m |\n",
      "| \u001b[0m 202     \u001b[0m | \u001b[0m 80.0    \u001b[0m | \u001b[0m 0.8547  \u001b[0m | \u001b[0m 0.6445  \u001b[0m | \u001b[0m 5.777   \u001b[0m | \u001b[0m 2.326   \u001b[0m | \u001b[0m 308.3   \u001b[0m | \u001b[0m 4.681   \u001b[0m | \u001b[0m 0.7135  \u001b[0m |\n",
      "| \u001b[0m 203     \u001b[0m | \u001b[0m 50.0    \u001b[0m | \u001b[0m 0.8064  \u001b[0m | \u001b[0m 0.5948  \u001b[0m | \u001b[0m 5.26    \u001b[0m | \u001b[0m 1.934   \u001b[0m | \u001b[0m 307.5   \u001b[0m | \u001b[0m 4.671   \u001b[0m | \u001b[0m 0.9151  \u001b[0m |\n",
      "| \u001b[0m 204     \u001b[0m | \u001b[0m 85.0    \u001b[0m | \u001b[0m 0.8299  \u001b[0m | \u001b[0m 0.5385  \u001b[0m | \u001b[0m 5.703   \u001b[0m | \u001b[0m 2.73    \u001b[0m | \u001b[0m 309.4   \u001b[0m | \u001b[0m 4.469   \u001b[0m | \u001b[0m 0.7984  \u001b[0m |\n",
      "| \u001b[0m 205     \u001b[0m | \u001b[0m 190.0   \u001b[0m | \u001b[0m 0.7442  \u001b[0m | \u001b[0m 0.3874  \u001b[0m | \u001b[0m 5.509   \u001b[0m | \u001b[0m 1.893   \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 1.958   \u001b[0m | \u001b[0m 0.7528  \u001b[0m |\n",
      "| \u001b[0m 206     \u001b[0m | \u001b[0m 80.0    \u001b[0m | \u001b[0m 0.7434  \u001b[0m | \u001b[0m 0.8472  \u001b[0m | \u001b[0m 9.286   \u001b[0m | \u001b[0m 1.619   \u001b[0m | \u001b[0m 331.5   \u001b[0m | \u001b[0m 8.046   \u001b[0m | \u001b[0m 0.8392  \u001b[0m |\n",
      "| \u001b[0m 207     \u001b[0m | \u001b[0m 110.0   \u001b[0m | \u001b[0m 0.7596  \u001b[0m | \u001b[0m 0.05823 \u001b[0m | \u001b[0m 6.202   \u001b[0m | \u001b[0m 2.021   \u001b[0m | \u001b[0m 309.3   \u001b[0m | \u001b[0m 4.831   \u001b[0m | \u001b[0m 0.991   \u001b[0m |\n",
      "| \u001b[0m 208     \u001b[0m | \u001b[0m 50.0    \u001b[0m | \u001b[0m 0.7142  \u001b[0m | \u001b[0m 0.6071  \u001b[0m | \u001b[0m 6.9     \u001b[0m | \u001b[0m 3.24    \u001b[0m | \u001b[0m 309.2   \u001b[0m | \u001b[0m 4.772   \u001b[0m | \u001b[0m 0.7696  \u001b[0m |\n",
      "| \u001b[0m 209     \u001b[0m | \u001b[0m 180.0   \u001b[0m | \u001b[0m 0.7922  \u001b[0m | \u001b[0m 0.248   \u001b[0m | \u001b[0m 5.886   \u001b[0m | \u001b[0m 1.866   \u001b[0m | \u001b[0m 310.1   \u001b[0m | \u001b[0m 2.534   \u001b[0m | \u001b[0m 0.6308  \u001b[0m |\n",
      "| \u001b[0m 210     \u001b[0m | \u001b[0m 70.0    \u001b[0m | \u001b[0m 0.969   \u001b[0m | \u001b[0m 0.1562  \u001b[0m | \u001b[0m 8.928   \u001b[0m | \u001b[0m 1.232   \u001b[0m | \u001b[0m 331.2   \u001b[0m | \u001b[0m 9.131   \u001b[0m | \u001b[0m 0.8668  \u001b[0m |\n",
      "| \u001b[0m 211     \u001b[0m | \u001b[0m 170.0   \u001b[0m | \u001b[0m 0.8434  \u001b[0m | \u001b[0m 0.8161  \u001b[0m | \u001b[0m 5.034   \u001b[0m | \u001b[0m 2.703   \u001b[0m | \u001b[0m 312.1   \u001b[0m | \u001b[0m 1.894   \u001b[0m | \u001b[0m 0.9007  \u001b[0m |\n",
      "| \u001b[0m 212     \u001b[0m | \u001b[0m 150.0   \u001b[0m | \u001b[0m 0.6426  \u001b[0m | \u001b[0m 0.5556  \u001b[0m | \u001b[0m 7.467   \u001b[0m | \u001b[0m 2.596   \u001b[0m | \u001b[0m 178.3   \u001b[0m | \u001b[0m 3.275   \u001b[0m | \u001b[0m 0.9909  \u001b[0m |\n",
      "| \u001b[0m 213     \u001b[0m | \u001b[0m 120.0   \u001b[0m | \u001b[0m 0.8376  \u001b[0m | \u001b[0m 0.0579  \u001b[0m | \u001b[0m 6.662   \u001b[0m | \u001b[0m 3.559   \u001b[0m | \u001b[0m 178.8   \u001b[0m | \u001b[0m 3.721   \u001b[0m | \u001b[0m 0.6867  \u001b[0m |\n",
      "| \u001b[0m 214     \u001b[0m | \u001b[0m 50.0    \u001b[0m | \u001b[0m 0.6236  \u001b[0m | \u001b[0m 0.4239  \u001b[0m | \u001b[0m 8.989   \u001b[0m | \u001b[0m 1.832   \u001b[0m | \u001b[0m 331.4   \u001b[0m | \u001b[0m 9.114   \u001b[0m | \u001b[0m 0.9631  \u001b[0m |\n",
      "| \u001b[0m 215     \u001b[0m | \u001b[0m 160.0   \u001b[0m | \u001b[0m 0.6121  \u001b[0m | \u001b[0m 0.4907  \u001b[0m | \u001b[0m 4.118   \u001b[0m | \u001b[0m 1.507   \u001b[0m | \u001b[0m 309.9   \u001b[0m | \u001b[0m 2.88    \u001b[0m | \u001b[0m 0.6084  \u001b[0m |\n",
      "| \u001b[0m 216     \u001b[0m | \u001b[0m-30.0    \u001b[0m | \u001b[0m 0.7183  \u001b[0m | \u001b[0m 0.9398  \u001b[0m | \u001b[0m 3.682   \u001b[0m | \u001b[0m 4.261   \u001b[0m | \u001b[0m 248.1   \u001b[0m | \u001b[0m 12.65   \u001b[0m | \u001b[0m 0.9206  \u001b[0m |\n",
      "| \u001b[0m 217     \u001b[0m | \u001b[0m 165.0   \u001b[0m | \u001b[0m 0.9595  \u001b[0m | \u001b[0m 0.9514  \u001b[0m | \u001b[0m 4.198   \u001b[0m | \u001b[0m 1.846   \u001b[0m | \u001b[0m 309.7   \u001b[0m | \u001b[0m 2.508   \u001b[0m | \u001b[0m 0.8697  \u001b[0m |\n",
      "| \u001b[0m 218     \u001b[0m | \u001b[0m 90.0    \u001b[0m | \u001b[0m 0.6984  \u001b[0m | \u001b[0m 0.3769  \u001b[0m | \u001b[0m 5.884   \u001b[0m | \u001b[0m 1.141   \u001b[0m | \u001b[0m 309.8   \u001b[0m | \u001b[0m 4.026   \u001b[0m | \u001b[0m 0.9387  \u001b[0m |\n",
      "| \u001b[0m 219     \u001b[0m | \u001b[0m 185.0   \u001b[0m | \u001b[0m 0.9498  \u001b[0m | \u001b[0m 0.7259  \u001b[0m | \u001b[0m 5.565   \u001b[0m | \u001b[0m 1.992   \u001b[0m | \u001b[0m 309.9   \u001b[0m | \u001b[0m 1.594   \u001b[0m | \u001b[0m 0.8386  \u001b[0m |\n",
      "| \u001b[0m 220     \u001b[0m | \u001b[0m 115.0   \u001b[0m | \u001b[0m 0.824   \u001b[0m | \u001b[0m 0.7046  \u001b[0m | \u001b[0m 5.415   \u001b[0m | \u001b[0m 1.949   \u001b[0m | \u001b[0m 311.6   \u001b[0m | \u001b[0m 2.772   \u001b[0m | \u001b[0m 0.9635  \u001b[0m |\n",
      "| \u001b[0m 221     \u001b[0m | \u001b[0m 150.0   \u001b[0m | \u001b[0m 0.7649  \u001b[0m | \u001b[0m 0.6283  \u001b[0m | \u001b[0m 4.93    \u001b[0m | \u001b[0m 2.781   \u001b[0m | \u001b[0m 307.7   \u001b[0m | \u001b[0m 2.57    \u001b[0m | \u001b[0m 0.6394  \u001b[0m |\n",
      "| \u001b[0m 222     \u001b[0m | \u001b[0m 175.0   \u001b[0m | \u001b[0m 0.9698  \u001b[0m | \u001b[0m 0.06714 \u001b[0m | \u001b[0m 5.05    \u001b[0m | \u001b[0m 1.219   \u001b[0m | \u001b[0m 308.2   \u001b[0m | \u001b[0m 3.221   \u001b[0m | \u001b[0m 0.6815  \u001b[0m |\n",
      "| \u001b[0m 223     \u001b[0m | \u001b[0m 45.0    \u001b[0m | \u001b[0m 0.7494  \u001b[0m | \u001b[0m 0.6526  \u001b[0m | \u001b[0m 8.866   \u001b[0m | \u001b[0m 2.415   \u001b[0m | \u001b[0m 331.3   \u001b[0m | \u001b[0m 9.432   \u001b[0m | \u001b[0m 0.8165  \u001b[0m |\n",
      "| \u001b[0m 224     \u001b[0m | \u001b[0m-25.0    \u001b[0m | \u001b[0m 0.9265  \u001b[0m | \u001b[0m 0.1571  \u001b[0m | \u001b[0m 4.226   \u001b[0m | \u001b[0m 4.729   \u001b[0m | \u001b[0m 247.2   \u001b[0m | \u001b[0m 12.85   \u001b[0m | \u001b[0m 0.6557  \u001b[0m |\n",
      "| \u001b[0m 225     \u001b[0m | \u001b[0m 205.0   \u001b[0m | \u001b[0m 0.6918  \u001b[0m | \u001b[0m 0.8257  \u001b[0m | \u001b[0m 5.452   \u001b[0m | \u001b[0m 1.919   \u001b[0m | \u001b[0m 311.9   \u001b[0m | \u001b[0m 2.443   \u001b[0m | \u001b[0m 0.6813  \u001b[0m |\n",
      "| \u001b[0m 226     \u001b[0m | \u001b[0m 145.0   \u001b[0m | \u001b[0m 0.6704  \u001b[0m | \u001b[0m 0.2961  \u001b[0m | \u001b[0m 6.475   \u001b[0m | \u001b[0m 2.908   \u001b[0m | \u001b[0m 307.8   \u001b[0m | \u001b[0m 3.911   \u001b[0m | \u001b[0m 0.8902  \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 227     \u001b[0m | \u001b[0m-90.0    \u001b[0m | \u001b[0m 0.9913  \u001b[0m | \u001b[0m 0.4703  \u001b[0m | \u001b[0m 4.395   \u001b[0m | \u001b[0m 4.816   \u001b[0m | \u001b[0m 247.9   \u001b[0m | \u001b[0m 13.07   \u001b[0m | \u001b[0m 0.6961  \u001b[0m |\n",
      "| \u001b[0m 228     \u001b[0m | \u001b[0m 155.0   \u001b[0m | \u001b[0m 0.8123  \u001b[0m | \u001b[0m 0.07254 \u001b[0m | \u001b[0m 5.56    \u001b[0m | \u001b[0m 1.427   \u001b[0m | \u001b[0m 310.1   \u001b[0m | \u001b[0m 2.978   \u001b[0m | \u001b[0m 0.684   \u001b[0m |\n",
      "| \u001b[0m 229     \u001b[0m | \u001b[0m 110.0   \u001b[0m | \u001b[0m 0.7001  \u001b[0m | \u001b[0m 0.6939  \u001b[0m | \u001b[0m 4.884   \u001b[0m | \u001b[0m 1.526   \u001b[0m | \u001b[0m 311.5   \u001b[0m | \u001b[0m 2.748   \u001b[0m | \u001b[0m 0.7694  \u001b[0m |\n",
      "| \u001b[0m 230     \u001b[0m | \u001b[0m 155.0   \u001b[0m | \u001b[0m 0.8152  \u001b[0m | \u001b[0m 0.4726  \u001b[0m | \u001b[0m 5.098   \u001b[0m | \u001b[0m 1.099   \u001b[0m | \u001b[0m 309.5   \u001b[0m | \u001b[0m 2.811   \u001b[0m | \u001b[0m 0.6634  \u001b[0m |\n",
      "| \u001b[0m 231     \u001b[0m | \u001b[0m 155.0   \u001b[0m | \u001b[0m 0.7556  \u001b[0m | \u001b[0m 0.6531  \u001b[0m | \u001b[0m 5.612   \u001b[0m | \u001b[0m 2.004   \u001b[0m | \u001b[0m 311.8   \u001b[0m | \u001b[0m 2.199   \u001b[0m | \u001b[0m 0.8569  \u001b[0m |\n",
      "| \u001b[0m 232     \u001b[0m | \u001b[0m 100.0   \u001b[0m | \u001b[0m 0.6231  \u001b[0m | \u001b[0m 0.2455  \u001b[0m | \u001b[0m 5.184   \u001b[0m | \u001b[0m 1.419   \u001b[0m | \u001b[0m 308.3   \u001b[0m | \u001b[0m 3.638   \u001b[0m | \u001b[0m 0.6784  \u001b[0m |\n",
      "| \u001b[0m 233     \u001b[0m | \u001b[0m 115.0   \u001b[0m | \u001b[0m 0.9122  \u001b[0m | \u001b[0m 0.3509  \u001b[0m | \u001b[0m 6.879   \u001b[0m | \u001b[0m 3.74    \u001b[0m | \u001b[0m 178.6   \u001b[0m | \u001b[0m 3.87    \u001b[0m | \u001b[0m 0.766   \u001b[0m |\n",
      "| \u001b[0m 234     \u001b[0m | \u001b[0m 125.0   \u001b[0m | \u001b[0m 0.7712  \u001b[0m | \u001b[0m 0.3362  \u001b[0m | \u001b[0m 5.55    \u001b[0m | \u001b[0m 1.362   \u001b[0m | \u001b[0m 307.6   \u001b[0m | \u001b[0m 4.116   \u001b[0m | \u001b[0m 0.9379  \u001b[0m |\n",
      "| \u001b[0m 235     \u001b[0m | \u001b[0m 45.0    \u001b[0m | \u001b[0m 0.6855  \u001b[0m | \u001b[0m 0.8238  \u001b[0m | \u001b[0m 8.289   \u001b[0m | \u001b[0m 2.516   \u001b[0m | \u001b[0m 329.4   \u001b[0m | \u001b[0m 8.25    \u001b[0m | \u001b[0m 0.9372  \u001b[0m |\n",
      "| \u001b[0m 236     \u001b[0m | \u001b[0m 75.0    \u001b[0m | \u001b[0m 0.715   \u001b[0m | \u001b[0m 0.7388  \u001b[0m | \u001b[0m 5.292   \u001b[0m | \u001b[0m 2.082   \u001b[0m | \u001b[0m 309.4   \u001b[0m | \u001b[0m 3.988   \u001b[0m | \u001b[0m 0.94    \u001b[0m |\n",
      "| \u001b[0m 237     \u001b[0m | \u001b[0m 65.0    \u001b[0m | \u001b[0m 0.8157  \u001b[0m | \u001b[0m 0.4452  \u001b[0m | \u001b[0m 8.971   \u001b[0m | \u001b[0m 3.18    \u001b[0m | \u001b[0m 331.2   \u001b[0m | \u001b[0m 9.756   \u001b[0m | \u001b[0m 0.7836  \u001b[0m |\n",
      "| \u001b[0m 238     \u001b[0m | \u001b[0m 20.0    \u001b[0m | \u001b[0m 0.6785  \u001b[0m | \u001b[0m 0.216   \u001b[0m | \u001b[0m 4.872   \u001b[0m | \u001b[0m 4.359   \u001b[0m | \u001b[0m 247.7   \u001b[0m | \u001b[0m 12.41   \u001b[0m | \u001b[0m 0.8704  \u001b[0m |\n",
      "| \u001b[0m 239     \u001b[0m | \u001b[0m 45.0    \u001b[0m | \u001b[0m 0.9789  \u001b[0m | \u001b[0m 0.5415  \u001b[0m | \u001b[0m 9.155   \u001b[0m | \u001b[0m 2.55    \u001b[0m | \u001b[0m 331.3   \u001b[0m | \u001b[0m 9.813   \u001b[0m | \u001b[0m 0.9128  \u001b[0m |\n",
      "| \u001b[0m 240     \u001b[0m | \u001b[0m 115.0   \u001b[0m | \u001b[0m 0.6746  \u001b[0m | \u001b[0m 0.6304  \u001b[0m | \u001b[0m 6.035   \u001b[0m | \u001b[0m 1.296   \u001b[0m | \u001b[0m 311.8   \u001b[0m | \u001b[0m 3.527   \u001b[0m | \u001b[0m 0.9072  \u001b[0m |\n",
      "| \u001b[0m 241     \u001b[0m | \u001b[0m 70.0    \u001b[0m | \u001b[0m 0.8374  \u001b[0m | \u001b[0m 0.7213  \u001b[0m | \u001b[0m 6.429   \u001b[0m | \u001b[0m 3.126   \u001b[0m | \u001b[0m 178.4   \u001b[0m | \u001b[0m 3.9     \u001b[0m | \u001b[0m 0.698   \u001b[0m |\n",
      "| \u001b[0m 242     \u001b[0m | \u001b[0m 100.0   \u001b[0m | \u001b[0m 0.6642  \u001b[0m | \u001b[0m 0.6654  \u001b[0m | \u001b[0m 7.367   \u001b[0m | \u001b[0m 3.162   \u001b[0m | \u001b[0m 309.0   \u001b[0m | \u001b[0m 4.665   \u001b[0m | \u001b[0m 0.6677  \u001b[0m |\n",
      "| \u001b[0m 243     \u001b[0m | \u001b[0m 25.0    \u001b[0m | \u001b[0m 0.8315  \u001b[0m | \u001b[0m 0.6864  \u001b[0m | \u001b[0m 9.096   \u001b[0m | \u001b[0m 1.137   \u001b[0m | \u001b[0m 102.1   \u001b[0m | \u001b[0m 4.708   \u001b[0m | \u001b[0m 0.7835  \u001b[0m |\n",
      "| \u001b[0m 244     \u001b[0m | \u001b[0m 130.0   \u001b[0m | \u001b[0m 0.97    \u001b[0m | \u001b[0m 0.4635  \u001b[0m | \u001b[0m 5.839   \u001b[0m | \u001b[0m 1.785   \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.38    \u001b[0m | \u001b[0m 0.8137  \u001b[0m |\n",
      "| \u001b[0m 245     \u001b[0m | \u001b[0m 220.0   \u001b[0m | \u001b[0m 0.9173  \u001b[0m | \u001b[0m 0.6705  \u001b[0m | \u001b[0m 5.016   \u001b[0m | \u001b[0m 2.038   \u001b[0m | \u001b[0m 309.7   \u001b[0m | \u001b[0m 1.439   \u001b[0m | \u001b[0m 0.9219  \u001b[0m |\n",
      "| \u001b[0m 246     \u001b[0m | \u001b[0m 75.0    \u001b[0m | \u001b[0m 0.8393  \u001b[0m | \u001b[0m 0.9328  \u001b[0m | \u001b[0m 8.009   \u001b[0m | \u001b[0m 2.662   \u001b[0m | \u001b[0m 329.7   \u001b[0m | \u001b[0m 7.982   \u001b[0m | \u001b[0m 0.8761  \u001b[0m |\n",
      "| \u001b[0m 247     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.6492  \u001b[0m | \u001b[0m 0.6308  \u001b[0m | \u001b[0m 8.282   \u001b[0m | \u001b[0m 2.647   \u001b[0m | \u001b[0m 329.4   \u001b[0m | \u001b[0m 7.779   \u001b[0m | \u001b[0m 0.9784  \u001b[0m |\n",
      "| \u001b[0m 248     \u001b[0m | \u001b[0m 80.0    \u001b[0m | \u001b[0m 0.6841  \u001b[0m | \u001b[0m 0.9825  \u001b[0m | \u001b[0m 6.072   \u001b[0m | \u001b[0m 2.196   \u001b[0m | \u001b[0m 309.2   \u001b[0m | \u001b[0m 3.091   \u001b[0m | \u001b[0m 0.7435  \u001b[0m |\n",
      "| \u001b[0m 249     \u001b[0m | \u001b[0m 85.0    \u001b[0m | \u001b[0m 0.8422  \u001b[0m | \u001b[0m 0.5412  \u001b[0m | \u001b[0m 5.904   \u001b[0m | \u001b[0m 2.051   \u001b[0m | \u001b[0m 308.5   \u001b[0m | \u001b[0m 4.959   \u001b[0m | \u001b[0m 0.934   \u001b[0m |\n",
      "| \u001b[0m 250     \u001b[0m | \u001b[0m 70.0    \u001b[0m | \u001b[0m 0.7777  \u001b[0m | \u001b[0m 0.5963  \u001b[0m | \u001b[0m 9.229   \u001b[0m | \u001b[0m 1.583   \u001b[0m | \u001b[0m 331.6   \u001b[0m | \u001b[0m 8.43    \u001b[0m | \u001b[0m 0.8188  \u001b[0m |\n",
      "=============================================================================================================\n"
     ]
    }
   ],
   "source": [
    "optimization_XGB = BayesianOptimization(evaluateXGB, params_XGB, random_state=42)\n",
    "optimization_XGB.maximize(n_iter=200, init_points=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': 220.0,\n",
       " 'params': {'colsample_bytree': 0.605873136934962,\n",
       "  'gamma': 0.327183911209176,\n",
       "  'max_depth': 4.660877147619236,\n",
       "  'min_child_weight': 1.7514049980791158,\n",
       "  'n_estimators': 309.86651749531757,\n",
       "  'reg_alpha': 1.691261657814916,\n",
       "  'subsample': 0.7249958039005243}}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimization_XGB.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(cross_validate(XGBClassifier(learning_rate =0.1,\n",
    "                          n_estimators=308,\n",
    "                          max_depth=4,\n",
    "                          min_child_weight=1,\n",
    "                          gamma=0.327183911209176,\n",
    "                          subsample=0.7249958039005243,\n",
    "                          colsample_bytree=0.605873136934962,\n",
    "                          reg_alpha=1.691261657814916,\n",
    "                          #reg_lambda=0.5123,\n",
    "                          objective= 'binary:logistic',\n",
    "                          n_jobs=-1,\n",
    "                          scale_pos_weight=1,\n",
    "                          seed=231),\n",
    "                   X_train_trust12_prepared,\n",
    "                   y=y_train_trust12,\n",
    "                   cv=cv,\n",
    "                   scoring=profit_scoring)['test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateLogistic(C):\n",
    "    \n",
    "    model = LogisticRegression(C=C, solver='liblinear', random_state=42)\n",
    "    \n",
    "    return sum(cross_validate(model, X_train_trust12_prepared, y=y_train_trust12, cv=cv,\n",
    "                             scoring=profit_scoring,\n",
    "                             #scoring=\"precision\",\n",
    "                             )['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_logistic = {\n",
    "    'C': (1,1000),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |     C     |\n",
      "-------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 260.0   \u001b[0m | \u001b[0m 781.7   \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 270.0   \u001b[0m | \u001b[95m 584.6   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 270.0   \u001b[0m | \u001b[0m 427.3   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 270.0   \u001b[0m | \u001b[0m 316.0   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 260.0   \u001b[0m | \u001b[0m 827.1   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 260.0   \u001b[0m | \u001b[0m 903.5   \u001b[0m |\n",
      "| \u001b[95m 7       \u001b[0m | \u001b[95m 330.0   \u001b[0m | \u001b[95m 39.9    \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 260.0   \u001b[0m | \u001b[0m 915.3   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 61.44   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 280.0   \u001b[0m | \u001b[0m 181.5   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 73.23   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 270.0   \u001b[0m | \u001b[0m 459.3   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 260.0   \u001b[0m | \u001b[0m 708.7   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 270.0   \u001b[0m | \u001b[0m 483.8   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 26.42   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 67.84   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 270.0   \u001b[0m | \u001b[0m 426.5   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 280.0   \u001b[0m | \u001b[0m 220.0   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 260.0   \u001b[0m | \u001b[0m 810.3   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 280.0   \u001b[0m | \u001b[0m 140.9   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 260.0   \u001b[0m | \u001b[0m 751.4   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 245.0   \u001b[0m | \u001b[0m 279.8   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 260.0   \u001b[0m | \u001b[0m 949.2   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 260.0   \u001b[0m | \u001b[0m 885.1   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 270.0   \u001b[0m | \u001b[0m 610.6   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 260.0   \u001b[0m | \u001b[0m 779.3   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 42.51   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 260.0   \u001b[0m | \u001b[0m 786.6   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 260.0   \u001b[0m | \u001b[0m 902.6   \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 270.0   \u001b[0m | \u001b[0m 433.6   \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m 260.0   \u001b[0m | \u001b[0m 886.7   \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 270.0   \u001b[0m | \u001b[0m 549.0   \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 260.0   \u001b[0m | \u001b[0m 987.0   \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m 270.0   \u001b[0m | \u001b[0m 565.7   \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m 260.0   \u001b[0m | \u001b[0m 901.1   \u001b[0m |\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m 270.0   \u001b[0m | \u001b[0m 564.2   \u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m 305.0   \u001b[0m | \u001b[0m 96.8    \u001b[0m |\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m 270.0   \u001b[0m | \u001b[0m 617.9   \u001b[0m |\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 60.95   \u001b[0m |\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m 270.0   \u001b[0m | \u001b[0m 580.8   \u001b[0m |\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m 260.0   \u001b[0m | \u001b[0m 871.8   \u001b[0m |\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m 260.0   \u001b[0m | \u001b[0m 800.0   \u001b[0m |\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 67.59   \u001b[0m |\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 61.09   \u001b[0m |\n",
      "| \u001b[0m 45      \u001b[0m | \u001b[0m 260.0   \u001b[0m | \u001b[0m 899.4   \u001b[0m |\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m 260.0   \u001b[0m | \u001b[0m 644.0   \u001b[0m |\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m 260.0   \u001b[0m | \u001b[0m 668.3   \u001b[0m |\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m 305.0   \u001b[0m | \u001b[0m 101.0   \u001b[0m |\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m 260.0   \u001b[0m | \u001b[0m 646.3   \u001b[0m |\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 43.69   \u001b[0m |\n",
      "| \u001b[0m 51      \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 30.85   \u001b[0m |\n",
      "| \u001b[0m 52      \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 71.31   \u001b[0m |\n",
      "| \u001b[0m 53      \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 52.29   \u001b[0m |\n",
      "| \u001b[0m 54      \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 28.29   \u001b[0m |\n",
      "| \u001b[0m 55      \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 35.08   \u001b[0m |\n",
      "| \u001b[0m 56      \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 56.06   \u001b[0m |\n",
      "| \u001b[0m 57      \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 48.32   \u001b[0m |\n",
      "| \u001b[0m 58      \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 65.0    \u001b[0m |\n",
      "| \u001b[0m 59      \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 72.42   \u001b[0m |\n",
      "| \u001b[0m 60      \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 32.98   \u001b[0m |\n",
      "| \u001b[0m 61      \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 58.38   \u001b[0m |\n",
      "| \u001b[0m 62      \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 37.51   \u001b[0m |\n",
      "| \u001b[0m 63      \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 46.17   \u001b[0m |\n",
      "| \u001b[0m 64      \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 27.23   \u001b[0m |\n",
      "| \u001b[0m 65      \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 50.38   \u001b[0m |\n",
      "| \u001b[0m 66      \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 72.48   \u001b[0m |\n",
      "| \u001b[0m 67      \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 54.19   \u001b[0m |\n",
      "| \u001b[0m 68      \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 63.21   \u001b[0m |\n",
      "| \u001b[0m 69      \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 72.5    \u001b[0m |\n",
      "| \u001b[0m 70      \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 66.37   \u001b[0m |\n",
      "| \u001b[0m 71      \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 72.5    \u001b[0m |\n",
      "| \u001b[0m 72      \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 41.23   \u001b[0m |\n",
      "| \u001b[0m 73      \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 59.62   \u001b[0m |\n",
      "| \u001b[0m 74      \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 44.9    \u001b[0m |\n",
      "| \u001b[0m 75      \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 72.47   \u001b[0m |\n",
      "| \u001b[0m 76      \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 36.29   \u001b[0m |\n",
      "| \u001b[0m 77      \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 27.22   \u001b[0m |\n",
      "| \u001b[0m 78      \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 38.7    \u001b[0m |\n",
      "| \u001b[0m 79      \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 57.23   \u001b[0m |\n",
      "| \u001b[0m 80      \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 31.96   \u001b[0m |\n",
      "| \u001b[0m 81      \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 72.45   \u001b[0m |\n",
      "| \u001b[0m 82      \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 47.24   \u001b[0m |\n",
      "| \u001b[0m 83      \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 34.03   \u001b[0m |\n",
      "| \u001b[0m 84      \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 72.44   \u001b[0m |\n",
      "| \u001b[0m 85      \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 49.34   \u001b[0m |\n",
      "| \u001b[0m 86      \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 29.76   \u001b[0m |\n",
      "| \u001b[0m 87      \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 51.32   \u001b[0m |\n",
      "| \u001b[0m 88      \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 53.23   \u001b[0m |\n",
      "| \u001b[0m 89      \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 72.42   \u001b[0m |\n",
      "| \u001b[0m 90      \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 55.12   \u001b[0m |\n",
      "| \u001b[0m 91      \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 66.48   \u001b[0m |\n",
      "| \u001b[0m 92      \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 64.05   \u001b[0m |\n",
      "| \u001b[0m 93      \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 72.44   \u001b[0m |\n",
      "| \u001b[0m 94      \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 62.49   \u001b[0m |\n",
      "| \u001b[0m 95      \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 27.32   \u001b[0m |\n",
      "| \u001b[0m 96      \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 72.41   \u001b[0m |\n",
      "| \u001b[0m 97      \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 40.64   \u001b[0m |\n",
      "| \u001b[0m 98      \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 72.42   \u001b[0m |\n",
      "| \u001b[0m 99      \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 45.42   \u001b[0m |\n",
      "| \u001b[0m 100     \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 59.15   \u001b[0m |\n",
      "| \u001b[0m 101     \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 36.8    \u001b[0m |\n",
      "| \u001b[0m 102     \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 42.33   \u001b[0m |\n",
      "| \u001b[0m 103     \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 38.61   \u001b[0m |\n",
      "| \u001b[0m 104     \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 72.41   \u001b[0m |\n",
      "| \u001b[0m 105     \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 57.07   \u001b[0m |\n",
      "| \u001b[0m 106     \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 31.54   \u001b[0m |\n",
      "| \u001b[0m 107     \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 66.69   \u001b[0m |\n",
      "| \u001b[0m 108     \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 43.93   \u001b[0m |\n",
      "| \u001b[0m 109     \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 35.18   \u001b[0m |\n",
      "| \u001b[0m 110     \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 72.39   \u001b[0m |\n",
      "| \u001b[0m 111     \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 47.61   \u001b[0m |\n",
      "| \u001b[0m 112     \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 33.38   \u001b[0m |\n",
      "| \u001b[0m 113     \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 49.79   \u001b[0m |\n",
      "| \u001b[0m 114     \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 65.38   \u001b[0m |\n",
      "| \u001b[0m 115     \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 29.11   \u001b[0m |\n",
      "| \u001b[0m 116     \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 72.41   \u001b[0m |\n",
      "| \u001b[0m 117     \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 51.74   \u001b[0m |\n",
      "| \u001b[0m 118     \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 53.68   \u001b[0m |\n",
      "| \u001b[0m 119     \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 55.51   \u001b[0m |\n",
      "| \u001b[0m 120     \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 27.57   \u001b[0m |\n",
      "| \u001b[0m 121     \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 72.37   \u001b[0m |\n",
      "| \u001b[0m 122     \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 30.45   \u001b[0m |\n",
      "| \u001b[0m 123     \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 39.63   \u001b[0m |\n",
      "| \u001b[0m 124     \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 60.01   \u001b[0m |\n",
      "| \u001b[0m 125     \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 46.38   \u001b[0m |\n",
      "| \u001b[0m 126     \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 58.05   \u001b[0m |\n",
      "| \u001b[0m 127     \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 72.37   \u001b[0m |\n",
      "| \u001b[0m 128     \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 26.07   \u001b[0m |\n",
      "| \u001b[0m 129     \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 26.73   \u001b[0m |\n",
      "| \u001b[0m 130     \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 62.58   \u001b[0m |\n",
      "| \u001b[0m 131     \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 48.54   \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 132     \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 66.74   \u001b[0m |\n",
      "| \u001b[0m 133     \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 72.36   \u001b[0m |\n",
      "| \u001b[0m 134     \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 37.58   \u001b[0m |\n",
      "| \u001b[0m 135     \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 41.57   \u001b[0m |\n",
      "| \u001b[0m 136     \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 64.09   \u001b[0m |\n",
      "| \u001b[0m 137     \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 25.46   \u001b[0m |\n",
      "| \u001b[0m 138     \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 24.87   \u001b[0m |\n",
      "| \u001b[0m 139     \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 25.64   \u001b[0m |\n",
      "| \u001b[0m 140     \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 24.14   \u001b[0m |\n",
      "| \u001b[0m 141     \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 24.82   \u001b[0m |\n",
      "| \u001b[0m 142     \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 23.38   \u001b[0m |\n",
      "| \u001b[0m 143     \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 24.07   \u001b[0m |\n",
      "| \u001b[0m 144     \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 22.56   \u001b[0m |\n",
      "| \u001b[0m 145     \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 23.23   \u001b[0m |\n",
      "| \u001b[0m 146     \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 21.69   \u001b[0m |\n",
      "| \u001b[0m 147     \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 22.45   \u001b[0m |\n",
      "| \u001b[0m 148     \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 20.78   \u001b[0m |\n",
      "| \u001b[0m 149     \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 21.51   \u001b[0m |\n",
      "| \u001b[0m 150     \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 19.81   \u001b[0m |\n",
      "=====================================\n"
     ]
    }
   ],
   "source": [
    "optimization_logistic = BayesianOptimization(evaluateLogistic, params_logistic, random_state=231)\n",
    "optimization_logistic.maximize(n_iter=100, init_points=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': 330.0, 'params': {'C': 39.89916730939222}}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimization_logistic.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "330"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(cross_validate(LogisticRegression(C=39.89916730939222,\n",
    "                                      solver='liblinear',\n",
    "                                      random_state=42),\n",
    "                   X_train_trust12_prepared,\n",
    "                   y=y_train_trust12,\n",
    "                   cv=cv,\n",
    "                   scoring=profit_scoring)['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add additional Features - Interaction Effects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PolynomialFeatures - SelectKBest for trustLevel==1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(332, 9)\n",
      "(332,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trustLevel</th>\n",
       "      <th>totalScanTimeInSeconds</th>\n",
       "      <th>grandTotal</th>\n",
       "      <th>lineItemVoids</th>\n",
       "      <th>scansWithoutRegistration</th>\n",
       "      <th>quantityModifications</th>\n",
       "      <th>scannedLineItemsPerSecond</th>\n",
       "      <th>valuePerSecond</th>\n",
       "      <th>lineItemVoidsPerPosition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>770</td>\n",
       "      <td>11.09</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.033766</td>\n",
       "      <td>0.014403</td>\n",
       "      <td>0.423077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>870</td>\n",
       "      <td>32.45</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.006897</td>\n",
       "      <td>0.037299</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>78.91</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>1.111408</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    trustLevel  totalScanTimeInSeconds  grandTotal  lineItemVoids  \\\n",
       "5            1                     770       11.09             11   \n",
       "15           1                     870       32.45              3   \n",
       "24           1                      71       78.91              1   \n",
       "\n",
       "    scansWithoutRegistration  quantityModifications  \\\n",
       "5                          5                      2   \n",
       "15                         1                      5   \n",
       "24                         4                      4   \n",
       "\n",
       "    scannedLineItemsPerSecond  valuePerSecond  lineItemVoidsPerPosition  \n",
       "5                    0.033766        0.014403                  0.423077  \n",
       "15                   0.006897        0.037299                  0.500000  \n",
       "24                   0.014085        1.111408                  1.000000  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create X_train trustLevel==1\n",
    "df_train = pd.read_csv('train.csv' ,delimiter=\"|\")\n",
    "\n",
    "is_trust1 = df_train['trustLevel']==1\n",
    "df_train_trust1 = df_train[is_trust1]\n",
    "\n",
    "X_train_trust1, y_train_trust1 = df_train_trust1.drop(columns='fraud'), df_train_trust1['fraud']\n",
    "\n",
    "print(X_train_trust1.shape)\n",
    "print(y_train_trust1.shape)\n",
    "X_train_trust1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 332 entries, 5 to 1875\n",
      "Data columns (total 9 columns):\n",
      "trustLevel                   332 non-null int64\n",
      "totalScanTimeInSeconds       332 non-null int64\n",
      "grandTotal                   332 non-null float64\n",
      "lineItemVoids                332 non-null int64\n",
      "scansWithoutRegistration     332 non-null int64\n",
      "quantityModifications        332 non-null int64\n",
      "scannedLineItemsPerSecond    332 non-null float64\n",
      "valuePerSecond               332 non-null float64\n",
      "lineItemVoidsPerPosition     332 non-null float64\n",
      "dtypes: float64(4), int64(5)\n",
      "memory usage: 25.9 KB\n"
     ]
    }
   ],
   "source": [
    "X_train_trust1.head(3)\n",
    "X_train_trust1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data size trustLevel==1: 332\n",
      "[(0, 243), (1, 89)]\n",
      "Max. profit: 445\n"
     ]
    }
   ],
   "source": [
    "# show distribution\n",
    "from collections import Counter\n",
    "\n",
    "print(\"training data size trustLevel==1: {}\".format(len(y_train_trust1)))\n",
    "print(sorted(Counter(y_train_trust1).items()))\n",
    "print(\"Max. profit: {}\".format(89*5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Maximal profit equals **445**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop trustLevel\n",
    "X_train_trust1 = X_train_trust1.drop(columns='trustLevel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Only two preprocessing steps at the moment are adding newly designed features (see above) and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import mutual_info_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_pipeline = Pipeline([\n",
    "    #(\"transformer\", Transformer()),                           # This class is still void\n",
    "    #(\"interactions\", PolynomialFeatures(2, interaction_only=True)),\n",
    "    (\"interactions\", PolynomialFeatures(2, interaction_only=False)),\n",
    "    (\"scaler1\", StandardScaler()),\n",
    "    (\"scaler\", MinMaxScaler()),\n",
    "    (\"featureSelection\", SelectKBest(mutual_info_classif, k=8)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply new pipeline\n",
    "X_train_trust1_prepared = preprocessing_pipeline.fit_transform(X_train_trust1, y=y_train_trust1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete trustLevel feature!\n",
    "#X_train_trust1_prepared = np.delete(X_train_trust1_prepared, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(332, 6)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_trust1_prepared.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.06232423e-02, 4.23076923e-02, 8.62068966e-01, 4.65384615e-02,\n",
       "        4.39135492e-04, 7.15398485e-05],\n",
       "       [3.93980009e-03, 5.00000000e-02, 1.72413793e-01, 1.50000000e-02,\n",
       "        1.82066175e-05, 2.18954215e-04],\n",
       "       [8.40281669e-03, 1.00000000e-01, 1.11022302e-16, 1.00000000e-02,\n",
       "        7.63073803e-05, 1.30485289e-02],\n",
       "       ...,\n",
       "       [1.30031476e-03, 2.33333333e-01, 6.89655172e-02, 1.63333333e-01,\n",
       "        2.57920517e-06, 3.50525002e-04],\n",
       "       [4.41460295e-02, 3.47826087e-02, 7.58620690e-01, 2.78260870e-02,\n",
       "        1.97773894e-03, 9.67230464e-04],\n",
       "       [4.03213306e-02, 1.92307692e-02, 8.62068966e-01, 9.61538462e-03,\n",
       "        1.65228125e-03, 2.38234343e-04]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_trust1_prepared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the library for Bayesian optimization from here: https://github.com/fmfn/BayesianOptimization\n",
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateLogistic(C):\n",
    "    \n",
    "    model = LogisticRegression(C=C, solver='liblinear', random_state=42)\n",
    "    \n",
    "    return sum(cross_validate(model, X_train_trust1_prepared, y=y_train_trust1, cv=cv,\n",
    "                                scoring=profit_scoring,\n",
    "                                  #scoring=\"f1\"\n",
    "                                 )['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_logistic = {\n",
    "    'C': (1,1000),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |     C     |\n",
      "-------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 60.0    \u001b[0m | \u001b[0m 781.7   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 60.0    \u001b[0m | \u001b[0m 584.6   \u001b[0m |\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m 85.0    \u001b[0m | \u001b[95m 427.3   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 85.0    \u001b[0m | \u001b[0m 316.0   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 60.0    \u001b[0m | \u001b[0m 827.1   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 60.0    \u001b[0m | \u001b[0m 903.5   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-40.0    \u001b[0m | \u001b[0m 39.9    \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 60.0    \u001b[0m | \u001b[0m 915.3   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-15.0    \u001b[0m | \u001b[0m 61.44   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 70.0    \u001b[0m | \u001b[0m 181.5   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-15.0    \u001b[0m | \u001b[0m 73.23   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 60.0    \u001b[0m | \u001b[0m 459.3   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 60.0    \u001b[0m | \u001b[0m 708.7   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 60.0    \u001b[0m | \u001b[0m 483.8   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-40.0    \u001b[0m | \u001b[0m 26.42   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-15.0    \u001b[0m | \u001b[0m 67.84   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 85.0    \u001b[0m | \u001b[0m 426.5   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 70.0    \u001b[0m | \u001b[0m 220.0   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 60.0    \u001b[0m | \u001b[0m 810.3   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 70.0    \u001b[0m | \u001b[0m 140.9   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 60.0    \u001b[0m | \u001b[0m 751.4   \u001b[0m |\n",
      "| \u001b[95m 22      \u001b[0m | \u001b[95m 95.0    \u001b[0m | \u001b[95m 279.8   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 60.0    \u001b[0m | \u001b[0m 949.2   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 60.0    \u001b[0m | \u001b[0m 885.1   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 60.0    \u001b[0m | \u001b[0m 610.6   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 60.0    \u001b[0m | \u001b[0m 779.3   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m-40.0    \u001b[0m | \u001b[0m 42.51   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 60.0    \u001b[0m | \u001b[0m 786.6   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 60.0    \u001b[0m | \u001b[0m 902.6   \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 85.0    \u001b[0m | \u001b[0m 433.6   \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m 60.0    \u001b[0m | \u001b[0m 886.7   \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 60.0    \u001b[0m | \u001b[0m 549.0   \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 60.0    \u001b[0m | \u001b[0m 987.0   \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m 60.0    \u001b[0m | \u001b[0m 565.7   \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m 60.0    \u001b[0m | \u001b[0m 901.1   \u001b[0m |\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m 60.0    \u001b[0m | \u001b[0m 564.2   \u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m 20.0    \u001b[0m | \u001b[0m 96.8    \u001b[0m |\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m 60.0    \u001b[0m | \u001b[0m 617.9   \u001b[0m |\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m-15.0    \u001b[0m | \u001b[0m 60.95   \u001b[0m |\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m 60.0    \u001b[0m | \u001b[0m 580.8   \u001b[0m |\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m 60.0    \u001b[0m | \u001b[0m 871.8   \u001b[0m |\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m 60.0    \u001b[0m | \u001b[0m 800.0   \u001b[0m |\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m-15.0    \u001b[0m | \u001b[0m 67.59   \u001b[0m |\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m-15.0    \u001b[0m | \u001b[0m 61.09   \u001b[0m |\n",
      "| \u001b[0m 45      \u001b[0m | \u001b[0m 60.0    \u001b[0m | \u001b[0m 899.4   \u001b[0m |\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m 60.0    \u001b[0m | \u001b[0m 644.0   \u001b[0m |\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m 60.0    \u001b[0m | \u001b[0m 668.3   \u001b[0m |\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m 20.0    \u001b[0m | \u001b[0m 101.0   \u001b[0m |\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m 60.0    \u001b[0m | \u001b[0m 646.3   \u001b[0m |\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m-15.0    \u001b[0m | \u001b[0m 43.69   \u001b[0m |\n",
      "| \u001b[0m 51      \u001b[0m | \u001b[0m 95.0    \u001b[0m | \u001b[0m 280.0   \u001b[0m |\n",
      "| \u001b[0m 52      \u001b[0m | \u001b[0m 95.0    \u001b[0m | \u001b[0m 279.9   \u001b[0m |\n",
      "| \u001b[0m 53      \u001b[0m | \u001b[0m 95.0    \u001b[0m | \u001b[0m 279.9   \u001b[0m |\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[0;34m(self, init_points, n_iter, acq, kappa, xi, **gp_params)\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m                 \u001b[0mx_probe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Queue is empty, no more objects to retrieve.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStopIteration\u001b[0m: Queue is empty, no more objects to retrieve.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-3030656010f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moptimization_logistic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBayesianOptimization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluateLogistic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_logistic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m231\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moptimization_logistic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[0;34m(self, init_points, n_iter, acq, kappa, xi, **gp_params)\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0mx_probe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m                 \u001b[0mx_probe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m                 \u001b[0miteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36msuggest\u001b[0;34m(self, utility_function)\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0my_max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0mbounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_random_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         )\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/bayes_opt/util.py\u001b[0m in \u001b[0;36macq_max\u001b[0;34m(ac, gp, y_max, bounds, random_state, n_warmup, n_iter)\u001b[0m\n\u001b[1;32m     56\u001b[0m                        \u001b[0mx_try\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                        \u001b[0mbounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                        method=\"L-BFGS-B\")\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# See if success\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0;32m--> 601\u001b[0;31m                                 callback=callback, **options)\n\u001b[0m\u001b[1;32m    602\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tnc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m         return _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_approx_fprime_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_approx_fprime_helper\u001b[0;34m(xk, f, epsilon, args, f0)\u001b[0m\n\u001b[1;32m    668\u001b[0m         \u001b[0mei\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mei\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m         \u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxk\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mf0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m         \u001b[0mei\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/bayes_opt/util.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx_try\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx_seeds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;31m# Find the minimum of minus the acquisition function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         res = minimize(lambda x: -ac(x.reshape(1, -1), gp=gp, y_max=y_max),\n\u001b[0m\u001b[1;32m     56\u001b[0m                        \u001b[0mx_try\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                        \u001b[0mbounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimization_logistic = BayesianOptimization(evaluateLogistic, params_logistic, random_state=231)\n",
    "optimization_logistic.maximize(n_iter=100, init_points=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimization_logistic.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "335"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(cross_validate(LogisticRegression(C=2.32,\n",
    "                                      solver='liblinear',\n",
    "                                      random_state=42),\n",
    "                   X_train_trust1_prepared,\n",
    "                   y=y_train_trust1,\n",
    "                   cv=cv,\n",
    "                   scoring=profit_scoring)['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7528089887640449"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "335/445"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:** For **trustLevel==1** Logistic Regression achieves profit of **335** or **0.75** percent of maximal profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SELECT FROM MODEL for trustLevel==1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(332, 9)\n",
      "(332,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trustLevel</th>\n",
       "      <th>totalScanTimeInSeconds</th>\n",
       "      <th>grandTotal</th>\n",
       "      <th>lineItemVoids</th>\n",
       "      <th>scansWithoutRegistration</th>\n",
       "      <th>quantityModifications</th>\n",
       "      <th>scannedLineItemsPerSecond</th>\n",
       "      <th>valuePerSecond</th>\n",
       "      <th>lineItemVoidsPerPosition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>770</td>\n",
       "      <td>11.09</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.033766</td>\n",
       "      <td>0.014403</td>\n",
       "      <td>0.423077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>870</td>\n",
       "      <td>32.45</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.006897</td>\n",
       "      <td>0.037299</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>78.91</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>1.111408</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    trustLevel  totalScanTimeInSeconds  grandTotal  lineItemVoids  \\\n",
       "5            1                     770       11.09             11   \n",
       "15           1                     870       32.45              3   \n",
       "24           1                      71       78.91              1   \n",
       "\n",
       "    scansWithoutRegistration  quantityModifications  \\\n",
       "5                          5                      2   \n",
       "15                         1                      5   \n",
       "24                         4                      4   \n",
       "\n",
       "    scannedLineItemsPerSecond  valuePerSecond  lineItemVoidsPerPosition  \n",
       "5                    0.033766        0.014403                  0.423077  \n",
       "15                   0.006897        0.037299                  0.500000  \n",
       "24                   0.014085        1.111408                  1.000000  "
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create X_train trustLevel==1\n",
    "df_train = pd.read_csv('train.csv' ,delimiter=\"|\")\n",
    "\n",
    "is_trust1 = df_train['trustLevel']==1\n",
    "df_train_trust1 = df_train[is_trust1]\n",
    "\n",
    "X_train_trust1, y_train_trust1 = df_train_trust1.drop(columns='fraud'), df_train_trust1['fraud']\n",
    "\n",
    "print(X_train_trust1.shape)\n",
    "print(y_train_trust1.shape)\n",
    "X_train_trust1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data size trustLevel==1: 332\n",
      "[(0, 243), (1, 89)]\n",
      "Max. profit: 445\n"
     ]
    }
   ],
   "source": [
    "# show distribution\n",
    "from collections import Counter\n",
    "\n",
    "print(\"training data size trustLevel==1: {}\".format(len(y_train_trust1)))\n",
    "print(sorted(Counter(y_train_trust1).items()))\n",
    "print(\"Max. profit: {}\".format(89*5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Maximal profit equals **445**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop trustLevel\n",
    "X_train_trust1 = X_train_trust1.drop(columns='trustLevel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of features that show at least some correlation with fraud according to Niklas' and Yaxi's notebooks:\n",
    "- scannedLineItemsTotal * totalScanTimeInSeconds\n",
    "- scannedLineItemsTotal * scansWithoutRegistration\n",
    "- lineItemVoids * scannedLineItemsTotal\n",
    "- grandTotal * scannedLineItemsTotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select one or more out of feature list below that will be added in the featureGenerationPipeline\n",
    "feature_list = ['scannedLineItemsTotal',\n",
    "                'valuePerLineItem',\n",
    "                'quantityModificationsPerLineItem',\n",
    "                'lineItemVoids*scansWithoutRegistration',\n",
    "                #'totalScanTimeInSeconds/trustLevel',\n",
    "                #'trustLevel_Log', \n",
    "               ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Only two preprocessing steps at the moment are adding newly designed features (see above) and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureGeneration_pipeline = Pipeline([\n",
    "    (\"attribs_adder\", CustomAttributeAdder(featurelist=feature_list)),\n",
    "    (\"interactions\", PolynomialFeatures(3, interaction_only=False))\n",
    "    ])\n",
    "\n",
    "\n",
    "preprocessing_pipeline = Pipeline([\n",
    "    (\"scaler\", Scaling(strategy='Standard')),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine two pipeline into a single data_preparation_pipeline\n",
    "data_preparation_pipeline = Pipeline([\n",
    "    ('feature_generation', featureGeneration_pipeline),\n",
    "    ('preprocessing', preprocessing_pipeline)\n",
    "])\n",
    "\n",
    "X_train_trust1_prepared = data_preparation_pipeline.fit_transform(X_train_trust1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(332, 455)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_trust1_prepared.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the library for Bayesian optimization from here: https://github.com/fmfn/BayesianOptimization\n",
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SelectFromModel + Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate fbeta scorer with beta = 0.5 giving more weight to precision as an alternative to cost evaluation\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "ftwo_scorer = make_scorer(fbeta_score, beta=0.333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateLogistic(C, k,\n",
    "                    max_depth,\n",
    "                    #min_child_weight,\n",
    "                    #gamma,\n",
    "                    #subsample,\n",
    "                    #colsample_bytree,\n",
    "                    #reg_alpha,\n",
    "                    #n_estimators\n",
    "                    ):\n",
    "    \n",
    "    model = LogisticRegression(C=C, solver='liblinear', random_state=42)\n",
    "                     \n",
    "    \n",
    "    #estimator=RandomForestClassifier(max_depth=3, n_estimators=150, random_state=231),\n",
    "    #estimator=LinearSVC(penalty=\"l1\", dual=False),\n",
    "    \n",
    "    rf = RandomForestClassifier(max_depth=int(max_depth), n_estimators=300, random_state=231,\n",
    "                               class_weight='balanced')\n",
    "    \n",
    "    #xgb = XGBClassifier(learning_rate =0.1,\n",
    "     #                     n_estimators=300,\n",
    "      #                    max_depth=int(max_depth),\n",
    "       #                   min_child_weight=1,\n",
    "        #                  gamma=gamma,\n",
    "         #                 subsample=subsample,\n",
    "          #                colsample_bytree=colsample_bytree,\n",
    "           #               reg_alpha=reg_alpha,\n",
    "            #              #reg_lambda=0.5123,\n",
    "             #             objective= 'binary:logistic',\n",
    "              #            n_jobs=-1,\n",
    "               #           scale_pos_weight=1,\n",
    "                #          seed=231)\n",
    "    \n",
    "    test_pipeline = Pipeline([\n",
    "        ('feature_selection', SelectFromModel(estimator=rf,\n",
    "                                             max_features=int(k),\n",
    "                                             threshold=-np.inf)),\n",
    "        ('classification', model),\n",
    "    ])\n",
    "    \n",
    "    return np.mean(cross_validate(test_pipeline, X_train_trust1_prepared, y=y_train_trust1, cv=cv,\n",
    "                              #scoring=profit_scoring,\n",
    "                              n_jobs=-1,\n",
    "                              scoring=ftwo_scorer,\n",
    "                                  #scoring=\"f1\"\n",
    "                                 )['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_logistic = {\n",
    "    'C': (1,500),\n",
    "    'k': (2,20),\n",
    "    'max_depth':(2,5.5),\n",
    "    #'min_child_weight':(1,7),\n",
    "    #'gamma': (0,1),\n",
    "    #'subsample':(0.6,1),\n",
    "    #'colsample_bytree':(0.6,1),\n",
    "    #'reg_alpha':(0.001, 100),\n",
    "    #'n_estimators': (50,300),\n",
    "    #'reg_lambda':(0.3, 0.7)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |     C     |     k     | max_depth |\n",
      "-------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.9449  \u001b[0m | \u001b[0m 391.0   \u001b[0m | \u001b[0m 12.52   \u001b[0m | \u001b[0m 3.493   \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.9636  \u001b[0m | \u001b[95m 158.4   \u001b[0m | \u001b[95m 16.88   \u001b[0m | \u001b[95m 5.162   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.9562  \u001b[0m | \u001b[0m 20.43   \u001b[0m | \u001b[0m 18.47   \u001b[0m | \u001b[0m 2.212   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.8515  \u001b[0m | \u001b[0m 91.18   \u001b[0m | \u001b[0m 3.301   \u001b[0m | \u001b[0m 3.606   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.9056  \u001b[0m | \u001b[0m 354.5   \u001b[0m | \u001b[0m 10.7    \u001b[0m | \u001b[0m 2.089   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.9191  \u001b[0m | \u001b[0m 34.38   \u001b[0m | \u001b[0m 9.666   \u001b[0m | \u001b[0m 2.767   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.854   \u001b[0m | \u001b[0m 405.3   \u001b[0m | \u001b[0m 4.521   \u001b[0m | \u001b[0m 4.629   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.9562  \u001b[0m | \u001b[0m 140.3   \u001b[0m | \u001b[0m 19.08   \u001b[0m | \u001b[0m 5.098   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.9458  \u001b[0m | \u001b[0m 305.5   \u001b[0m | \u001b[0m 16.02   \u001b[0m | \u001b[0m 2.145   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.9498  \u001b[0m | \u001b[0m 393.4   \u001b[0m | \u001b[0m 18.24   \u001b[0m | \u001b[0m 3.515   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.9357  \u001b[0m | \u001b[0m 443.4   \u001b[0m | \u001b[0m 11.87   \u001b[0m | \u001b[0m 5.454   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.9498  \u001b[0m | \u001b[0m 283.1   \u001b[0m | \u001b[0m 18.22   \u001b[0m | \u001b[0m 3.973   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.9464  \u001b[0m | \u001b[0m 48.85   \u001b[0m | \u001b[0m 13.12   \u001b[0m | \u001b[0m 2.21    \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.9562  \u001b[0m | \u001b[0m 290.6   \u001b[0m | \u001b[0m 17.69   \u001b[0m | \u001b[0m 4.799   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.8266  \u001b[0m | \u001b[0m 34.26   \u001b[0m | \u001b[0m 3.083   \u001b[0m | \u001b[0m 5.148   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.957   \u001b[0m | \u001b[0m 322.2   \u001b[0m | \u001b[0m 14.02   \u001b[0m | \u001b[0m 2.351   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.8031  \u001b[0m | \u001b[0m 323.3   \u001b[0m | \u001b[0m 2.769   \u001b[0m | \u001b[0m 4.16    \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.9533  \u001b[0m | \u001b[0m 131.7   \u001b[0m | \u001b[0m 14.91   \u001b[0m | \u001b[0m 5.489   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.8805  \u001b[0m | \u001b[0m 130.7   \u001b[0m | \u001b[0m 7.748   \u001b[0m | \u001b[0m 2.546   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.9192  \u001b[0m | \u001b[0m 5.332   \u001b[0m | \u001b[0m 10.95   \u001b[0m | \u001b[0m 2.817   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.9562  \u001b[0m | \u001b[0m 55.11   \u001b[0m | \u001b[0m 19.02   \u001b[0m | \u001b[0m 5.119   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.9541  \u001b[0m | \u001b[0m 140.1   \u001b[0m | \u001b[0m 16.87   \u001b[0m | \u001b[0m 3.571   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.9549  \u001b[0m | \u001b[0m 12.11   \u001b[0m | \u001b[0m 18.27   \u001b[0m | \u001b[0m 4.237   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.9449  \u001b[0m | \u001b[0m 306.4   \u001b[0m | \u001b[0m 12.56   \u001b[0m | \u001b[0m 3.17    \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.8836  \u001b[0m | \u001b[0m 130.1   \u001b[0m | \u001b[0m 8.955   \u001b[0m | \u001b[0m 3.862   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.9562  \u001b[0m | \u001b[0m 486.0   \u001b[0m | \u001b[0m 18.91   \u001b[0m | \u001b[0m 2.399   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.9415  \u001b[0m | \u001b[0m 485.0   \u001b[0m | \u001b[0m 11.79   \u001b[0m | \u001b[0m 3.642   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.8873  \u001b[0m | \u001b[0m 217.1   \u001b[0m | \u001b[0m 5.989   \u001b[0m | \u001b[0m 3.096   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.9498  \u001b[0m | \u001b[0m 452.4   \u001b[0m | \u001b[0m 19.45   \u001b[0m | \u001b[0m 3.916   \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.8836  \u001b[0m | \u001b[0m 159.0   \u001b[0m | \u001b[0m 7.088   \u001b[0m | \u001b[0m 4.196   \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m 0.9175  \u001b[0m | \u001b[0m 74.35   \u001b[0m | \u001b[0m 9.943   \u001b[0m | \u001b[0m 3.647   \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 0.9439  \u001b[0m | \u001b[0m 174.7   \u001b[0m | \u001b[0m 13.97   \u001b[0m | \u001b[0m 5.302   \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 0.8174  \u001b[0m | \u001b[0m 158.8   \u001b[0m | \u001b[0m 3.824   \u001b[0m | \u001b[0m 2.984   \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m 0.9533  \u001b[0m | \u001b[0m 31.86   \u001b[0m | \u001b[0m 15.71   \u001b[0m | \u001b[0m 5.192   \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m 0.8109  \u001b[0m | \u001b[0m 390.3   \u001b[0m | \u001b[0m 2.768   \u001b[0m | \u001b[0m 2.337   \u001b[0m |\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m 0.8873  \u001b[0m | \u001b[0m 481.8   \u001b[0m | \u001b[0m 5.286   \u001b[0m | \u001b[0m 3.479   \u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m 0.9175  \u001b[0m | \u001b[0m 50.18   \u001b[0m | \u001b[0m 9.057   \u001b[0m | \u001b[0m 3.295   \u001b[0m |\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m 0.9533  \u001b[0m | \u001b[0m 88.82   \u001b[0m | \u001b[0m 16.63   \u001b[0m | \u001b[0m 2.546   \u001b[0m |\n",
      "| \u001b[95m 39      \u001b[0m | \u001b[95m 0.9648  \u001b[0m | \u001b[95m 187.9   \u001b[0m | \u001b[95m 17.62   \u001b[0m | \u001b[95m 2.32    \u001b[0m |\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m 0.9415  \u001b[0m | \u001b[0m 337.4   \u001b[0m | \u001b[0m 11.3    \u001b[0m | \u001b[0m 3.508   \u001b[0m |\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m 0.8651  \u001b[0m | \u001b[0m 259.5   \u001b[0m | \u001b[0m 4.623   \u001b[0m | \u001b[0m 3.603   \u001b[0m |\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m 0.8836  \u001b[0m | \u001b[0m 127.6   \u001b[0m | \u001b[0m 7.676   \u001b[0m | \u001b[0m 3.507   \u001b[0m |\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m 0.9498  \u001b[0m | \u001b[0m 199.4   \u001b[0m | \u001b[0m 19.14   \u001b[0m | \u001b[0m 3.925   \u001b[0m |\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m 0.9549  \u001b[0m | \u001b[0m 62.91   \u001b[0m | \u001b[0m 17.97   \u001b[0m | \u001b[0m 5.108   \u001b[0m |\n",
      "| \u001b[0m 45      \u001b[0m | \u001b[0m 0.9154  \u001b[0m | \u001b[0m 80.9    \u001b[0m | \u001b[0m 9.843   \u001b[0m | \u001b[0m 4.181   \u001b[0m |\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m 0.8484  \u001b[0m | \u001b[0m 39.45   \u001b[0m | \u001b[0m 2.466   \u001b[0m | \u001b[0m 3.863   \u001b[0m |\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m 0.9533  \u001b[0m | \u001b[0m 27.87   \u001b[0m | \u001b[0m 14.29   \u001b[0m | \u001b[0m 2.704   \u001b[0m |\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m 0.8651  \u001b[0m | \u001b[0m 418.0   \u001b[0m | \u001b[0m 4.013   \u001b[0m | \u001b[0m 3.288   \u001b[0m |\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m 0.9026  \u001b[0m | \u001b[0m 456.1   \u001b[0m | \u001b[0m 10.06   \u001b[0m | \u001b[0m 2.929   \u001b[0m |\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m 0.9533  \u001b[0m | \u001b[0m 150.0   \u001b[0m | \u001b[0m 15.46   \u001b[0m | \u001b[0m 2.292   \u001b[0m |\n",
      "| \u001b[0m 51      \u001b[0m | \u001b[0m 0.9056  \u001b[0m | \u001b[0m 405.9   \u001b[0m | \u001b[0m 9.119   \u001b[0m | \u001b[0m 3.069   \u001b[0m |\n",
      "| \u001b[0m 52      \u001b[0m | \u001b[0m 0.9553  \u001b[0m | \u001b[0m 102.1   \u001b[0m | \u001b[0m 19.71   \u001b[0m | \u001b[0m 3.709   \u001b[0m |\n",
      "| \u001b[0m 53      \u001b[0m | \u001b[0m 0.9433  \u001b[0m | \u001b[0m 88.58   \u001b[0m | \u001b[0m 12.71   \u001b[0m | \u001b[0m 4.425   \u001b[0m |\n",
      "| \u001b[0m 54      \u001b[0m | \u001b[0m 0.9415  \u001b[0m | \u001b[0m 200.4   \u001b[0m | \u001b[0m 11.61   \u001b[0m | \u001b[0m 3.426   \u001b[0m |\n",
      "| \u001b[0m 55      \u001b[0m | \u001b[0m 0.856   \u001b[0m | \u001b[0m 270.5   \u001b[0m | \u001b[0m 4.491   \u001b[0m | \u001b[0m 2.802   \u001b[0m |\n",
      "| \u001b[0m 56      \u001b[0m | \u001b[0m 0.9562  \u001b[0m | \u001b[0m 37.51   \u001b[0m | \u001b[0m 18.21   \u001b[0m | \u001b[0m 2.616   \u001b[0m |\n",
      "| \u001b[0m 57      \u001b[0m | \u001b[0m 0.9498  \u001b[0m | \u001b[0m 445.9   \u001b[0m | \u001b[0m 19.13   \u001b[0m | \u001b[0m 3.636   \u001b[0m |\n",
      "| \u001b[0m 58      \u001b[0m | \u001b[0m 0.9434  \u001b[0m | \u001b[0m 226.2   \u001b[0m | \u001b[0m 13.12   \u001b[0m | \u001b[0m 3.523   \u001b[0m |\n",
      "| \u001b[0m 59      \u001b[0m | \u001b[0m 0.9533  \u001b[0m | \u001b[0m 135.0   \u001b[0m | \u001b[0m 15.38   \u001b[0m | \u001b[0m 2.248   \u001b[0m |\n",
      "| \u001b[0m 60      \u001b[0m | \u001b[0m 0.9056  \u001b[0m | \u001b[0m 291.2   \u001b[0m | \u001b[0m 10.52   \u001b[0m | \u001b[0m 2.192   \u001b[0m |\n",
      "| \u001b[0m 61      \u001b[0m | \u001b[0m 0.8873  \u001b[0m | \u001b[0m 170.3   \u001b[0m | \u001b[0m 6.037   \u001b[0m | \u001b[0m 3.316   \u001b[0m |\n",
      "| \u001b[0m 62      \u001b[0m | \u001b[0m 0.8777  \u001b[0m | \u001b[0m 479.0   \u001b[0m | \u001b[0m 8.208   \u001b[0m | \u001b[0m 3.909   \u001b[0m |\n",
      "| \u001b[0m 63      \u001b[0m | \u001b[0m 0.9175  \u001b[0m | \u001b[0m 141.9   \u001b[0m | \u001b[0m 9.437   \u001b[0m | \u001b[0m 3.991   \u001b[0m |\n",
      "| \u001b[0m 64      \u001b[0m | \u001b[0m 0.9154  \u001b[0m | \u001b[0m 165.4   \u001b[0m | \u001b[0m 9.892   \u001b[0m | \u001b[0m 4.268   \u001b[0m |\n",
      "| \u001b[0m 65      \u001b[0m | \u001b[0m 0.9415  \u001b[0m | \u001b[0m 150.4   \u001b[0m | \u001b[0m 11.83   \u001b[0m | \u001b[0m 3.829   \u001b[0m |\n",
      "| \u001b[0m 66      \u001b[0m | \u001b[0m 0.9544  \u001b[0m | \u001b[0m 443.8   \u001b[0m | \u001b[0m 12.88   \u001b[0m | \u001b[0m 5.045   \u001b[0m |\n",
      "| \u001b[0m 67      \u001b[0m | \u001b[0m 0.9415  \u001b[0m | \u001b[0m 329.6   \u001b[0m | \u001b[0m 11.16   \u001b[0m | \u001b[0m 3.063   \u001b[0m |\n",
      "| \u001b[0m 68      \u001b[0m | \u001b[0m 0.8873  \u001b[0m | \u001b[0m 69.87   \u001b[0m | \u001b[0m 6.252   \u001b[0m | \u001b[0m 3.042   \u001b[0m |\n",
      "| \u001b[0m 69      \u001b[0m | \u001b[0m 0.957   \u001b[0m | \u001b[0m 486.3   \u001b[0m | \u001b[0m 14.03   \u001b[0m | \u001b[0m 2.035   \u001b[0m |\n",
      "| \u001b[0m 70      \u001b[0m | \u001b[0m 0.9314  \u001b[0m | \u001b[0m 424.5   \u001b[0m | \u001b[0m 10.64   \u001b[0m | \u001b[0m 3.306   \u001b[0m |\n",
      "| \u001b[0m 71      \u001b[0m | \u001b[0m 0.9541  \u001b[0m | \u001b[0m 105.2   \u001b[0m | \u001b[0m 16.54   \u001b[0m | \u001b[0m 3.043   \u001b[0m |\n",
      "| \u001b[0m 72      \u001b[0m | \u001b[0m 0.9562  \u001b[0m | \u001b[0m 336.8   \u001b[0m | \u001b[0m 19.82   \u001b[0m | \u001b[0m 2.351   \u001b[0m |\n",
      "| \u001b[0m 73      \u001b[0m | \u001b[0m 0.8836  \u001b[0m | \u001b[0m 364.4   \u001b[0m | \u001b[0m 6.837   \u001b[0m | \u001b[0m 2.8     \u001b[0m |\n",
      "| \u001b[0m 74      \u001b[0m | \u001b[0m 0.9562  \u001b[0m | \u001b[0m 444.8   \u001b[0m | \u001b[0m 18.21   \u001b[0m | \u001b[0m 2.336   \u001b[0m |\n",
      "| \u001b[0m 75      \u001b[0m | \u001b[0m 0.9537  \u001b[0m | \u001b[0m 103.3   \u001b[0m | \u001b[0m 16.19   \u001b[0m | \u001b[0m 4.114   \u001b[0m |\n",
      "| \u001b[0m 76      \u001b[0m | \u001b[0m 0.9562  \u001b[0m | \u001b[0m 500.0   \u001b[0m | \u001b[0m 20.0    \u001b[0m | \u001b[0m 5.5     \u001b[0m |\n",
      "| \u001b[0m 77      \u001b[0m | \u001b[0m 0.816   \u001b[0m | \u001b[0m 499.6   \u001b[0m | \u001b[0m 2.003   \u001b[0m | \u001b[0m 2.641   \u001b[0m |\n",
      "| \u001b[0m 78      \u001b[0m | \u001b[0m 0.9498  \u001b[0m | \u001b[0m 250.1   \u001b[0m | \u001b[0m 20.0    \u001b[0m | \u001b[0m 5.5     \u001b[0m |\n",
      "| \u001b[0m 79      \u001b[0m | \u001b[0m 0.9562  \u001b[0m | \u001b[0m 365.3   \u001b[0m | \u001b[0m 19.98   \u001b[0m | \u001b[0m 5.475   \u001b[0m |\n",
      "| \u001b[0m 80      \u001b[0m | \u001b[0m 0.9281  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 20.0    \u001b[0m | \u001b[0m 2.0     \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 81      \u001b[0m | \u001b[0m 0.9498  \u001b[0m | \u001b[0m 321.9   \u001b[0m | \u001b[0m 20.0    \u001b[0m | \u001b[0m 5.5     \u001b[0m |\n",
      "| \u001b[0m 82      \u001b[0m | \u001b[0m 0.9468  \u001b[0m | \u001b[0m 238.3   \u001b[0m | \u001b[0m 20.0    \u001b[0m | \u001b[0m 2.0     \u001b[0m |\n",
      "| \u001b[0m 83      \u001b[0m | \u001b[0m 0.9562  \u001b[0m | \u001b[0m 377.9   \u001b[0m | \u001b[0m 19.92   \u001b[0m | \u001b[0m 2.024   \u001b[0m |\n",
      "| \u001b[0m 84      \u001b[0m | \u001b[0m 0.9562  \u001b[0m | \u001b[0m 118.6   \u001b[0m | \u001b[0m 19.97   \u001b[0m | \u001b[0m 5.281   \u001b[0m |\n",
      "| \u001b[0m 85      \u001b[0m | \u001b[0m 0.9562  \u001b[0m | \u001b[0m 222.0   \u001b[0m | \u001b[0m 19.8    \u001b[0m | \u001b[0m 5.483   \u001b[0m |\n",
      "| \u001b[0m 86      \u001b[0m | \u001b[0m 0.8352  \u001b[0m | \u001b[0m 235.8   \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 5.5     \u001b[0m |\n",
      "| \u001b[0m 87      \u001b[0m | \u001b[0m 0.9562  \u001b[0m | \u001b[0m 264.7   \u001b[0m | \u001b[0m 19.85   \u001b[0m | \u001b[0m 2.162   \u001b[0m |\n",
      "| \u001b[0m 88      \u001b[0m | \u001b[0m 0.9562  \u001b[0m | \u001b[0m 381.8   \u001b[0m | \u001b[0m 19.01   \u001b[0m | \u001b[0m 5.493   \u001b[0m |\n",
      "| \u001b[0m 89      \u001b[0m | \u001b[0m 0.9562  \u001b[0m | \u001b[0m 213.6   \u001b[0m | \u001b[0m 19.96   \u001b[0m | \u001b[0m 2.049   \u001b[0m |\n",
      "| \u001b[0m 90      \u001b[0m | \u001b[0m 0.9498  \u001b[0m | \u001b[0m 268.1   \u001b[0m | \u001b[0m 20.0    \u001b[0m | \u001b[0m 5.5     \u001b[0m |\n",
      "| \u001b[0m 91      \u001b[0m | \u001b[0m 0.9562  \u001b[0m | \u001b[0m 77.47   \u001b[0m | \u001b[0m 19.87   \u001b[0m | \u001b[0m 5.486   \u001b[0m |\n",
      "| \u001b[0m 92      \u001b[0m | \u001b[0m 0.8352  \u001b[0m | \u001b[0m 189.3   \u001b[0m | \u001b[0m 2.085   \u001b[0m | \u001b[0m 5.297   \u001b[0m |\n",
      "| \u001b[0m 93      \u001b[0m | \u001b[0m 0.9213  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 16.49   \u001b[0m | \u001b[0m 5.5     \u001b[0m |\n",
      "| \u001b[0m 94      \u001b[0m | \u001b[0m 0.9562  \u001b[0m | \u001b[0m 347.3   \u001b[0m | \u001b[0m 19.44   \u001b[0m | \u001b[0m 5.425   \u001b[0m |\n",
      "| \u001b[0m 95      \u001b[0m | \u001b[0m 0.9562  \u001b[0m | \u001b[0m 494.7   \u001b[0m | \u001b[0m 19.46   \u001b[0m | \u001b[0m 2.013   \u001b[0m |\n",
      "| \u001b[0m 96      \u001b[0m | \u001b[0m 0.9562  \u001b[0m | \u001b[0m 416.5   \u001b[0m | \u001b[0m 19.99   \u001b[0m | \u001b[0m 5.495   \u001b[0m |\n",
      "| \u001b[0m 97      \u001b[0m | \u001b[0m 0.9562  \u001b[0m | \u001b[0m 173.1   \u001b[0m | \u001b[0m 19.51   \u001b[0m | \u001b[0m 2.07    \u001b[0m |\n",
      "| \u001b[0m 98      \u001b[0m | \u001b[0m 0.9562  \u001b[0m | \u001b[0m 127.4   \u001b[0m | \u001b[0m 19.8    \u001b[0m | \u001b[0m 2.431   \u001b[0m |\n",
      "| \u001b[0m 99      \u001b[0m | \u001b[0m 0.9562  \u001b[0m | \u001b[0m 64.2    \u001b[0m | \u001b[0m 19.58   \u001b[0m | \u001b[0m 2.026   \u001b[0m |\n",
      "| \u001b[0m 100     \u001b[0m | \u001b[0m 0.9562  \u001b[0m | \u001b[0m 492.7   \u001b[0m | \u001b[0m 19.0    \u001b[0m | \u001b[0m 5.428   \u001b[0m |\n",
      "| \u001b[0m 101     \u001b[0m | \u001b[0m 0.9439  \u001b[0m | \u001b[0m 373.9   \u001b[0m | \u001b[0m 13.88   \u001b[0m | \u001b[0m 5.478   \u001b[0m |\n",
      "| \u001b[0m 102     \u001b[0m | \u001b[0m 0.9549  \u001b[0m | \u001b[0m 334.3   \u001b[0m | \u001b[0m 16.34   \u001b[0m | \u001b[0m 5.456   \u001b[0m |\n",
      "| \u001b[0m 103     \u001b[0m | \u001b[0m 0.9562  \u001b[0m | \u001b[0m 422.3   \u001b[0m | \u001b[0m 19.8    \u001b[0m | \u001b[0m 2.063   \u001b[0m |\n",
      "| \u001b[0m 104     \u001b[0m | \u001b[0m 0.9562  \u001b[0m | \u001b[0m 430.0   \u001b[0m | \u001b[0m 19.32   \u001b[0m | \u001b[0m 5.48    \u001b[0m |\n",
      "| \u001b[0m 105     \u001b[0m | \u001b[0m 0.9562  \u001b[0m | \u001b[0m 311.8   \u001b[0m | \u001b[0m 17.38   \u001b[0m | \u001b[0m 5.5     \u001b[0m |\n",
      "| \u001b[0m 106     \u001b[0m | \u001b[0m 0.9433  \u001b[0m | \u001b[0m 180.8   \u001b[0m | \u001b[0m 12.57   \u001b[0m | \u001b[0m 2.001   \u001b[0m |\n",
      "| \u001b[0m 107     \u001b[0m | \u001b[0m 0.9562  \u001b[0m | \u001b[0m 356.6   \u001b[0m | \u001b[0m 19.86   \u001b[0m | \u001b[0m 2.072   \u001b[0m |\n",
      "| \u001b[0m 108     \u001b[0m | \u001b[0m 0.9464  \u001b[0m | \u001b[0m 248.5   \u001b[0m | \u001b[0m 13.51   \u001b[0m | \u001b[0m 2.055   \u001b[0m |\n",
      "| \u001b[0m 109     \u001b[0m | \u001b[0m 0.9562  \u001b[0m | \u001b[0m 184.2   \u001b[0m | \u001b[0m 19.99   \u001b[0m | \u001b[0m 5.335   \u001b[0m |\n",
      "| \u001b[0m 110     \u001b[0m | \u001b[0m 0.9562  \u001b[0m | \u001b[0m 27.75   \u001b[0m | \u001b[0m 19.86   \u001b[0m | \u001b[0m 5.372   \u001b[0m |\n",
      "| \u001b[0m 111     \u001b[0m | \u001b[0m 0.9562  \u001b[0m | \u001b[0m 226.1   \u001b[0m | \u001b[0m 19.88   \u001b[0m | \u001b[0m 2.056   \u001b[0m |\n",
      "| \u001b[0m 112     \u001b[0m | \u001b[0m 0.9562  \u001b[0m | \u001b[0m 92.91   \u001b[0m | \u001b[0m 19.7    \u001b[0m | \u001b[0m 5.455   \u001b[0m |\n",
      "| \u001b[0m 113     \u001b[0m | \u001b[0m 0.937   \u001b[0m | \u001b[0m 261.0   \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 5.48    \u001b[0m |\n",
      "| \u001b[0m 114     \u001b[0m | \u001b[0m 0.9489  \u001b[0m | \u001b[0m 435.3   \u001b[0m | \u001b[0m 15.4    \u001b[0m | \u001b[0m 2.044   \u001b[0m |\n",
      "| \u001b[0m 115     \u001b[0m | \u001b[0m 0.9562  \u001b[0m | \u001b[0m 253.1   \u001b[0m | \u001b[0m 19.91   \u001b[0m | \u001b[0m 2.019   \u001b[0m |\n",
      "| \u001b[0m 116     \u001b[0m | \u001b[0m 0.9464  \u001b[0m | \u001b[0m 448.8   \u001b[0m | \u001b[0m 13.64   \u001b[0m | \u001b[0m 2.072   \u001b[0m |\n",
      "| \u001b[0m 117     \u001b[0m | \u001b[0m 0.9562  \u001b[0m | \u001b[0m 465.0   \u001b[0m | \u001b[0m 19.79   \u001b[0m | \u001b[0m 2.315   \u001b[0m |\n",
      "| \u001b[0m 118     \u001b[0m | \u001b[0m 0.9533  \u001b[0m | \u001b[0m 418.4   \u001b[0m | \u001b[0m 14.98   \u001b[0m | \u001b[0m 5.495   \u001b[0m |\n",
      "| \u001b[0m 119     \u001b[0m | \u001b[0m 0.9562  \u001b[0m | \u001b[0m 464.1   \u001b[0m | \u001b[0m 19.77   \u001b[0m | \u001b[0m 5.455   \u001b[0m |\n",
      "| \u001b[0m 120     \u001b[0m | \u001b[0m 0.9562  \u001b[0m | \u001b[0m 131.0   \u001b[0m | \u001b[0m 19.95   \u001b[0m | \u001b[0m 5.397   \u001b[0m |\n",
      "| \u001b[0m 121     \u001b[0m | \u001b[0m 0.9557  \u001b[0m | \u001b[0m 119.1   \u001b[0m | \u001b[0m 14.23   \u001b[0m | \u001b[0m 2.065   \u001b[0m |\n",
      "| \u001b[0m 122     \u001b[0m | \u001b[0m 0.9562  \u001b[0m | \u001b[0m 151.2   \u001b[0m | \u001b[0m 18.73   \u001b[0m | \u001b[0m 5.49    \u001b[0m |\n",
      "| \u001b[0m 123     \u001b[0m | \u001b[0m 0.9562  \u001b[0m | \u001b[0m 299.9   \u001b[0m | \u001b[0m 19.81   \u001b[0m | \u001b[0m 5.415   \u001b[0m |\n",
      "| \u001b[0m 124     \u001b[0m | \u001b[0m 0.9489  \u001b[0m | \u001b[0m 385.6   \u001b[0m | \u001b[0m 16.65   \u001b[0m | \u001b[0m 2.045   \u001b[0m |\n",
      "| \u001b[0m 125     \u001b[0m | \u001b[0m 0.9533  \u001b[0m | \u001b[0m 211.6   \u001b[0m | \u001b[0m 14.8    \u001b[0m | \u001b[0m 5.452   \u001b[0m |\n",
      "| \u001b[0m 126     \u001b[0m | \u001b[0m 0.9562  \u001b[0m | \u001b[0m 45.71   \u001b[0m | \u001b[0m 19.51   \u001b[0m | \u001b[0m 5.494   \u001b[0m |\n",
      "| \u001b[0m 127     \u001b[0m | \u001b[0m 0.9562  \u001b[0m | \u001b[0m 367.6   \u001b[0m | \u001b[0m 19.5    \u001b[0m | \u001b[0m 2.073   \u001b[0m |\n",
      "| \u001b[0m 128     \u001b[0m | \u001b[0m 0.9562  \u001b[0m | \u001b[0m 181.2   \u001b[0m | \u001b[0m 19.83   \u001b[0m | \u001b[0m 2.057   \u001b[0m |\n",
      "| \u001b[0m 129     \u001b[0m | \u001b[0m 0.9562  \u001b[0m | \u001b[0m 289.4   \u001b[0m | \u001b[0m 19.86   \u001b[0m | \u001b[0m 2.025   \u001b[0m |\n",
      "| \u001b[0m 130     \u001b[0m | \u001b[0m 0.9562  \u001b[0m | \u001b[0m 160.1   \u001b[0m | \u001b[0m 19.78   \u001b[0m | \u001b[0m 2.064   \u001b[0m |\n",
      "| \u001b[0m 131     \u001b[0m | \u001b[0m 0.9458  \u001b[0m | \u001b[0m 218.3   \u001b[0m | \u001b[0m 15.66   \u001b[0m | \u001b[0m 2.128   \u001b[0m |\n",
      "| \u001b[0m 132     \u001b[0m | \u001b[0m 0.9562  \u001b[0m | \u001b[0m 167.3   \u001b[0m | \u001b[0m 19.86   \u001b[0m | \u001b[0m 5.456   \u001b[0m |\n",
      "| \u001b[0m 133     \u001b[0m | \u001b[0m 0.9562  \u001b[0m | \u001b[0m 231.8   \u001b[0m | \u001b[0m 18.85   \u001b[0m | \u001b[0m 5.491   \u001b[0m |\n",
      "| \u001b[0m 134     \u001b[0m | \u001b[0m 0.9562  \u001b[0m | \u001b[0m 327.6   \u001b[0m | \u001b[0m 18.34   \u001b[0m | \u001b[0m 2.008   \u001b[0m |\n",
      "| \u001b[0m 135     \u001b[0m | \u001b[0m 0.9562  \u001b[0m | \u001b[0m 344.4   \u001b[0m | \u001b[0m 18.28   \u001b[0m | \u001b[0m 2.022   \u001b[0m |\n",
      "| \u001b[0m 136     \u001b[0m | \u001b[0m 0.958   \u001b[0m | \u001b[0m 442.4   \u001b[0m | \u001b[0m 17.0    \u001b[0m | \u001b[0m 5.493   \u001b[0m |\n",
      "| \u001b[0m 137     \u001b[0m | \u001b[0m 0.9562  \u001b[0m | \u001b[0m 402.6   \u001b[0m | \u001b[0m 18.63   \u001b[0m | \u001b[0m 5.448   \u001b[0m |\n",
      "| \u001b[0m 138     \u001b[0m | \u001b[0m 0.9533  \u001b[0m | \u001b[0m 19.32   \u001b[0m | \u001b[0m 15.85   \u001b[0m | \u001b[0m 5.471   \u001b[0m |\n",
      "| \u001b[0m 139     \u001b[0m | \u001b[0m 0.9562  \u001b[0m | \u001b[0m 288.5   \u001b[0m | \u001b[0m 20.0    \u001b[0m | \u001b[0m 5.5     \u001b[0m |\n",
      "| \u001b[0m 140     \u001b[0m | \u001b[0m 0.9562  \u001b[0m | \u001b[0m 273.1   \u001b[0m | \u001b[0m 19.42   \u001b[0m | \u001b[0m 2.107   \u001b[0m |\n",
      "| \u001b[0m 141     \u001b[0m | \u001b[0m 0.937   \u001b[0m | \u001b[0m 191.2   \u001b[0m | \u001b[0m 15.51   \u001b[0m | \u001b[0m 5.477   \u001b[0m |\n",
      "| \u001b[0m 142     \u001b[0m | \u001b[0m 0.9446  \u001b[0m | \u001b[0m 205.7   \u001b[0m | \u001b[0m 16.03   \u001b[0m | \u001b[0m 2.132   \u001b[0m |\n",
      "| \u001b[0m 143     \u001b[0m | \u001b[0m 0.9562  \u001b[0m | \u001b[0m 190.8   \u001b[0m | \u001b[0m 19.76   \u001b[0m | \u001b[0m 2.035   \u001b[0m |\n",
      "| \u001b[0m 144     \u001b[0m | \u001b[0m 0.8007  \u001b[0m | \u001b[0m 111.8   \u001b[0m | \u001b[0m 2.864   \u001b[0m | \u001b[0m 2.029   \u001b[0m |\n",
      "| \u001b[0m 145     \u001b[0m | \u001b[0m 0.9562  \u001b[0m | \u001b[0m 208.9   \u001b[0m | \u001b[0m 19.93   \u001b[0m | \u001b[0m 5.452   \u001b[0m |\n",
      "| \u001b[0m 146     \u001b[0m | \u001b[0m 0.8016  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 2.0     \u001b[0m |\n",
      "| \u001b[0m 147     \u001b[0m | \u001b[0m 0.9439  \u001b[0m | \u001b[0m 495.8   \u001b[0m | \u001b[0m 13.52   \u001b[0m | \u001b[0m 5.248   \u001b[0m |\n",
      "| \u001b[0m 148     \u001b[0m | \u001b[0m 0.9562  \u001b[0m | \u001b[0m 108.0   \u001b[0m | \u001b[0m 19.26   \u001b[0m | \u001b[0m 5.5     \u001b[0m |\n",
      "| \u001b[0m 149     \u001b[0m | \u001b[0m 0.9562  \u001b[0m | \u001b[0m 49.36   \u001b[0m | \u001b[0m 19.87   \u001b[0m | \u001b[0m 2.059   \u001b[0m |\n",
      "| \u001b[0m 150     \u001b[0m | \u001b[0m 0.9562  \u001b[0m | \u001b[0m 68.0    \u001b[0m | \u001b[0m 19.65   \u001b[0m | \u001b[0m 5.49    \u001b[0m |\n",
      "| \u001b[0m 151     \u001b[0m | \u001b[0m 0.9562  \u001b[0m | \u001b[0m 408.5   \u001b[0m | \u001b[0m 19.79   \u001b[0m | \u001b[0m 2.272   \u001b[0m |\n",
      "| \u001b[0m 152     \u001b[0m | \u001b[0m 0.9562  \u001b[0m | \u001b[0m 116.1   \u001b[0m | \u001b[0m 19.61   \u001b[0m | \u001b[0m 2.086   \u001b[0m |\n",
      "| \u001b[0m 153     \u001b[0m | \u001b[0m 0.9533  \u001b[0m | \u001b[0m 321.4   \u001b[0m | \u001b[0m 14.94   \u001b[0m | \u001b[0m 5.486   \u001b[0m |\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[0;34m(self, init_points, n_iter, acq, kappa, xi, **gp_params)\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m                 \u001b[0mx_probe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Queue is empty, no more objects to retrieve.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStopIteration\u001b[0m: Queue is empty, no more objects to retrieve.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-183-163be2a1b625>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moptimization_logistic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBayesianOptimization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluateLogistic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_logistic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m231\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moptimization_logistic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[0;34m(self, init_points, n_iter, acq, kappa, xi, **gp_params)\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0mx_probe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m                 \u001b[0mx_probe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m                 \u001b[0miteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36msuggest\u001b[0;34m(self, utility_function)\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0my_max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0mbounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_random_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         )\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/bayes_opt/util.py\u001b[0m in \u001b[0;36macq_max\u001b[0;34m(ac, gp, y_max, bounds, random_state, n_warmup, n_iter)\u001b[0m\n\u001b[1;32m     56\u001b[0m                        \u001b[0mx_try\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                        \u001b[0mbounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                        method=\"L-BFGS-B\")\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# See if success\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0;32m--> 601\u001b[0;31m                                 callback=callback, **options)\n\u001b[0m\u001b[1;32m    602\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tnc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m         return _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mjac\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_approx_fprime_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/bayes_opt/util.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx_try\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx_seeds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;31m# Find the minimum of minus the acquisition function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         res = minimize(lambda x: -ac(x.reshape(1, -1), gp=gp, y_max=y_max),\n\u001b[0m\u001b[1;32m     56\u001b[0m                        \u001b[0mx_try\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                        \u001b[0mbounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/bayes_opt/util.py\u001b[0m in \u001b[0;36mutility\u001b[0;34m(self, x, gp, y_max)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mutility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'ucb'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ucb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkappa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'ei'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ei\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/bayes_opt/util.py\u001b[0m in \u001b[0;36m_ucb\u001b[0;34m(x, gp, kappa)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_warnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_std\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmean\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mkappa\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, return_std, return_cov)\u001b[0m\n\u001b[1;32m    330\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0my_mean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Predict based on GP posterior\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m             \u001b[0mK_trans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m             \u001b[0my_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK_trans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha_\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Line 4 (y_mean = f_star)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0my_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y_train_mean\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my_mean\u001b[0m  \u001b[0;31m# undo normal.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/kernels.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, X, Y, eval_gradient)\u001b[0m\n\u001b[1;32m   1337\u001b[0m                     \"Gradient can only be evaluated when Y is None.\")\n\u001b[1;32m   1338\u001b[0m             dists = cdist(X / length_scale, Y / length_scale,\n\u001b[0;32m-> 1339\u001b[0;31m                           metric='euclidean')\n\u001b[0m\u001b[1;32m   1340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnu\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/spatial/distance.py\u001b[0m in \u001b[0;36mcdist\u001b[0;34m(XA, XB, metric, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2755\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmetric_name\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2756\u001b[0m             XA, XB, typ, kwargs = _validate_cdist_input(XA, XB, mA, mB, n,\n\u001b[0;32m-> 2757\u001b[0;31m                                                         metric_name, **kwargs)\n\u001b[0m\u001b[1;32m   2758\u001b[0m             \u001b[0;31m# get cdist wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2759\u001b[0m             cdist_fn = getattr(_distance_wrap,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/spatial/distance.py\u001b[0m in \u001b[0;36m_validate_cdist_input\u001b[0;34m(XA, XB, mA, mB, n, metric_name, **kwargs)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;31m# validate data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mXA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_to_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0mXB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_to_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;31m# validate kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimization_logistic = BayesianOptimization(evaluateLogistic, params_logistic, random_state=231)\n",
    "optimization_logistic.maximize(n_iter=200, init_points=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': 340.0, 'params': {'C': 617.4371992275123, 'k': 8.026182029526707}}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimization_logistic.max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show results of best performing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_from_model = Pipeline([\n",
    "    ('feature_selection', SelectFromModel(estimator=RandomForestClassifier(max_depth=2,\n",
    "                                                                           n_estimators=300, random_state=231,\n",
    "                                                                           class_weight='balanced'),\n",
    "                                             max_features=17,\n",
    "                                             threshold=-np.inf)),\n",
    "        ('classification', LogisticRegression(C=187.9, solver='liblinear', random_state=42)),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "330"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(cross_validate(select_from_model,\n",
    "                   \n",
    "                   X_train_trust1_prepared,\n",
    "                   y=y_train_trust1,\n",
    "                   cv=cv,\n",
    "                   scoring=profit_scoring)['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "#..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
