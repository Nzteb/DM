{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of pipeline steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FeatureGenerationPipeline:**\n",
    "- CustomAttributeAdder(feature_list=['feature1', 'feature2', 'feature3', etc.]):\n",
    "- RandomAttributeAdder(stratgey=['multiply', 'add', 'substract', 'divide']):\n",
    "\n",
    "**PreprocessingPipeline:**\n",
    "- Imputer???\n",
    "- RandomAttributeTransformer(strategy=['sqaure', 'log', 'sqrt'])\n",
    "- Balancing(stratgey=['up', 'down', 'other', 'none'])\n",
    "- Scaling(strategy=['Standard', 'MinMax', 'None'])\n",
    "\n",
    "**ModelSelectionPipeline:**\n",
    "- ModelSelector\n",
    "- CrossValidation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# classifiers\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# use sklearn pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# custom imports\n",
    "from funcs import plot_cv_confidence_vs_profit, score_dmc_profit,dmc_profit,cv_preds_and_confusion_matrix\n",
    "from customClassifiers import CustomModelWithThreshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trustLevel</th>\n",
       "      <th>totalScanTimeInSeconds</th>\n",
       "      <th>grandTotal</th>\n",
       "      <th>lineItemVoids</th>\n",
       "      <th>scansWithoutRegistration</th>\n",
       "      <th>quantityModifications</th>\n",
       "      <th>scannedLineItemsPerSecond</th>\n",
       "      <th>valuePerSecond</th>\n",
       "      <th>lineItemVoidsPerPosition</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>4</td>\n",
       "      <td>477</td>\n",
       "      <td>1.36</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.044025</td>\n",
       "      <td>0.002851</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>6</td>\n",
       "      <td>615</td>\n",
       "      <td>96.76</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.030894</td>\n",
       "      <td>0.157333</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>2</td>\n",
       "      <td>810</td>\n",
       "      <td>22.50</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.013580</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      trustLevel  totalScanTimeInSeconds  grandTotal  lineItemVoids  \\\n",
       "110            4                     477        1.36             10   \n",
       "622            6                     615       96.76              4   \n",
       "1208           2                     810       22.50              9   \n",
       "\n",
       "      scansWithoutRegistration  quantityModifications  \\\n",
       "110                          1                      1   \n",
       "622                          8                      3   \n",
       "1208                         7                      3   \n",
       "\n",
       "      scannedLineItemsPerSecond  valuePerSecond  lineItemVoidsPerPosition  \\\n",
       "110                    0.044025        0.002851                  0.476190   \n",
       "622                    0.030894        0.157333                  0.210526   \n",
       "1208                   0.013580        0.027778                  0.818182   \n",
       "\n",
       "      fraud  \n",
       "110       0  \n",
       "622       0  \n",
       "1208      0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('train.csv', sep='|')\n",
    "df_test = pd.read_csv('test.csv', sep='|')\n",
    "\n",
    "df_train.head()\n",
    "df_train.tail()\n",
    "df_train.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trustLevel</th>\n",
       "      <th>totalScanTimeInSeconds</th>\n",
       "      <th>grandTotal</th>\n",
       "      <th>lineItemVoids</th>\n",
       "      <th>scansWithoutRegistration</th>\n",
       "      <th>quantityModifications</th>\n",
       "      <th>scannedLineItemsPerSecond</th>\n",
       "      <th>valuePerSecond</th>\n",
       "      <th>lineItemVoidsPerPosition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1054</td>\n",
       "      <td>54.70</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.027514</td>\n",
       "      <td>0.051898</td>\n",
       "      <td>0.241379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>108</td>\n",
       "      <td>27.36</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.129630</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.357143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1516</td>\n",
       "      <td>62.16</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.008575</td>\n",
       "      <td>0.041003</td>\n",
       "      <td>0.230769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>1791</td>\n",
       "      <td>92.31</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.016192</td>\n",
       "      <td>0.051541</td>\n",
       "      <td>0.275862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>430</td>\n",
       "      <td>81.53</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.062791</td>\n",
       "      <td>0.189605</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   trustLevel  totalScanTimeInSeconds  grandTotal  lineItemVoids  \\\n",
       "0           5                    1054       54.70              7   \n",
       "1           3                     108       27.36              5   \n",
       "2           3                    1516       62.16              3   \n",
       "3           6                    1791       92.31              8   \n",
       "4           5                     430       81.53              3   \n",
       "\n",
       "   scansWithoutRegistration  quantityModifications  scannedLineItemsPerSecond  \\\n",
       "0                         0                      3                   0.027514   \n",
       "1                         2                      4                   0.129630   \n",
       "2                        10                      5                   0.008575   \n",
       "3                         4                      4                   0.016192   \n",
       "4                         7                      2                   0.062791   \n",
       "\n",
       "   valuePerSecond  lineItemVoidsPerPosition  \n",
       "0        0.051898                  0.241379  \n",
       "1        0.253333                  0.357143  \n",
       "2        0.041003                  0.230769  \n",
       "3        0.051541                  0.275862  \n",
       "4        0.189605                  0.111111  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split label and predictors\n",
    "X_train, y_train = df_train.drop(columns=['fraud',]), df_train['fraud']\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 FeatureGeneration Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling class\n",
    "class Scaling(TransformerMixin):\n",
    "    \n",
    "    _strategy = \"Standard\"\n",
    "    _scaler = None\n",
    "    \n",
    "    def __init__(self, strategy):\n",
    "        self._strategy = strategy\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        if self._strategy == \"Standard\":\n",
    "            self._scaler = StandardScaler()\n",
    "            return self._scaler.fit(X)\n",
    "        elif self._strategy == \"MinMax\":\n",
    "            self._scaler = MinMaxScaler()\n",
    "            return self._scaler.fit(X)\n",
    "        elif self._strategy == \"None\":\n",
    "            return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \n",
    "        if self._strategy == \"None\":\n",
    "            return X\n",
    "        else:\n",
    "            return self._scaler.transform(X)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom attribute adder\n",
    "class CustomAttributeAdder(TransformerMixin):\n",
    "    \n",
    "    _featureList = ['scannedLineItemsTotal', 'valuePerLineItem', 'quantityModificationsPerLineItem']\n",
    "    \n",
    "    def __init__(self, feature_list = ['scannedLineItemsTotal',\n",
    "                                       'valuePerLineItem',\n",
    "                                       'quantityModificationsPerLineItem']):\n",
    "        self.__featurelist = feature_list\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \n",
    "        X['scannedLineItemsTotal'] = X['scannedLineItemsPerSecond'] * X['totalScanTimeInSeconds']\n",
    "            \n",
    "        if \"valuePerLineItem\" in self._featureList:\n",
    "            X['valuePerLineItem'] = X['grandTotal'] / X['scannedLineItemsTotal']\n",
    "            \n",
    "        if \"quantityModificationsPerLineItem\" in self._featureList:\n",
    "            X['quantityModificationsPerLineItem'] = X['quantityModifications'] / X['scannedLineItemsTotal']\n",
    "            \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom attribute adder\n",
    "class RandomAttributeAdder(TransformerMixin):\n",
    "    \n",
    "    \"\"\"This class is still empty and needs to be filled!\"\"\"\n",
    "    \n",
    "    def __init__(self,):\n",
    "        pass\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):    \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# featureGeneration pipeline \n",
    "# all transform methods should return a pd.DataFrame\n",
    "\n",
    "featureGeneration_pipeline = Pipeline([\n",
    "    (\"attribs_adder\", CustomAttributeAdder()),    # returns pd.dataframe\n",
    "    (\"RandomAttributeAdder\", RandomAttributeAdder())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(TransformerMixin):\n",
    "    \n",
    "    \"\"\"This class is still empty and needs to be filled!\"\"\"\n",
    "    \n",
    "    def __init__(self,):\n",
    "        pass\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):    \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Balancing(TransformerMixin):\n",
    "    \n",
    "    \"\"\"This class is still empty and needs to be filled!\"\"\"\n",
    "    \n",
    "    def __init__(self,):\n",
    "        pass\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):    \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling class\n",
    "class Scaling(TransformerMixin):\n",
    "    \n",
    "    _strategy = \"Standard\"\n",
    "    _scaler = None\n",
    "    \n",
    "    def __init__(self, strategy):\n",
    "        self._strategy = strategy\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        if self._strategy == \"Standard\":\n",
    "            self._scaler = StandardScaler()\n",
    "            return self._scaler.fit(X)\n",
    "        elif self._strategy == \"MinMax\":\n",
    "            self._scaler = MinMaxScaler()\n",
    "            return self._scaler.fit(X)\n",
    "        elif self._strategy == \"None\":\n",
    "            return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \n",
    "        if self._strategy == \"None\":\n",
    "            return X\n",
    "        else:\n",
    "            return self._scaler.transform(X)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this pipeline, we are working with np.array\n",
    "\n",
    "preprocessing_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")),   # This step is actually not needed\n",
    "    (\"transformer\", Transformer()),                # This class is still void\n",
    "    (\"balancing\", Balancing()),                    # This class is still void\n",
    "    (\"scaler\", Scaling(strategy='Standard')),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Model Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "class ClfSwitcher(BaseEstimator):\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        estimator = SGDClassifier()\n",
    "    ):\n",
    "        \"\"\"\n",
    "        A Custom BaseEstimator that can switch between classifiers.\n",
    "        :param estimator: sklearn object - The classifier\n",
    "        \"\"\" \n",
    "\n",
    "        self.estimator = estimator\n",
    "\n",
    "\n",
    "    def fit(self, X, y=None, **kwargs):\n",
    "        self.estimator.fit(X, y)\n",
    "        return self\n",
    "\n",
    "\n",
    "    def predict(self, X, y=None):\n",
    "        return self.estimator.predict(X)\n",
    "\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.estimator.predict_proba(X)\n",
    "\n",
    "\n",
    "    def score(self, X, y):\n",
    "        return self.estimator.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_training_pipeline = Pipeline([\n",
    "    ('feature_generation', featureGeneration_pipeline),\n",
    "    ('preprocessing', preprocessing_pipeline),\n",
    "    ('classifier', ClfSwitcher())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [\n",
    "    {\n",
    "        'classifier__estimator': [SGDClassifier()],\n",
    "        'classifier__estimator__penalty': ('l2', 'elasticnet', 'l1'),\n",
    "        'classifier__estimator__max_iter': [50, 80],\n",
    "        'classifier__estimator__tol': [1e-4],\n",
    "        'classifier__estimator__loss': ['hinge', 'log', 'modified_huber']\n",
    "    },\n",
    "    {\n",
    "        'classifier__estimator': [XGBClassifier()],\n",
    "        'classifier__estimator__n_estimators': [50, 100, 150],\n",
    "        'classifier__estimator__reg_alpha': [0, 0.05, 0.1]\n",
    "    },\n",
    "    {\n",
    "        'classifier__estimator': [RandomForestClassifier()],\n",
    "        'classifier__estimator__min_samples_split': [2, 4, 6],\n",
    "        'classifier__estimator__criterion': ['gini', 'entropy']\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Full Pipeline Usage Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=10, random_state=42)\n",
    "\n",
    "def profit_scorer(y, y_pred):\n",
    "    profit_matrix = {(0,0): 0, (0,1): -5, (1,0): -25, (1,1): 5}\n",
    "    return sum(profit_matrix[(pred, actual)] for pred, actual in zip(y_pred, y))\n",
    "\n",
    "profit_scoring = make_scorer(profit_scorer, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 33 candidates, totalling 330 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:   18.8s\n",
      "[Parallel(n_jobs=-1)]: Done 330 out of 330 | elapsed:   21.7s finished\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('feature_generation', Pipeline(memory=None,\n",
       "     steps=[('attribs_adder', <__main__.CustomAttributeAdder object at 0x1a1a1c47f0>), ('RandomAttributeAdder', <__main__.RandomAttributeAdder object at 0x1a1a1c46a0>)])), ('preprocessing', Pipeline(memory=None,\n",
       "     steps=[('imputer', SimpleImpute..._state=None, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False)))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid=[{'classifier__estimator': [SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=80,\n",
       "       n_iter=None, n_iter_no_change=5, n_jobs=None, ..._estimator__min_samples_split': [2, 4, 6], 'classifier__estimator__criterion': ['gini', 'entropy']}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=make_scorer(profit_scorer), verbose=3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv = GridSearchCV(model_training_pipeline, parameters, cv=10, n_jobs=-1, scoring=profit_scoring, verbose=3)\n",
    "gscv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.49175093134646"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__estimator': SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "        early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "        l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=80,\n",
       "        n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "        power_t=0.5, random_state=None, shuffle=True, tol=0.0001,\n",
       "        validation_fraction=0.1, verbose=0, warm_start=False),\n",
       " 'classifier__estimator__loss': 'hinge',\n",
       " 'classifier__estimator__max_iter': 80,\n",
       " 'classifier__estimator__penalty': 'l2',\n",
       " 'classifier__estimator__tol': 0.0001}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature_generation': Pipeline(memory=None,\n",
       "      steps=[('attribs_adder', <__main__.CustomAttributeAdder object at 0x1a1bd606d8>), ('RandomAttributeAdder', <__main__.RandomAttributeAdder object at 0x1065d3c18>)]),\n",
       " 'preprocessing': Pipeline(memory=None,\n",
       "      steps=[('imputer', SimpleImputer(copy=True, fill_value=None, missing_values=nan, strategy='mean',\n",
       "        verbose=0)), ('transformer', <__main__.Transformer object at 0x1065bae80>), ('balancing', <__main__.Balancing object at 0x1065a2518>), ('scaler', <__main__.Scaling object at 0x1065bc1d0>)]),\n",
       " 'classifier': ClfSwitcher(estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "        early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "        l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=80,\n",
       "        n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "        power_t=0.5, random_state=None, shuffle=True, tol=0.0001,\n",
       "        validation_fraction=0.1, verbose=0, warm_start=False))}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv.best_estimator_.named_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-Validation (training on balanced, validation on unbalanced dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_imbalanced(classifier, X, y, sampler):\n",
    "    kf = StratifiedKFold(n_splits=10, random_state=42)\n",
    "    cross_val_profit_lst = []\n",
    "    \n",
    "    X = pd.DataFrame(X)\n",
    "\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        # keeping validation set apart and oversampling in each iteration using smote \n",
    "        train, test = X.iloc[train_index], X.iloc[test_index]\n",
    "        target_train, target_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        X_train_res, y_train_res = sampler.fit_sample(train, target_train.ravel())\n",
    "\n",
    "        # training the model on oversampled 4 folds of training set\n",
    "#         classifier.fit(train, target_train)\n",
    "        classifier.fit(pd.DataFrame(X_train_res), y_train_res)\n",
    "        # testing on 1 fold of validation set\n",
    "        test_preds = classifier.predict(test)\n",
    "        cross_val_profit_lst.append(profit_scorer(target_test, test_preds))\n",
    "        \n",
    "#     print ('Cross validated profit: {}'.format(np.sum(cross_val_profit_lst)))\n",
    "    return np.sum(cross_val_profit_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-40"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_preparation_pipeline = Pipeline([\n",
    "    ('feature_generation', featureGeneration_pipeline),\n",
    "    ('preprocessing', preprocessing_pipeline)\n",
    "])\n",
    "\n",
    "X_train_prepared = data_preparation_pipeline.fit_transform(X_train)\n",
    "\n",
    "cross_val_imbalanced(RandomForestClassifier(n_estimators=100, random_state=42), \n",
    "                     X_train_prepared, y_train, SMOTE(random_state=42))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the library for Bayesian optimization from here: https://github.com/fmfn/BayesianOptimization\n",
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preparation_pipeline = Pipeline([\n",
    "    ('feature_generation', featureGeneration_pipeline),\n",
    "    ('preprocessing', preprocessing_pipeline)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_prepared = data_preparation_pipeline.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomForest(n_estimators, max_depth, min_samples_split, min_samples_leaf):\n",
    "    \n",
    "    model = RandomForestClassifier(n_estimators=int(n_estimators), \n",
    "                                   max_depth=int(max_depth), \n",
    "                                   min_samples_split=int(min_samples_split), \n",
    "                                   min_samples_leaf=int(min_samples_leaf),\n",
    "                                   random_state=231)\n",
    "    \n",
    "    return cross_val_imbalanced(model, X_train_prepared, y_train, SMOTE(random_state=42))\n",
    "    \n",
    "#     cv_results = cross_val_score(model, X_train_prepared, y_train, cv=10, scoring=profit_scoring)\n",
    "    \n",
    "#     return np.mean(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_random_forest = {\n",
    "    'n_estimators': (25, 500),\n",
    "    'max_depth': (1, 10),\n",
    "    'min_samples_split': (2, 20),\n",
    "    'min_samples_leaf': (1, 20)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | max_depth | min_sa... | min_sa... | n_esti... |\n",
      "-------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-350.0   \u001b[0m | \u001b[0m 8.033   \u001b[0m | \u001b[0m 12.1    \u001b[0m | \u001b[0m 9.681   \u001b[0m | \u001b[0m 174.8   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-400.0   \u001b[0m | \u001b[0m 8.442   \u001b[0m | \u001b[0m 18.17   \u001b[0m | \u001b[0m 2.701   \u001b[0m | \u001b[0m 459.7   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-1.595e+0\u001b[0m | \u001b[0m 1.545   \u001b[0m | \u001b[0m 4.434   \u001b[0m | \u001b[0m 3.301   \u001b[0m | \u001b[0m 242.9   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-385.0   \u001b[0m | \u001b[0m 7.375   \u001b[0m | \u001b[0m 10.18   \u001b[0m | \u001b[0m 2.458   \u001b[0m | \u001b[0m 56.78   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-505.0   \u001b[0m | \u001b[0m 4.833   \u001b[0m | \u001b[0m 5.166   \u001b[0m | \u001b[0m 16.58   \u001b[0m | \u001b[0m 91.53   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-350.0   \u001b[0m | \u001b[0m 8.072   \u001b[0m | \u001b[0m 12.14   \u001b[0m | \u001b[0m 9.72    \u001b[0m | \u001b[0m 174.4   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-350.0   \u001b[0m | \u001b[0m 8.119   \u001b[0m | \u001b[0m 12.21   \u001b[0m | \u001b[0m 9.76    \u001b[0m | \u001b[0m 174.6   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-420.0   \u001b[0m | \u001b[0m 7.975   \u001b[0m | \u001b[0m 12.12   \u001b[0m | \u001b[0m 9.544   \u001b[0m | \u001b[0m 174.6   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-400.0   \u001b[0m | \u001b[0m 7.645   \u001b[0m | \u001b[0m 18.01   \u001b[0m | \u001b[0m 2.919   \u001b[0m | \u001b[0m 459.5   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-350.0   \u001b[0m | \u001b[0m 8.869   \u001b[0m | \u001b[0m 12.36   \u001b[0m | \u001b[0m 9.958   \u001b[0m | \u001b[0m 174.0   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-420.0   \u001b[0m | \u001b[0m 7.71    \u001b[0m | \u001b[0m 12.31   \u001b[0m | \u001b[0m 9.926   \u001b[0m | \u001b[0m 174.9   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-350.0   \u001b[0m | \u001b[0m 9.089   \u001b[0m | \u001b[0m 12.45   \u001b[0m | \u001b[0m 10.01   \u001b[0m | \u001b[0m 174.1   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-385.0   \u001b[0m | \u001b[0m 7.373   \u001b[0m | \u001b[0m 10.18   \u001b[0m | \u001b[0m 2.454   \u001b[0m | \u001b[0m 56.78   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-435.0   \u001b[0m | \u001b[0m 8.263   \u001b[0m | \u001b[0m 17.99   \u001b[0m | \u001b[0m 2.716   \u001b[0m | \u001b[0m 460.3   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-350.0   \u001b[0m | \u001b[0m 8.9     \u001b[0m | \u001b[0m 12.89   \u001b[0m | \u001b[0m 9.635   \u001b[0m | \u001b[0m 173.9   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-410.0   \u001b[0m | \u001b[0m 7.465   \u001b[0m | \u001b[0m 17.76   \u001b[0m | \u001b[0m 2.043   \u001b[0m | \u001b[0m 459.8   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-435.0   \u001b[0m | \u001b[0m 8.082   \u001b[0m | \u001b[0m 17.89   \u001b[0m | \u001b[0m 2.728   \u001b[0m | \u001b[0m 460.1   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-410.0   \u001b[0m | \u001b[0m 7.505   \u001b[0m | \u001b[0m 17.71   \u001b[0m | \u001b[0m 2.224   \u001b[0m | \u001b[0m 459.5   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-350.0   \u001b[0m | \u001b[0m 9.1     \u001b[0m | \u001b[0m 12.16   \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 173.3   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-350.0   \u001b[0m | \u001b[0m 8.122   \u001b[0m | \u001b[0m 12.43   \u001b[0m | \u001b[0m 9.545   \u001b[0m | \u001b[0m 174.3   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m-350.0   \u001b[0m | \u001b[0m 9.197   \u001b[0m | \u001b[0m 12.38   \u001b[0m | \u001b[0m 10.08   \u001b[0m | \u001b[0m 173.3   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-350.0   \u001b[0m | \u001b[0m 8.981   \u001b[0m | \u001b[0m 12.5    \u001b[0m | \u001b[0m 9.914   \u001b[0m | \u001b[0m 173.9   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-350.0   \u001b[0m | \u001b[0m 9.078   \u001b[0m | \u001b[0m 12.29   \u001b[0m | \u001b[0m 10.51   \u001b[0m | \u001b[0m 172.5   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-400.0   \u001b[0m | \u001b[0m 7.782   \u001b[0m | \u001b[0m 18.17   \u001b[0m | \u001b[0m 2.08    \u001b[0m | \u001b[0m 459.1   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-350.0   \u001b[0m | \u001b[0m 9.08    \u001b[0m | \u001b[0m 12.29   \u001b[0m | \u001b[0m 10.5    \u001b[0m | \u001b[0m 172.6   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m-350.0   \u001b[0m | \u001b[0m 9.384   \u001b[0m | \u001b[0m 12.06   \u001b[0m | \u001b[0m 10.39   \u001b[0m | \u001b[0m 172.9   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m-410.0   \u001b[0m | \u001b[0m 7.506   \u001b[0m | \u001b[0m 17.33   \u001b[0m | \u001b[0m 2.568   \u001b[0m | \u001b[0m 459.6   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m-395.0   \u001b[0m | \u001b[0m 9.309   \u001b[0m | \u001b[0m 13.53   \u001b[0m | \u001b[0m 8.826   \u001b[0m | \u001b[0m 173.8   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m-350.0   \u001b[0m | \u001b[0m 9.304   \u001b[0m | \u001b[0m 12.13   \u001b[0m | \u001b[0m 10.35   \u001b[0m | \u001b[0m 172.9   \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m-395.0   \u001b[0m | \u001b[0m 9.297   \u001b[0m | \u001b[0m 13.51   \u001b[0m | \u001b[0m 8.851   \u001b[0m | \u001b[0m 173.8   \u001b[0m |\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/bayes_opt/target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: (7.771655038797601, 18.149166893458176, 2.1115058228200425, 459.1499955406986)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-c80282b8a89e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moptimization\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBayesianOptimization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluateRandomForest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_random_forest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m231\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moptimization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[0;34m(self, init_points, n_iter, acq, kappa, xi, **gp_params)\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0miteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_probe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlazy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOPTMIZATION_END\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mprobe\u001b[0;34m(self, params, lazy)\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOPTMIZATION_STEP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/bayes_opt/target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-43-9d4cdd8cb973>\u001b[0m in \u001b[0;36mevaluateRandomForest\u001b[0;34m(n_estimators, max_depth, min_samples_split, min_samples_leaf)\u001b[0m\n\u001b[1;32m      7\u001b[0m                                    random_state=231)\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcross_val_imbalanced\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_prepared\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#     cv_results = cross_val_score(model, X_train_prepared, y_train, cv=10, scoring=profit_scoring)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-9763ab06b9c7>\u001b[0m in \u001b[0;36mcross_val_imbalanced\u001b[0;34m(classifier, X, y, sampler)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# training the model on oversampled 4 folds of training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#         classifier.fit(train, target_train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_res\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;31m# testing on 1 fold of validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mtest_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    331\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 333\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    799\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 801\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    802\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    364\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimization = BayesianOptimization(evaluateRandomForest, params_random_forest, random_state=231)\n",
    "optimization.maximize(n_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': 60.0,\n",
       " 'params': {'max_depth': 7.588495835164709,\n",
       "  'min_samples_leaf': 11.259814622879999,\n",
       "  'min_samples_split': 3.981682006813868,\n",
       "  'n_estimators': 55.181217441016784}}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimization.max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateSgd(alpha, l1_ratio, tol, penalty, loss):\n",
    "    \n",
    "    # 3 options, l1 by default\n",
    "    penalty_str = 'l1'\n",
    "    if int(penalty) == 0:\n",
    "        penalty_str = 'l2'\n",
    "    elif int(penalty) == 1:\n",
    "        penalty_str = 'elasticnet'\n",
    "    \n",
    "    # 3 options, modified_huber by default\n",
    "    loss_str = 'modified_huber'\n",
    "    if int(loss) == 0:\n",
    "        loss_str = 'hinge'\n",
    "    elif int(loss) == 1:\n",
    "        loss_str = 'log'\n",
    "        \n",
    "    \n",
    "    model = SGDClassifier(alpha=alpha, l1_ratio=l1_ratio, tol=tol, penalty=penalty_str, loss=loss_str, random_state=231)\n",
    "    \n",
    "    \n",
    "    return cross_val_imbalanced(model, X_train_prepared, y_train, SMOTE(random_state=42))\n",
    "\n",
    "#     cv_results = cross_val_score(model, X_train_prepared, y_train, cv=10, scoring=profit_scoring)\n",
    "    \n",
    "#     return np.mean(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_sgd = {\n",
    "    'alpha': (1e-6, 1),\n",
    "    'l1_ratio': (0, 1),\n",
    "    'tol': (1e-9, 1e-1),\n",
    "    'penalty': (0, 3),\n",
    "    'loss': (0, 3)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |   alpha   | l1_ratio  |   loss    |  penalty  |    tol    |\n",
      "-------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-7.98e+03\u001b[0m | \u001b[0m 0.7815  \u001b[0m | \u001b[0m 0.5842  \u001b[0m | \u001b[0m 1.28    \u001b[0m | \u001b[0m 0.946   \u001b[0m | \u001b[0m 0.08269 \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m-5.255e+0\u001b[0m | \u001b[95m 0.9034  \u001b[0m | \u001b[95m 0.03894 \u001b[0m | \u001b[95m 2.746   \u001b[0m | \u001b[95m 0.1815  \u001b[0m | \u001b[95m 0.01807 \u001b[0m |\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m-855.0   \u001b[0m | \u001b[95m 0.0723  \u001b[0m | \u001b[95m 0.4588  \u001b[0m | \u001b[95m 2.125   \u001b[0m | \u001b[95m 1.45    \u001b[0m | \u001b[95m 0.002545\u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-3.93e+03\u001b[0m | \u001b[0m 0.0669  \u001b[0m | \u001b[0m 0.4259  \u001b[0m | \u001b[0m 0.6577  \u001b[0m | \u001b[0m 2.43    \u001b[0m | \u001b[0m 0.01401 \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-6.58e+03\u001b[0m | \u001b[0m 0.7512  \u001b[0m | \u001b[0m 0.2791  \u001b[0m | \u001b[0m 2.847   \u001b[0m | \u001b[0m 2.655   \u001b[0m | \u001b[0m 0.06102 \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-5.655e+0\u001b[0m | \u001b[0m 0.7949  \u001b[0m | \u001b[0m 0.1375  \u001b[0m | \u001b[0m 2.891   \u001b[0m | \u001b[0m 1.398   \u001b[0m | \u001b[0m 0.02334 \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-6.905e+0\u001b[0m | \u001b[0m 0.2285  \u001b[0m | \u001b[0m 0.659   \u001b[0m | \u001b[0m 1.156   \u001b[0m | \u001b[0m 2.647   \u001b[0m | \u001b[0m 0.03248 \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-9.83e+03\u001b[0m | \u001b[0m 0.262   \u001b[0m | \u001b[0m 0.1225  \u001b[0m | \u001b[0m 1.663   \u001b[0m | \u001b[0m 2.001   \u001b[0m | \u001b[0m 0.03901 \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-7.03e+03\u001b[0m | \u001b[0m 0.6054  \u001b[0m | \u001b[0m 0.8215  \u001b[0m | \u001b[0m 1.169   \u001b[0m | \u001b[0m 0.7796  \u001b[0m | \u001b[0m 0.04115 \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-855.0   \u001b[0m | \u001b[0m 0.07219 \u001b[0m | \u001b[0m 0.459   \u001b[0m | \u001b[0m 2.125   \u001b[0m | \u001b[0m 1.449   \u001b[0m | \u001b[0m 0.002523\u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-855.0   \u001b[0m | \u001b[0m 0.07215 \u001b[0m | \u001b[0m 0.459   \u001b[0m | \u001b[0m 2.125   \u001b[0m | \u001b[0m 1.449   \u001b[0m | \u001b[0m 0.002517\u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-855.0   \u001b[0m | \u001b[0m 0.07213 \u001b[0m | \u001b[0m 0.4591  \u001b[0m | \u001b[0m 2.126   \u001b[0m | \u001b[0m 1.449   \u001b[0m | \u001b[0m 0.002529\u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-855.0   \u001b[0m | \u001b[0m 0.07177 \u001b[0m | \u001b[0m 0.4592  \u001b[0m | \u001b[0m 2.126   \u001b[0m | \u001b[0m 1.449   \u001b[0m | \u001b[0m 0.002387\u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-855.0   \u001b[0m | \u001b[0m 0.07243 \u001b[0m | \u001b[0m 0.4592  \u001b[0m | \u001b[0m 2.126   \u001b[0m | \u001b[0m 1.449   \u001b[0m | \u001b[0m 0.00272 \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-855.0   \u001b[0m | \u001b[0m 0.07169 \u001b[0m | \u001b[0m 0.4593  \u001b[0m | \u001b[0m 2.126   \u001b[0m | \u001b[0m 1.449   \u001b[0m | \u001b[0m 0.002376\u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-855.0   \u001b[0m | \u001b[0m 0.07162 \u001b[0m | \u001b[0m 0.46    \u001b[0m | \u001b[0m 2.127   \u001b[0m | \u001b[0m 1.45    \u001b[0m | \u001b[0m 0.002652\u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-855.0   \u001b[0m | \u001b[0m 0.07151 \u001b[0m | \u001b[0m 0.4595  \u001b[0m | \u001b[0m 2.126   \u001b[0m | \u001b[0m 1.449   \u001b[0m | \u001b[0m 0.002479\u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-855.0   \u001b[0m | \u001b[0m 0.07227 \u001b[0m | \u001b[0m 0.4609  \u001b[0m | \u001b[0m 2.126   \u001b[0m | \u001b[0m 1.448   \u001b[0m | \u001b[0m 0.002045\u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-855.0   \u001b[0m | \u001b[0m 0.07132 \u001b[0m | \u001b[0m 0.4597  \u001b[0m | \u001b[0m 2.126   \u001b[0m | \u001b[0m 1.448   \u001b[0m | \u001b[0m 0.0026  \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-855.0   \u001b[0m | \u001b[0m 0.07213 \u001b[0m | \u001b[0m 0.4591  \u001b[0m | \u001b[0m 2.127   \u001b[0m | \u001b[0m 1.448   \u001b[0m | \u001b[0m 0.000220\u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m-855.0   \u001b[0m | \u001b[0m 0.07175 \u001b[0m | \u001b[0m 0.4595  \u001b[0m | \u001b[0m 2.127   \u001b[0m | \u001b[0m 1.448   \u001b[0m | \u001b[0m 0.001725\u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-855.0   \u001b[0m | \u001b[0m 0.07108 \u001b[0m | \u001b[0m 0.4598  \u001b[0m | \u001b[0m 2.126   \u001b[0m | \u001b[0m 1.448   \u001b[0m | \u001b[0m 0.001728\u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-855.0   \u001b[0m | \u001b[0m 0.07195 \u001b[0m | \u001b[0m 0.4596  \u001b[0m | \u001b[0m 2.127   \u001b[0m | \u001b[0m 1.448   \u001b[0m | \u001b[0m 0.002594\u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-855.0   \u001b[0m | \u001b[0m 0.07092 \u001b[0m | \u001b[0m 0.46    \u001b[0m | \u001b[0m 2.126   \u001b[0m | \u001b[0m 1.448   \u001b[0m | \u001b[0m 0.001885\u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-855.0   \u001b[0m | \u001b[0m 0.07147 \u001b[0m | \u001b[0m 0.4596  \u001b[0m | \u001b[0m 2.127   \u001b[0m | \u001b[0m 1.448   \u001b[0m | \u001b[0m 0.002565\u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m-855.0   \u001b[0m | \u001b[0m 0.07099 \u001b[0m | \u001b[0m 0.4598  \u001b[0m | \u001b[0m 2.126   \u001b[0m | \u001b[0m 1.448   \u001b[0m | \u001b[0m 0.002214\u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m-855.0   \u001b[0m | \u001b[0m 0.07144 \u001b[0m | \u001b[0m 0.4599  \u001b[0m | \u001b[0m 2.127   \u001b[0m | \u001b[0m 1.448   \u001b[0m | \u001b[0m 0.002461\u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m-855.0   \u001b[0m | \u001b[0m 0.0708  \u001b[0m | \u001b[0m 0.4595  \u001b[0m | \u001b[0m 2.127   \u001b[0m | \u001b[0m 1.448   \u001b[0m | \u001b[0m 0.002308\u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m-855.0   \u001b[0m | \u001b[0m 0.07107 \u001b[0m | \u001b[0m 0.46    \u001b[0m | \u001b[0m 2.127   \u001b[0m | \u001b[0m 1.449   \u001b[0m | \u001b[0m 0.001777\u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m-855.0   \u001b[0m | \u001b[0m 0.0712  \u001b[0m | \u001b[0m 0.4598  \u001b[0m | \u001b[0m 2.126   \u001b[0m | \u001b[0m 1.448   \u001b[0m | \u001b[0m 0.002554\u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m-855.0   \u001b[0m | \u001b[0m 0.072   \u001b[0m | \u001b[0m 0.4606  \u001b[0m | \u001b[0m 2.127   \u001b[0m | \u001b[0m 1.449   \u001b[0m | \u001b[0m 0.002192\u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m-855.0   \u001b[0m | \u001b[0m 0.07163 \u001b[0m | \u001b[0m 0.46    \u001b[0m | \u001b[0m 2.127   \u001b[0m | \u001b[0m 1.448   \u001b[0m | \u001b[0m 0.001483\u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m-855.0   \u001b[0m | \u001b[0m 0.07076 \u001b[0m | \u001b[0m 0.46    \u001b[0m | \u001b[0m 2.126   \u001b[0m | \u001b[0m 1.448   \u001b[0m | \u001b[0m 0.002346\u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m-855.0   \u001b[0m | \u001b[0m 0.07104 \u001b[0m | \u001b[0m 0.4596  \u001b[0m | \u001b[0m 2.126   \u001b[0m | \u001b[0m 1.448   \u001b[0m | \u001b[0m 0.002301\u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m-855.0   \u001b[0m | \u001b[0m 0.07103 \u001b[0m | \u001b[0m 0.4596  \u001b[0m | \u001b[0m 2.127   \u001b[0m | \u001b[0m 1.448   \u001b[0m | \u001b[0m 0.002543\u001b[0m |\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m-855.0   \u001b[0m | \u001b[0m 0.07113 \u001b[0m | \u001b[0m 0.4596  \u001b[0m | \u001b[0m 2.127   \u001b[0m | \u001b[0m 1.449   \u001b[0m | \u001b[0m 0.001228\u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m-855.0   \u001b[0m | \u001b[0m 0.07157 \u001b[0m | \u001b[0m 0.4606  \u001b[0m | \u001b[0m 2.127   \u001b[0m | \u001b[0m 1.448   \u001b[0m | \u001b[0m 0.00201 \u001b[0m |\n",
      "| \u001b[95m 38      \u001b[0m | \u001b[95m-755.0   \u001b[0m | \u001b[95m 0.06975 \u001b[0m | \u001b[95m 0.461   \u001b[0m | \u001b[95m 2.127   \u001b[0m | \u001b[95m 1.447   \u001b[0m | \u001b[95m 0.0019  \u001b[0m |\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m-2.205e+0\u001b[0m | \u001b[0m 0.1087  \u001b[0m | \u001b[0m 0.429   \u001b[0m | \u001b[0m 2.136   \u001b[0m | \u001b[0m 1.485   \u001b[0m | \u001b[0m 0.03614 \u001b[0m |\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m-1.355e+0\u001b[0m | \u001b[0m 0.08513 \u001b[0m | \u001b[0m 0.4533  \u001b[0m | \u001b[0m 2.124   \u001b[0m | \u001b[0m 1.405   \u001b[0m | \u001b[0m 0.05392 \u001b[0m |\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m-955.0   \u001b[0m | \u001b[0m 0.07131 \u001b[0m | \u001b[0m 0.4124  \u001b[0m | \u001b[0m 2.108   \u001b[0m | \u001b[0m 1.445   \u001b[0m | \u001b[0m 0.00552 \u001b[0m |\n",
      "| \u001b[95m 42      \u001b[0m | \u001b[95m-15.0    \u001b[0m | \u001b[95m 0.02567 \u001b[0m | \u001b[95m 0.4484  \u001b[0m | \u001b[95m 2.125   \u001b[0m | \u001b[95m 1.457   \u001b[0m | \u001b[95m 0.03711 \u001b[0m |\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m-2.73e+03\u001b[0m | \u001b[0m 0.1305  \u001b[0m | \u001b[0m 0.4173  \u001b[0m | \u001b[0m 2.088   \u001b[0m | \u001b[0m 1.448   \u001b[0m | \u001b[0m 0.000479\u001b[0m |\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m-430.0   \u001b[0m | \u001b[0m 0.04698 \u001b[0m | \u001b[0m 0.4657  \u001b[0m | \u001b[0m 2.095   \u001b[0m | \u001b[0m 1.409   \u001b[0m | \u001b[0m 0.05083 \u001b[0m |\n",
      "| \u001b[0m 45      \u001b[0m | \u001b[0m-405.0   \u001b[0m | \u001b[0m 0.05087 \u001b[0m | \u001b[0m 0.4688  \u001b[0m | \u001b[0m 2.143   \u001b[0m | \u001b[0m 1.389   \u001b[0m | \u001b[0m 0.09792 \u001b[0m |\n",
      "| \u001b[95m 46      \u001b[0m | \u001b[95m 210.0   \u001b[0m | \u001b[95m 0.01543 \u001b[0m | \u001b[95m 0.4933  \u001b[0m | \u001b[95m 2.132   \u001b[0m | \u001b[95m 1.373   \u001b[0m | \u001b[95m 0.06043 \u001b[0m |\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m-65.0    \u001b[0m | \u001b[0m 0.03236 \u001b[0m | \u001b[0m 0.5243  \u001b[0m | \u001b[0m 2.06    \u001b[0m | \u001b[0m 1.422   \u001b[0m | \u001b[0m 0.07377 \u001b[0m |\n",
      "| \u001b[95m 48      \u001b[0m | \u001b[95m 260.0   \u001b[0m | \u001b[95m 0.01739 \u001b[0m | \u001b[95m 0.5639  \u001b[0m | \u001b[95m 2.042   \u001b[0m | \u001b[95m 1.434   \u001b[0m | \u001b[95m 0.05178 \u001b[0m |\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m-1.805e+0\u001b[0m | \u001b[0m 0.1011  \u001b[0m | \u001b[0m 0.466   \u001b[0m | \u001b[0m 2.171   \u001b[0m | \u001b[0m 1.416   \u001b[0m | \u001b[0m 0.02991 \u001b[0m |\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m 60.0    \u001b[0m | \u001b[0m 0.02446 \u001b[0m | \u001b[0m 0.5149  \u001b[0m | \u001b[0m 2.086   \u001b[0m | \u001b[0m 1.435   \u001b[0m | \u001b[0m 0.07869 \u001b[0m |\n",
      "| \u001b[0m 51      \u001b[0m | \u001b[0m 210.0   \u001b[0m | \u001b[0m 0.0155  \u001b[0m | \u001b[0m 0.434   \u001b[0m | \u001b[0m 2.146   \u001b[0m | \u001b[0m 1.43    \u001b[0m | \u001b[0m 0.001742\u001b[0m |\n",
      "| \u001b[95m 52      \u001b[0m | \u001b[95m 280.0   \u001b[0m | \u001b[95m 0.01127 \u001b[0m | \u001b[95m 0.4634  \u001b[0m | \u001b[95m 2.076   \u001b[0m | \u001b[95m 1.458   \u001b[0m | \u001b[95m 0.02994 \u001b[0m |\n",
      "| \u001b[0m 53      \u001b[0m | \u001b[0m-1.68e+03\u001b[0m | \u001b[0m 0.09636 \u001b[0m | \u001b[0m 0.4529  \u001b[0m | \u001b[0m 2.093   \u001b[0m | \u001b[0m 1.449   \u001b[0m | \u001b[0m 0.006357\u001b[0m |\n",
      "| \u001b[0m 54      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 0.004852\u001b[0m | \u001b[0m 0.5213  \u001b[0m | \u001b[0m 2.059   \u001b[0m | \u001b[0m 1.48    \u001b[0m | \u001b[0m 0.02663 \u001b[0m |\n",
      "| \u001b[0m 55      \u001b[0m | \u001b[0m-555.0   \u001b[0m | \u001b[0m 0.06783 \u001b[0m | \u001b[0m 0.5049  \u001b[0m | \u001b[0m 2.115   \u001b[0m | \u001b[0m 1.424   \u001b[0m | \u001b[0m 0.01853 \u001b[0m |\n",
      "| \u001b[0m 56      \u001b[0m | \u001b[0m-530.0   \u001b[0m | \u001b[0m 0.06292 \u001b[0m | \u001b[0m 0.5042  \u001b[0m | \u001b[0m 2.1     \u001b[0m | \u001b[0m 1.486   \u001b[0m | \u001b[0m 0.02144 \u001b[0m |\n",
      "| \u001b[0m 57      \u001b[0m | \u001b[0m-780.0   \u001b[0m | \u001b[0m 0.0715  \u001b[0m | \u001b[0m 0.4822  \u001b[0m | \u001b[0m 2.076   \u001b[0m | \u001b[0m 1.399   \u001b[0m | \u001b[0m 0.06974 \u001b[0m |\n",
      "| \u001b[0m 58      \u001b[0m | \u001b[0m-330.0   \u001b[0m | \u001b[0m 0.03834 \u001b[0m | \u001b[0m 0.4431  \u001b[0m | \u001b[0m 2.135   \u001b[0m | \u001b[0m 1.449   \u001b[0m | \u001b[0m 0.004307\u001b[0m |\n",
      "| \u001b[0m 59      \u001b[0m | \u001b[0m-15.0    \u001b[0m | \u001b[0m 0.03054 \u001b[0m | \u001b[0m 0.5804  \u001b[0m | \u001b[0m 2.03    \u001b[0m | \u001b[0m 1.424   \u001b[0m | \u001b[0m 0.03792 \u001b[0m |\n",
      "| \u001b[0m 60      \u001b[0m | \u001b[0m 185.0   \u001b[0m | \u001b[0m 0.02088 \u001b[0m | \u001b[0m 0.5712  \u001b[0m | \u001b[0m 2.055   \u001b[0m | \u001b[0m 1.456   \u001b[0m | \u001b[0m 0.04396 \u001b[0m |\n",
      "| \u001b[0m 61      \u001b[0m | \u001b[0m-315.0   \u001b[0m | \u001b[0m 0.0401  \u001b[0m | \u001b[0m 0.4723  \u001b[0m | \u001b[0m 2.092   \u001b[0m | \u001b[0m 1.489   \u001b[0m | \u001b[0m 0.02824 \u001b[0m |\n",
      "| \u001b[0m 62      \u001b[0m | \u001b[0m-480.0   \u001b[0m | \u001b[0m 0.05518 \u001b[0m | \u001b[0m 0.479   \u001b[0m | \u001b[0m 2.118   \u001b[0m | \u001b[0m 1.458   \u001b[0m | \u001b[0m 0.008986\u001b[0m |\n",
      "| \u001b[0m 63      \u001b[0m | \u001b[0m 255.0   \u001b[0m | \u001b[0m 0.002179\u001b[0m | \u001b[0m 0.5435  \u001b[0m | \u001b[0m 2.037   \u001b[0m | \u001b[0m 1.41    \u001b[0m | \u001b[0m 0.09325 \u001b[0m |\n",
      "| \u001b[0m 64      \u001b[0m | \u001b[0m-430.0   \u001b[0m | \u001b[0m 0.04112 \u001b[0m | \u001b[0m 0.415   \u001b[0m | \u001b[0m 2.139   \u001b[0m | \u001b[0m 1.441   \u001b[0m | \u001b[0m 0.06586 \u001b[0m |\n",
      "| \u001b[0m 65      \u001b[0m | \u001b[0m-380.0   \u001b[0m | \u001b[0m 0.04453 \u001b[0m | \u001b[0m 0.4683  \u001b[0m | \u001b[0m 2.096   \u001b[0m | \u001b[0m 1.462   \u001b[0m | \u001b[0m 0.0924  \u001b[0m |\n",
      "| \u001b[0m 66      \u001b[0m | \u001b[0m-365.0   \u001b[0m | \u001b[0m 0.04563 \u001b[0m | \u001b[0m 0.4972  \u001b[0m | \u001b[0m 2.115   \u001b[0m | \u001b[0m 1.438   \u001b[0m | \u001b[0m 0.09725 \u001b[0m |\n",
      "| \u001b[0m 67      \u001b[0m | \u001b[0m-1.23e+03\u001b[0m | \u001b[0m 0.07975 \u001b[0m | \u001b[0m 0.4225  \u001b[0m | \u001b[0m 2.139   \u001b[0m | \u001b[0m 1.41    \u001b[0m | \u001b[0m 0.04616 \u001b[0m |\n",
      "| \u001b[0m 68      \u001b[0m | \u001b[0m-505.0   \u001b[0m | \u001b[0m 0.05369 \u001b[0m | \u001b[0m 0.4443  \u001b[0m | \u001b[0m 2.115   \u001b[0m | \u001b[0m 1.481   \u001b[0m | \u001b[0m 0.01843 \u001b[0m |\n",
      "| \u001b[0m 69      \u001b[0m | \u001b[0m-265.0   \u001b[0m | \u001b[0m 0.0412  \u001b[0m | \u001b[0m 0.5255  \u001b[0m | \u001b[0m 2.069   \u001b[0m | \u001b[0m 1.41    \u001b[0m | \u001b[0m 0.05629 \u001b[0m |\n",
      "| \u001b[0m 70      \u001b[0m | \u001b[0m-215.0   \u001b[0m | \u001b[0m 0.03706 \u001b[0m | \u001b[0m 0.4847  \u001b[0m | \u001b[0m 2.15    \u001b[0m | \u001b[0m 1.38    \u001b[0m | \u001b[0m 0.09059 \u001b[0m |\n",
      "| \u001b[0m 71      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 0.000717\u001b[0m | \u001b[0m 0.5833  \u001b[0m | \u001b[0m 2.026   \u001b[0m | \u001b[0m 1.466   \u001b[0m | \u001b[0m 0.06331 \u001b[0m |\n",
      "| \u001b[0m 72      \u001b[0m | \u001b[0m 160.0   \u001b[0m | \u001b[0m 0.0176  \u001b[0m | \u001b[0m 0.5029  \u001b[0m | \u001b[0m 2.137   \u001b[0m | \u001b[0m 1.377   \u001b[0m | \u001b[0m 0.06006 \u001b[0m |\n",
      "| \u001b[0m 73      \u001b[0m | \u001b[0m-1.33e+03\u001b[0m | \u001b[0m 0.09278 \u001b[0m | \u001b[0m 0.5457  \u001b[0m | \u001b[0m 2.059   \u001b[0m | \u001b[0m 1.431   \u001b[0m | \u001b[0m 0.04809 \u001b[0m |\n",
      "| \u001b[0m 74      \u001b[0m | \u001b[0m-455.0   \u001b[0m | \u001b[0m 0.05727 \u001b[0m | \u001b[0m 0.515   \u001b[0m | \u001b[0m 2.074   \u001b[0m | \u001b[0m 1.407   \u001b[0m | \u001b[0m 0.003448\u001b[0m |\n",
      "| \u001b[0m 75      \u001b[0m | \u001b[0m-215.0   \u001b[0m | \u001b[0m 0.03421 \u001b[0m | \u001b[0m 0.4755  \u001b[0m | \u001b[0m 2.06    \u001b[0m | \u001b[0m 1.461   \u001b[0m | \u001b[0m 0.03072 \u001b[0m |\n",
      "| \u001b[95m 76      \u001b[0m | \u001b[95m 295.0   \u001b[0m | \u001b[95m 0.004877\u001b[0m | \u001b[95m 0.464   \u001b[0m | \u001b[95m 2.133   \u001b[0m | \u001b[95m 1.44    \u001b[0m | \u001b[95m 0.02444 \u001b[0m |\n",
      "| \u001b[0m 77      \u001b[0m | \u001b[0m-605.0   \u001b[0m | \u001b[0m 0.06448 \u001b[0m | \u001b[0m 0.4886  \u001b[0m | \u001b[0m 2.054   \u001b[0m | \u001b[0m 1.376   \u001b[0m | \u001b[0m 0.07124 \u001b[0m |\n",
      "| \u001b[0m 78      \u001b[0m | \u001b[0m 295.0   \u001b[0m | \u001b[0m 0.009437\u001b[0m | \u001b[0m 0.5116  \u001b[0m | \u001b[0m 2.166   \u001b[0m | \u001b[0m 1.374   \u001b[0m | \u001b[0m 0.06402 \u001b[0m |\n",
      "| \u001b[0m 79      \u001b[0m | \u001b[0m-380.0   \u001b[0m | \u001b[0m 0.0417  \u001b[0m | \u001b[0m 0.4438  \u001b[0m | \u001b[0m 2.055   \u001b[0m | \u001b[0m 1.487   \u001b[0m | \u001b[0m 0.02449 \u001b[0m |\n",
      "| \u001b[0m 80      \u001b[0m | \u001b[0m-265.0   \u001b[0m | \u001b[0m 0.05153 \u001b[0m | \u001b[0m 0.59    \u001b[0m | \u001b[0m 2.069   \u001b[0m | \u001b[0m 1.385   \u001b[0m | \u001b[0m 0.05256 \u001b[0m |\n",
      "| \u001b[0m 81      \u001b[0m | \u001b[0m-430.0   \u001b[0m | \u001b[0m 0.05618 \u001b[0m | \u001b[0m 0.5264  \u001b[0m | \u001b[0m 2.062   \u001b[0m | \u001b[0m 1.37    \u001b[0m | \u001b[0m 0.08539 \u001b[0m |\n",
      "| \u001b[0m 82      \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 0.02557 \u001b[0m | \u001b[0m 0.5016  \u001b[0m | \u001b[0m 2.104   \u001b[0m | \u001b[0m 1.346   \u001b[0m | \u001b[0m 0.0686  \u001b[0m |\n",
      "| \u001b[0m 83      \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 0.02623 \u001b[0m | \u001b[0m 0.4969  \u001b[0m | \u001b[0m 2.044   \u001b[0m | \u001b[0m 1.445   \u001b[0m | \u001b[0m 0.0176  \u001b[0m |\n",
      "| \u001b[0m 84      \u001b[0m | \u001b[0m-1.005e+0\u001b[0m | \u001b[0m 0.08021 \u001b[0m | \u001b[0m 0.4912  \u001b[0m | \u001b[0m 2.085   \u001b[0m | \u001b[0m 1.512   \u001b[0m | \u001b[0m 0.02562 \u001b[0m |\n",
      "| \u001b[0m 85      \u001b[0m | \u001b[0m-605.0   \u001b[0m | \u001b[0m 0.0664  \u001b[0m | \u001b[0m 0.4904  \u001b[0m | \u001b[0m 2.01    \u001b[0m | \u001b[0m 1.375   \u001b[0m | \u001b[0m 0.06927 \u001b[0m |\n",
      "| \u001b[0m 86      \u001b[0m | \u001b[0m-440.0   \u001b[0m | \u001b[0m 0.05727 \u001b[0m | \u001b[0m 0.539   \u001b[0m | \u001b[0m 2.058   \u001b[0m | \u001b[0m 1.395   \u001b[0m | \u001b[0m 0.01477 \u001b[0m |\n",
      "| \u001b[0m 87      \u001b[0m | \u001b[0m-480.0   \u001b[0m | \u001b[0m 0.0507  \u001b[0m | \u001b[0m 0.4988  \u001b[0m | \u001b[0m 2.133   \u001b[0m | \u001b[0m 1.447   \u001b[0m | \u001b[0m 0.0768  \u001b[0m |\n",
      "| \u001b[0m 88      \u001b[0m | \u001b[0m 185.0   \u001b[0m | \u001b[0m 0.01724 \u001b[0m | \u001b[0m 0.5205  \u001b[0m | \u001b[0m 2.057   \u001b[0m | \u001b[0m 1.417   \u001b[0m | \u001b[0m 0.07173 \u001b[0m |\n",
      "| \u001b[0m 89      \u001b[0m | \u001b[0m-580.0   \u001b[0m | \u001b[0m 0.06159 \u001b[0m | \u001b[0m 0.4474  \u001b[0m | \u001b[0m 2.089   \u001b[0m | \u001b[0m 1.473   \u001b[0m | \u001b[0m 0.06588 \u001b[0m |\n",
      "| \u001b[0m 90      \u001b[0m | \u001b[0m 135.0   \u001b[0m | \u001b[0m 0.01859 \u001b[0m | \u001b[0m 0.526   \u001b[0m | \u001b[0m 2.173   \u001b[0m | \u001b[0m 1.364   \u001b[0m | \u001b[0m 0.04049 \u001b[0m |\n",
      "| \u001b[0m 91      \u001b[0m | \u001b[0m 290.0   \u001b[0m | \u001b[0m 0.01354 \u001b[0m | \u001b[0m 0.5592  \u001b[0m | \u001b[0m 2.051   \u001b[0m | \u001b[0m 1.426   \u001b[0m | \u001b[0m 0.07528 \u001b[0m |\n",
      "| \u001b[0m 92      \u001b[0m | \u001b[0m-365.0   \u001b[0m | \u001b[0m 0.05108 \u001b[0m | \u001b[0m 0.5332  \u001b[0m | \u001b[0m 2.068   \u001b[0m | \u001b[0m 1.381   \u001b[0m | \u001b[0m 0.09011 \u001b[0m |\n",
      "| \u001b[0m 93      \u001b[0m | \u001b[0m 35.0    \u001b[0m | \u001b[0m 0.02374 \u001b[0m | \u001b[0m 0.4703  \u001b[0m | \u001b[0m 2.114   \u001b[0m | \u001b[0m 1.364   \u001b[0m | \u001b[0m 0.08055 \u001b[0m |\n",
      "| \u001b[0m 94      \u001b[0m | \u001b[0m 135.0   \u001b[0m | \u001b[0m 0.02222 \u001b[0m | \u001b[0m 0.5297  \u001b[0m | \u001b[0m 2.071   \u001b[0m | \u001b[0m 1.396   \u001b[0m | \u001b[0m 0.05609 \u001b[0m |\n",
      "| \u001b[0m 95      \u001b[0m | \u001b[0m-805.0   \u001b[0m | \u001b[0m 0.07437 \u001b[0m | \u001b[0m 0.4969  \u001b[0m | \u001b[0m 2.038   \u001b[0m | \u001b[0m 1.397   \u001b[0m | \u001b[0m 0.03126 \u001b[0m |\n",
      "| \u001b[0m 96      \u001b[0m | \u001b[0m 280.0   \u001b[0m | \u001b[0m 0.01091 \u001b[0m | \u001b[0m 0.5433  \u001b[0m | \u001b[0m 2.08    \u001b[0m | \u001b[0m 1.429   \u001b[0m | \u001b[0m 0.03107 \u001b[0m |\n",
      "| \u001b[0m 97      \u001b[0m | \u001b[0m-355.0   \u001b[0m | \u001b[0m 0.04348 \u001b[0m | \u001b[0m 0.4706  \u001b[0m | \u001b[0m 2.13    \u001b[0m | \u001b[0m 1.455   \u001b[0m | \u001b[0m 0.02686 \u001b[0m |\n",
      "| \u001b[0m 98      \u001b[0m | \u001b[0m-440.0   \u001b[0m | \u001b[0m 0.06014 \u001b[0m | \u001b[0m 0.5413  \u001b[0m | \u001b[0m 2.073   \u001b[0m | \u001b[0m 1.37    \u001b[0m | \u001b[0m 0.01936 \u001b[0m |\n",
      "| \u001b[0m 99      \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 0.02461 \u001b[0m | \u001b[0m 0.4827  \u001b[0m | \u001b[0m 2.067   \u001b[0m | \u001b[0m 1.382   \u001b[0m | \u001b[0m 0.08981 \u001b[0m |\n",
      "| \u001b[0m 100     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 0.0256  \u001b[0m | \u001b[0m 0.5037  \u001b[0m | \u001b[0m 2.106   \u001b[0m | \u001b[0m 1.408   \u001b[0m | \u001b[0m 0.04715 \u001b[0m |\n",
      "| \u001b[0m 101     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 0.000745\u001b[0m | \u001b[0m 0.4664  \u001b[0m | \u001b[0m 2.101   \u001b[0m | \u001b[0m 1.45    \u001b[0m | \u001b[0m 0.04808 \u001b[0m |\n",
      "| \u001b[0m 102     \u001b[0m | \u001b[0m-215.0   \u001b[0m | \u001b[0m 0.03847 \u001b[0m | \u001b[0m 0.487   \u001b[0m | \u001b[0m 2.078   \u001b[0m | \u001b[0m 1.48    \u001b[0m | \u001b[0m 0.03981 \u001b[0m |\n",
      "| \u001b[0m 103     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 0.01368 \u001b[0m | \u001b[0m 0.5586  \u001b[0m | \u001b[0m 2.05    \u001b[0m | \u001b[0m 1.426   \u001b[0m | \u001b[0m 0.07382 \u001b[0m |\n",
      "| \u001b[0m 104     \u001b[0m | \u001b[0m-405.0   \u001b[0m | \u001b[0m 0.04494 \u001b[0m | \u001b[0m 0.4639  \u001b[0m | \u001b[0m 2.092   \u001b[0m | \u001b[0m 1.452   \u001b[0m | \u001b[0m 0.08894 \u001b[0m |\n",
      "| \u001b[0m 105     \u001b[0m | \u001b[0m-65.0    \u001b[0m | \u001b[0m 0.03064 \u001b[0m | \u001b[0m 0.4747  \u001b[0m | \u001b[0m 2.063   \u001b[0m | \u001b[0m 1.462   \u001b[0m | \u001b[0m 0.03067 \u001b[0m |\n",
      "| \u001b[0m 106     \u001b[0m | \u001b[0m-730.0   \u001b[0m | \u001b[0m 0.07077 \u001b[0m | \u001b[0m 0.4904  \u001b[0m | \u001b[0m 2.126   \u001b[0m | \u001b[0m 1.461   \u001b[0m | \u001b[0m 0.05771 \u001b[0m |\n",
      "| \u001b[0m 107     \u001b[0m | \u001b[0m 280.0   \u001b[0m | \u001b[0m 0.0123  \u001b[0m | \u001b[0m 0.5194  \u001b[0m | \u001b[0m 2.053   \u001b[0m | \u001b[0m 1.41    \u001b[0m | \u001b[0m 0.05931 \u001b[0m |\n",
      "| \u001b[0m 108     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 0.02471 \u001b[0m | \u001b[0m 0.4829  \u001b[0m | \u001b[0m 2.067   \u001b[0m | \u001b[0m 1.382   \u001b[0m | \u001b[0m 0.08965 \u001b[0m |\n",
      "| \u001b[0m 109     \u001b[0m | \u001b[0m-290.0   \u001b[0m | \u001b[0m 0.04172 \u001b[0m | \u001b[0m 0.5146  \u001b[0m | \u001b[0m 2.101   \u001b[0m | \u001b[0m 1.416   \u001b[0m | \u001b[0m 0.0153  \u001b[0m |\n",
      "| \u001b[0m 110     \u001b[0m | \u001b[0m-65.0    \u001b[0m | \u001b[0m 0.02885 \u001b[0m | \u001b[0m 0.4893  \u001b[0m | \u001b[0m 2.14    \u001b[0m | \u001b[0m 1.389   \u001b[0m | \u001b[0m 0.08776 \u001b[0m |\n",
      "| \u001b[0m 111     \u001b[0m | \u001b[0m-430.0   \u001b[0m | \u001b[0m 0.04897 \u001b[0m | \u001b[0m 0.4939  \u001b[0m | \u001b[0m 2.11    \u001b[0m | \u001b[0m 1.461   \u001b[0m | \u001b[0m 0.07291 \u001b[0m |\n",
      "| \u001b[0m 112     \u001b[0m | \u001b[0m-215.0   \u001b[0m | \u001b[0m 0.03541 \u001b[0m | \u001b[0m 0.4825  \u001b[0m | \u001b[0m 2.11    \u001b[0m | \u001b[0m 1.429   \u001b[0m | \u001b[0m 0.06452 \u001b[0m |\n",
      "| \u001b[0m 113     \u001b[0m | \u001b[0m-390.0   \u001b[0m | \u001b[0m 0.05241 \u001b[0m | \u001b[0m 0.5447  \u001b[0m | \u001b[0m 2.091   \u001b[0m | \u001b[0m 1.404   \u001b[0m | \u001b[0m 0.09496 \u001b[0m |\n",
      "| \u001b[0m 114     \u001b[0m | \u001b[0m-440.0   \u001b[0m | \u001b[0m 0.05583 \u001b[0m | \u001b[0m 0.5387  \u001b[0m | \u001b[0m 2.116   \u001b[0m | \u001b[0m 1.4     \u001b[0m | \u001b[0m 0.08529 \u001b[0m |\n",
      "| \u001b[0m 115     \u001b[0m | \u001b[0m 235.0   \u001b[0m | \u001b[0m 0.01517 \u001b[0m | \u001b[0m 0.5146  \u001b[0m | \u001b[0m 2.105   \u001b[0m | \u001b[0m 1.418   \u001b[0m | \u001b[0m 0.02206 \u001b[0m |\n",
      "| \u001b[0m 116     \u001b[0m | \u001b[0m 135.0   \u001b[0m | \u001b[0m 0.02111 \u001b[0m | \u001b[0m 0.4516  \u001b[0m | \u001b[0m 2.067   \u001b[0m | \u001b[0m 1.426   \u001b[0m | \u001b[0m 0.01897 \u001b[0m |\n",
      "| \u001b[0m 117     \u001b[0m | \u001b[0m 135.0   \u001b[0m | \u001b[0m 0.02317 \u001b[0m | \u001b[0m 0.4919  \u001b[0m | \u001b[0m 2.019   \u001b[0m | \u001b[0m 1.42    \u001b[0m | \u001b[0m 0.05158 \u001b[0m |\n",
      "| \u001b[0m 118     \u001b[0m | \u001b[0m-555.0   \u001b[0m | \u001b[0m 0.06195 \u001b[0m | \u001b[0m 0.4803  \u001b[0m | \u001b[0m 2.142   \u001b[0m | \u001b[0m 1.344   \u001b[0m | \u001b[0m 0.06495 \u001b[0m |\n",
      "| \u001b[0m 119     \u001b[0m | \u001b[0m-365.0   \u001b[0m | \u001b[0m 0.04555 \u001b[0m | \u001b[0m 0.4939  \u001b[0m | \u001b[0m 2.068   \u001b[0m | \u001b[0m 1.42    \u001b[0m | \u001b[0m 0.04434 \u001b[0m |\n",
      "| \u001b[0m 120     \u001b[0m | \u001b[0m 160.0   \u001b[0m | \u001b[0m 0.02297 \u001b[0m | \u001b[0m 0.5725  \u001b[0m | \u001b[0m 2.051   \u001b[0m | \u001b[0m 1.434   \u001b[0m | \u001b[0m 0.01998 \u001b[0m |\n",
      "| \u001b[0m 121     \u001b[0m | \u001b[0m-480.0   \u001b[0m | \u001b[0m 0.06345 \u001b[0m | \u001b[0m 0.532   \u001b[0m | \u001b[0m 2.057   \u001b[0m | \u001b[0m 1.386   \u001b[0m | \u001b[0m 0.0266  \u001b[0m |\n",
      "| \u001b[0m 122     \u001b[0m | \u001b[0m 295.0   \u001b[0m | \u001b[0m 0.009599\u001b[0m | \u001b[0m 0.5794  \u001b[0m | \u001b[0m 2.032   \u001b[0m | \u001b[0m 1.409   \u001b[0m | \u001b[0m 0.02474 \u001b[0m |\n",
      "| \u001b[95m 123     \u001b[0m | \u001b[95m 305.0   \u001b[0m | \u001b[95m 0.005854\u001b[0m | \u001b[95m 0.4548  \u001b[0m | \u001b[95m 2.08    \u001b[0m | \u001b[95m 1.469   \u001b[0m | \u001b[95m 0.02337 \u001b[0m |\n",
      "| \u001b[0m 124     \u001b[0m | \u001b[0m-65.0    \u001b[0m | \u001b[0m 0.02843 \u001b[0m | \u001b[0m 0.502   \u001b[0m | \u001b[0m 2.087   \u001b[0m | \u001b[0m 1.462   \u001b[0m | \u001b[0m 0.09201 \u001b[0m |\n",
      "| \u001b[0m 125     \u001b[0m | \u001b[0m-455.0   \u001b[0m | \u001b[0m 0.04274 \u001b[0m | \u001b[0m 0.4243  \u001b[0m | \u001b[0m 2.134   \u001b[0m | \u001b[0m 1.447   \u001b[0m | \u001b[0m 0.08769 \u001b[0m |\n",
      "| \u001b[0m 126     \u001b[0m | \u001b[0m 305.0   \u001b[0m | \u001b[0m 0.008331\u001b[0m | \u001b[0m 0.4582  \u001b[0m | \u001b[0m 2.079   \u001b[0m | \u001b[0m 1.465   \u001b[0m | \u001b[0m 0.02608 \u001b[0m |\n",
      "| \u001b[0m 127     \u001b[0m | \u001b[0m 285.0   \u001b[0m | \u001b[0m 0.00464 \u001b[0m | \u001b[0m 0.432   \u001b[0m | \u001b[0m 2.116   \u001b[0m | \u001b[0m 1.447   \u001b[0m | \u001b[0m 0.05635 \u001b[0m |\n",
      "| \u001b[0m 128     \u001b[0m | \u001b[0m 135.0   \u001b[0m | \u001b[0m 0.02104 \u001b[0m | \u001b[0m 0.5134  \u001b[0m | \u001b[0m 2.11    \u001b[0m | \u001b[0m 1.34    \u001b[0m | \u001b[0m 0.04971 \u001b[0m |\n",
      "| \u001b[0m 129     \u001b[0m | \u001b[0m-655.0   \u001b[0m | \u001b[0m 0.06775 \u001b[0m | \u001b[0m 0.4782  \u001b[0m | \u001b[0m 2.15    \u001b[0m | \u001b[0m 1.401   \u001b[0m | \u001b[0m 0.09689 \u001b[0m |\n",
      "| \u001b[0m 130     \u001b[0m | \u001b[0m 280.0   \u001b[0m | \u001b[0m 0.01057 \u001b[0m | \u001b[0m 0.4615  \u001b[0m | \u001b[0m 2.077   \u001b[0m | \u001b[0m 1.461   \u001b[0m | \u001b[0m 0.02847 \u001b[0m |\n",
      "| \u001b[0m 131     \u001b[0m | \u001b[0m-705.0   \u001b[0m | \u001b[0m 0.06866 \u001b[0m | \u001b[0m 0.4787  \u001b[0m | \u001b[0m 2.019   \u001b[0m | \u001b[0m 1.377   \u001b[0m | \u001b[0m 0.057   \u001b[0m |\n",
      "| \u001b[0m 132     \u001b[0m | \u001b[0m-455.0   \u001b[0m | \u001b[0m 0.05625 \u001b[0m | \u001b[0m 0.5039  \u001b[0m | \u001b[0m 2.089   \u001b[0m | \u001b[0m 1.473   \u001b[0m | \u001b[0m 0.0853  \u001b[0m |\n",
      "| \u001b[0m 133     \u001b[0m | \u001b[0m-405.0   \u001b[0m | \u001b[0m 0.04904 \u001b[0m | \u001b[0m 0.4877  \u001b[0m | \u001b[0m 2.143   \u001b[0m | \u001b[0m 1.423   \u001b[0m | \u001b[0m 0.09052 \u001b[0m |\n",
      "| \u001b[0m 134     \u001b[0m | \u001b[0m-115.0   \u001b[0m | \u001b[0m 0.02824 \u001b[0m | \u001b[0m 0.4361  \u001b[0m | \u001b[0m 2.062   \u001b[0m | \u001b[0m 1.35    \u001b[0m | \u001b[0m 0.09138 \u001b[0m |\n",
      "| \u001b[0m 135     \u001b[0m | \u001b[0m-505.0   \u001b[0m | \u001b[0m 0.06535 \u001b[0m | \u001b[0m 0.5386  \u001b[0m | \u001b[0m 2.106   \u001b[0m | \u001b[0m 1.438   \u001b[0m | \u001b[0m 0.03509 \u001b[0m |\n",
      "| \u001b[0m 136     \u001b[0m | \u001b[0m-240.0   \u001b[0m | \u001b[0m 0.04411 \u001b[0m | \u001b[0m 0.5629  \u001b[0m | \u001b[0m 2.037   \u001b[0m | \u001b[0m 1.414   \u001b[0m | \u001b[0m 0.01126 \u001b[0m |\n",
      "| \u001b[0m 137     \u001b[0m | \u001b[0m 185.0   \u001b[0m | \u001b[0m 0.01652 \u001b[0m | \u001b[0m 0.4968  \u001b[0m | \u001b[0m 2.134   \u001b[0m | \u001b[0m 1.375   \u001b[0m | \u001b[0m 0.0611  \u001b[0m |\n",
      "| \u001b[0m 138     \u001b[0m | \u001b[0m 135.0   \u001b[0m | \u001b[0m 0.02147 \u001b[0m | \u001b[0m 0.512   \u001b[0m | \u001b[0m 2.11    \u001b[0m | \u001b[0m 1.341   \u001b[0m | \u001b[0m 0.05174 \u001b[0m |\n",
      "| \u001b[0m 139     \u001b[0m | \u001b[0m-65.0    \u001b[0m | \u001b[0m 0.02705 \u001b[0m | \u001b[0m 0.4538  \u001b[0m | \u001b[0m 2.034   \u001b[0m | \u001b[0m 1.447   \u001b[0m | \u001b[0m 0.04117 \u001b[0m |\n",
      "| \u001b[0m 140     \u001b[0m | \u001b[0m 280.0   \u001b[0m | \u001b[0m 0.0111  \u001b[0m | \u001b[0m 0.4626  \u001b[0m | \u001b[0m 2.076   \u001b[0m | \u001b[0m 1.459   \u001b[0m | \u001b[0m 0.02937 \u001b[0m |\n",
      "| \u001b[0m 141     \u001b[0m | \u001b[0m 160.0   \u001b[0m | \u001b[0m 0.0243  \u001b[0m | \u001b[0m 0.5508  \u001b[0m | \u001b[0m 2.111   \u001b[0m | \u001b[0m 1.423   \u001b[0m | \u001b[0m 0.01305 \u001b[0m |\n",
      "| \u001b[0m 142     \u001b[0m | \u001b[0m 135.0   \u001b[0m | \u001b[0m 0.02339 \u001b[0m | \u001b[0m 0.4994  \u001b[0m | \u001b[0m 2.141   \u001b[0m | \u001b[0m 1.386   \u001b[0m | \u001b[0m 0.04213 \u001b[0m |\n",
      "| \u001b[0m 143     \u001b[0m | \u001b[0m 305.0   \u001b[0m | \u001b[0m 0.009222\u001b[0m | \u001b[0m 0.4919  \u001b[0m | \u001b[0m 2.078   \u001b[0m | \u001b[0m 1.477   \u001b[0m | \u001b[0m 0.07599 \u001b[0m |\n",
      "| \u001b[0m 144     \u001b[0m | \u001b[0m-680.0   \u001b[0m | \u001b[0m 0.07398 \u001b[0m | \u001b[0m 0.5641  \u001b[0m | \u001b[0m 2.034   \u001b[0m | \u001b[0m 1.4     \u001b[0m | \u001b[0m 0.02642 \u001b[0m |\n",
      "| \u001b[0m 145     \u001b[0m | \u001b[0m 305.0   \u001b[0m | \u001b[0m 0.00727 \u001b[0m | \u001b[0m 0.4775  \u001b[0m | \u001b[0m 2.132   \u001b[0m | \u001b[0m 1.366   \u001b[0m | \u001b[0m 0.0402  \u001b[0m |\n",
      "| \u001b[0m 146     \u001b[0m | \u001b[0m-380.0   \u001b[0m | \u001b[0m 0.04214 \u001b[0m | \u001b[0m 0.4525  \u001b[0m | \u001b[0m 2.054   \u001b[0m | \u001b[0m 1.433   \u001b[0m | \u001b[0m 0.004931\u001b[0m |\n",
      "| \u001b[0m 147     \u001b[0m | \u001b[0m 255.0   \u001b[0m | \u001b[0m 0.001193\u001b[0m | \u001b[0m 0.4798  \u001b[0m | \u001b[0m 2.127   \u001b[0m | \u001b[0m 1.407   \u001b[0m | \u001b[0m 0.02632 \u001b[0m |\n",
      "| \u001b[0m 148     \u001b[0m | \u001b[0m 60.0    \u001b[0m | \u001b[0m 0.02399 \u001b[0m | \u001b[0m 0.4749  \u001b[0m | \u001b[0m 2.14    \u001b[0m | \u001b[0m 1.381   \u001b[0m | \u001b[0m 0.03572 \u001b[0m |\n",
      "| \u001b[0m 149     \u001b[0m | \u001b[0m-65.0    \u001b[0m | \u001b[0m 0.02689 \u001b[0m | \u001b[0m 0.4543  \u001b[0m | \u001b[0m 2.035   \u001b[0m | \u001b[0m 1.446   \u001b[0m | \u001b[0m 0.04064 \u001b[0m |\n",
      "| \u001b[0m 150     \u001b[0m | \u001b[0m-440.0   \u001b[0m | \u001b[0m 0.06074 \u001b[0m | \u001b[0m 0.5731  \u001b[0m | \u001b[0m 2.068   \u001b[0m | \u001b[0m 1.41    \u001b[0m | \u001b[0m 0.07303 \u001b[0m |\n",
      "| \u001b[0m 151     \u001b[0m | \u001b[0m-65.0    \u001b[0m | \u001b[0m 0.02864 \u001b[0m | \u001b[0m 0.4961  \u001b[0m | \u001b[0m 2.147   \u001b[0m | \u001b[0m 1.382   \u001b[0m | \u001b[0m 0.06728 \u001b[0m |\n",
      "| \u001b[0m 152     \u001b[0m | \u001b[0m 265.0   \u001b[0m | \u001b[0m 0.01336 \u001b[0m | \u001b[0m 0.517   \u001b[0m | \u001b[0m 2.031   \u001b[0m | \u001b[0m 1.457   \u001b[0m | \u001b[0m 0.04117 \u001b[0m |\n",
      "| \u001b[0m 153     \u001b[0m | \u001b[0m 210.0   \u001b[0m | \u001b[0m 0.02037 \u001b[0m | \u001b[0m 0.5705  \u001b[0m | \u001b[0m 2.054   \u001b[0m | \u001b[0m 1.453   \u001b[0m | \u001b[0m 0.0439  \u001b[0m |\n",
      "| \u001b[0m 154     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 0.006505\u001b[0m | \u001b[0m 0.5161  \u001b[0m | \u001b[0m 2.051   \u001b[0m | \u001b[0m 1.419   \u001b[0m | \u001b[0m 0.04967 \u001b[0m |\n",
      "| \u001b[0m 155     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 0.004518\u001b[0m | \u001b[0m 0.5111  \u001b[0m | \u001b[0m 2.12    \u001b[0m | \u001b[0m 1.448   \u001b[0m | \u001b[0m 0.07912 \u001b[0m |\n",
      "| \u001b[0m 156     \u001b[0m | \u001b[0m-265.0   \u001b[0m | \u001b[0m 0.04181 \u001b[0m | \u001b[0m 0.5255  \u001b[0m | \u001b[0m 2.129   \u001b[0m | \u001b[0m 1.376   \u001b[0m | \u001b[0m 0.04309 \u001b[0m |\n",
      "| \u001b[0m 157     \u001b[0m | \u001b[0m 160.0   \u001b[0m | \u001b[0m 0.02478 \u001b[0m | \u001b[0m 0.5525  \u001b[0m | \u001b[0m 2.099   \u001b[0m | \u001b[0m 1.349   \u001b[0m | \u001b[0m 0.0649  \u001b[0m |\n",
      "| \u001b[0m 158     \u001b[0m | \u001b[0m 285.0   \u001b[0m | \u001b[0m 0.01327 \u001b[0m | \u001b[0m 0.5383  \u001b[0m | \u001b[0m 2.073   \u001b[0m | \u001b[0m 1.358   \u001b[0m | \u001b[0m 0.07419 \u001b[0m |\n",
      "| \u001b[0m 159     \u001b[0m | \u001b[0m-15.0    \u001b[0m | \u001b[0m 0.02906 \u001b[0m | \u001b[0m 0.5384  \u001b[0m | \u001b[0m 2.076   \u001b[0m | \u001b[0m 1.413   \u001b[0m | \u001b[0m 0.06193 \u001b[0m |\n",
      "| \u001b[0m 160     \u001b[0m | \u001b[0m-315.0   \u001b[0m | \u001b[0m 0.04656 \u001b[0m | \u001b[0m 0.5319  \u001b[0m | \u001b[0m 2.1     \u001b[0m | \u001b[0m 1.405   \u001b[0m | \u001b[0m 0.006657\u001b[0m |\n",
      "| \u001b[0m 161     \u001b[0m | \u001b[0m-505.0   \u001b[0m | \u001b[0m 0.05061 \u001b[0m | \u001b[0m 0.4586  \u001b[0m | \u001b[0m 2.129   \u001b[0m | \u001b[0m 1.451   \u001b[0m | \u001b[0m 0.0213  \u001b[0m |\n",
      "| \u001b[0m 162     \u001b[0m | \u001b[0m-630.0   \u001b[0m | \u001b[0m 0.06643 \u001b[0m | \u001b[0m 0.4836  \u001b[0m | \u001b[0m 2.119   \u001b[0m | \u001b[0m 1.431   \u001b[0m | \u001b[0m 0.003301\u001b[0m |\n",
      "| \u001b[0m 163     \u001b[0m | \u001b[0m 295.0   \u001b[0m | \u001b[0m 0.007869\u001b[0m | \u001b[0m 0.542   \u001b[0m | \u001b[0m 2.04    \u001b[0m | \u001b[0m 1.328   \u001b[0m | \u001b[0m 0.07586 \u001b[0m |\n",
      "| \u001b[0m 164     \u001b[0m | \u001b[0m-315.0   \u001b[0m | \u001b[0m 0.03614 \u001b[0m | \u001b[0m 0.4658  \u001b[0m | \u001b[0m 2.034   \u001b[0m | \u001b[0m 1.398   \u001b[0m | \u001b[0m 0.05116 \u001b[0m |\n",
      "| \u001b[0m 165     \u001b[0m | \u001b[0m 135.0   \u001b[0m | \u001b[0m 0.02294 \u001b[0m | \u001b[0m 0.5244  \u001b[0m | \u001b[0m 2.03    \u001b[0m | \u001b[0m 1.449   \u001b[0m | \u001b[0m 0.01217 \u001b[0m |\n",
      "| \u001b[0m 166     \u001b[0m | \u001b[0m-65.0    \u001b[0m | \u001b[0m 0.03061 \u001b[0m | \u001b[0m 0.4781  \u001b[0m | \u001b[0m 2.124   \u001b[0m | \u001b[0m 1.373   \u001b[0m | \u001b[0m 0.03501 \u001b[0m |\n",
      "| \u001b[0m 167     \u001b[0m | \u001b[0m 305.0   \u001b[0m | \u001b[0m 0.009394\u001b[0m | \u001b[0m 0.4831  \u001b[0m | \u001b[0m 2.033   \u001b[0m | \u001b[0m 1.435   \u001b[0m | \u001b[0m 0.06759 \u001b[0m |\n",
      "| \u001b[0m 168     \u001b[0m | \u001b[0m 280.0   \u001b[0m | \u001b[0m 0.01064 \u001b[0m | \u001b[0m 0.5184  \u001b[0m | \u001b[0m 2.053   \u001b[0m | \u001b[0m 1.416   \u001b[0m | \u001b[0m 0.05543 \u001b[0m |\n",
      "| \u001b[0m 169     \u001b[0m | \u001b[0m 290.0   \u001b[0m | \u001b[0m 0.01221 \u001b[0m | \u001b[0m 0.5517  \u001b[0m | \u001b[0m 2.06    \u001b[0m | \u001b[0m 1.423   \u001b[0m | \u001b[0m 0.07488 \u001b[0m |\n",
      "| \u001b[0m 170     \u001b[0m | \u001b[0m 285.0   \u001b[0m | \u001b[0m 0.004259\u001b[0m | \u001b[0m 0.4571  \u001b[0m | \u001b[0m 2.138   \u001b[0m | \u001b[0m 1.459   \u001b[0m | \u001b[0m 0.03844 \u001b[0m |\n",
      "| \u001b[0m 171     \u001b[0m | \u001b[0m-290.0   \u001b[0m | \u001b[0m 0.0453  \u001b[0m | \u001b[0m 0.5226  \u001b[0m | \u001b[0m 2.098   \u001b[0m | \u001b[0m 1.407   \u001b[0m | \u001b[0m 0.06554 \u001b[0m |\n",
      "| \u001b[0m 172     \u001b[0m | \u001b[0m-15.0    \u001b[0m | \u001b[0m 0.027   \u001b[0m | \u001b[0m 0.5005  \u001b[0m | \u001b[0m 2.057   \u001b[0m | \u001b[0m 1.46    \u001b[0m | \u001b[0m 0.02453 \u001b[0m |\n",
      "| \u001b[0m 173     \u001b[0m | \u001b[0m-15.0    \u001b[0m | \u001b[0m 0.02445 \u001b[0m | \u001b[0m 0.4618  \u001b[0m | \u001b[0m 2.009   \u001b[0m | \u001b[0m 1.473   \u001b[0m | \u001b[0m 0.05872 \u001b[0m |\n",
      "| \u001b[0m 174     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 0.003989\u001b[0m | \u001b[0m 0.4961  \u001b[0m | \u001b[0m 2.067   \u001b[0m | \u001b[0m 1.487   \u001b[0m | \u001b[0m 0.03783 \u001b[0m |\n",
      "| \u001b[0m 175     \u001b[0m | \u001b[0m 305.0   \u001b[0m | \u001b[0m 0.009234\u001b[0m | \u001b[0m 0.4957  \u001b[0m | \u001b[0m 2.11    \u001b[0m | \u001b[0m 1.32    \u001b[0m | \u001b[0m 0.08374 \u001b[0m |\n",
      "| \u001b[0m 176     \u001b[0m | \u001b[0m 135.0   \u001b[0m | \u001b[0m 0.02374 \u001b[0m | \u001b[0m 0.5253  \u001b[0m | \u001b[0m 2.131   \u001b[0m | \u001b[0m 1.316   \u001b[0m | \u001b[0m 0.07827 \u001b[0m |\n",
      "| \u001b[0m 177     \u001b[0m | \u001b[0m 285.0   \u001b[0m | \u001b[0m 0.007636\u001b[0m | \u001b[0m 0.5462  \u001b[0m | \u001b[0m 2.036   \u001b[0m | \u001b[0m 1.446   \u001b[0m | \u001b[0m 0.03198 \u001b[0m |\n",
      "| \u001b[0m 178     \u001b[0m | \u001b[0m-215.0   \u001b[0m | \u001b[0m 0.03944 \u001b[0m | \u001b[0m 0.5272  \u001b[0m | \u001b[0m 2.043   \u001b[0m | \u001b[0m 1.453   \u001b[0m | \u001b[0m 0.06143 \u001b[0m |\n",
      "| \u001b[0m 179     \u001b[0m | \u001b[0m 305.0   \u001b[0m | \u001b[0m 0.00967 \u001b[0m | \u001b[0m 0.4921  \u001b[0m | \u001b[0m 2.078   \u001b[0m | \u001b[0m 1.477   \u001b[0m | \u001b[0m 0.07558 \u001b[0m |\n",
      "| \u001b[0m 180     \u001b[0m | \u001b[0m 305.0   \u001b[0m | \u001b[0m 0.007844\u001b[0m | \u001b[0m 0.4677  \u001b[0m | \u001b[0m 2.134   \u001b[0m | \u001b[0m 1.5     \u001b[0m | \u001b[0m 0.03937 \u001b[0m |\n",
      "| \u001b[0m 181     \u001b[0m | \u001b[0m 305.0   \u001b[0m | \u001b[0m 0.007979\u001b[0m | \u001b[0m 0.4832  \u001b[0m | \u001b[0m 2.085   \u001b[0m | \u001b[0m 1.398   \u001b[0m | \u001b[0m 0.03384 \u001b[0m |\n",
      "| \u001b[0m 182     \u001b[0m | \u001b[0m 265.0   \u001b[0m | \u001b[0m 0.004499\u001b[0m | \u001b[0m 0.5573  \u001b[0m | \u001b[0m 2.072   \u001b[0m | \u001b[0m 1.448   \u001b[0m | \u001b[0m 0.02179 \u001b[0m |\n",
      "| \u001b[0m 183     \u001b[0m | \u001b[0m-15.0    \u001b[0m | \u001b[0m 0.02621 \u001b[0m | \u001b[0m 0.4866  \u001b[0m | \u001b[0m 2.124   \u001b[0m | \u001b[0m 1.509   \u001b[0m | \u001b[0m 0.04489 \u001b[0m |\n",
      "| \u001b[0m 184     \u001b[0m | \u001b[0m 160.0   \u001b[0m | \u001b[0m 0.02409 \u001b[0m | \u001b[0m 0.5482  \u001b[0m | \u001b[0m 2.032   \u001b[0m | \u001b[0m 1.343   \u001b[0m | \u001b[0m 0.07207 \u001b[0m |\n",
      "| \u001b[0m 185     \u001b[0m | \u001b[0m-415.0   \u001b[0m | \u001b[0m 0.05291 \u001b[0m | \u001b[0m 0.5111  \u001b[0m | \u001b[0m 2.102   \u001b[0m | \u001b[0m 1.331   \u001b[0m | \u001b[0m 0.08335 \u001b[0m |\n",
      "| \u001b[0m 186     \u001b[0m | \u001b[0m 255.0   \u001b[0m | \u001b[0m 0.001593\u001b[0m | \u001b[0m 0.4566  \u001b[0m | \u001b[0m 2.159   \u001b[0m | \u001b[0m 1.434   \u001b[0m | \u001b[0m 0.04232 \u001b[0m |\n",
      "| \u001b[0m 187     \u001b[0m | \u001b[0m-265.0   \u001b[0m | \u001b[0m 0.03958 \u001b[0m | \u001b[0m 0.513   \u001b[0m | \u001b[0m 2.075   \u001b[0m | \u001b[0m 1.474   \u001b[0m | \u001b[0m 0.09554 \u001b[0m |\n",
      "| \u001b[0m 188     \u001b[0m | \u001b[0m-190.0   \u001b[0m | \u001b[0m 0.03631 \u001b[0m | \u001b[0m 0.5125  \u001b[0m | \u001b[0m 2.084   \u001b[0m | \u001b[0m 1.397   \u001b[0m | \u001b[0m 0.02127 \u001b[0m |\n",
      "| \u001b[0m 189     \u001b[0m | \u001b[0m-65.0    \u001b[0m | \u001b[0m 0.02995 \u001b[0m | \u001b[0m 0.495   \u001b[0m | \u001b[0m 2.161   \u001b[0m | \u001b[0m 1.353   \u001b[0m | \u001b[0m 0.02986 \u001b[0m |\n",
      "| \u001b[0m 190     \u001b[0m | \u001b[0m-330.0   \u001b[0m | \u001b[0m 0.03859 \u001b[0m | \u001b[0m 0.4545  \u001b[0m | \u001b[0m 2.145   \u001b[0m | \u001b[0m 1.384   \u001b[0m | \u001b[0m 0.03501 \u001b[0m |\n",
      "| \u001b[0m 191     \u001b[0m | \u001b[0m 160.0   \u001b[0m | \u001b[0m 0.01784 \u001b[0m | \u001b[0m 0.5055  \u001b[0m | \u001b[0m 2.158   \u001b[0m | \u001b[0m 1.388   \u001b[0m | \u001b[0m 0.006583\u001b[0m |\n",
      "| \u001b[0m 192     \u001b[0m | \u001b[0m-355.0   \u001b[0m | \u001b[0m 0.048   \u001b[0m | \u001b[0m 0.4898  \u001b[0m | \u001b[0m 2.138   \u001b[0m | \u001b[0m 1.497   \u001b[0m | \u001b[0m 0.03833 \u001b[0m |\n",
      "| \u001b[0m 193     \u001b[0m | \u001b[0m-280.0   \u001b[0m | \u001b[0m 0.03909 \u001b[0m | \u001b[0m 0.4742  \u001b[0m | \u001b[0m 2.092   \u001b[0m | \u001b[0m 1.417   \u001b[0m | \u001b[0m 0.04601 \u001b[0m |\n",
      "| \u001b[0m 194     \u001b[0m | \u001b[0m-305.0   \u001b[0m | \u001b[0m 0.03681 \u001b[0m | \u001b[0m 0.4405  \u001b[0m | \u001b[0m 2.126   \u001b[0m | \u001b[0m 1.377   \u001b[0m | \u001b[0m 0.07765 \u001b[0m |\n",
      "| \u001b[0m 195     \u001b[0m | \u001b[0m 135.0   \u001b[0m | \u001b[0m 0.01923 \u001b[0m | \u001b[0m 0.5154  \u001b[0m | \u001b[0m 2.109   \u001b[0m | \u001b[0m 1.32    \u001b[0m | \u001b[0m 0.04866 \u001b[0m |\n",
      "| \u001b[0m 196     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 0.006433\u001b[0m | \u001b[0m 0.5056  \u001b[0m | \u001b[0m 2.11    \u001b[0m | \u001b[0m 1.42    \u001b[0m | \u001b[0m 0.01812 \u001b[0m |\n",
      "| \u001b[0m 197     \u001b[0m | \u001b[0m-65.0    \u001b[0m | \u001b[0m 0.0269  \u001b[0m | \u001b[0m 0.4614  \u001b[0m | \u001b[0m 2.12    \u001b[0m | \u001b[0m 1.533   \u001b[0m | \u001b[0m 0.0345  \u001b[0m |\n",
      "| \u001b[0m 198     \u001b[0m | \u001b[0m-240.0   \u001b[0m | \u001b[0m 0.03328 \u001b[0m | \u001b[0m 0.4456  \u001b[0m | \u001b[0m 2.061   \u001b[0m | \u001b[0m 1.389   \u001b[0m | \u001b[0m 0.02436 \u001b[0m |\n",
      "| \u001b[0m 199     \u001b[0m | \u001b[0m-65.0    \u001b[0m | \u001b[0m 0.03076 \u001b[0m | \u001b[0m 0.4818  \u001b[0m | \u001b[0m 2.077   \u001b[0m | \u001b[0m 1.472   \u001b[0m | \u001b[0m 0.02507 \u001b[0m |\n",
      "| \u001b[0m 200     \u001b[0m | \u001b[0m 60.0    \u001b[0m | \u001b[0m 0.02216 \u001b[0m | \u001b[0m 0.4442  \u001b[0m | \u001b[0m 2.119   \u001b[0m | \u001b[0m 1.393   \u001b[0m | \u001b[0m 0.05021 \u001b[0m |\n",
      "| \u001b[0m 201     \u001b[0m | \u001b[0m-330.0   \u001b[0m | \u001b[0m 0.04143 \u001b[0m | \u001b[0m 0.5054  \u001b[0m | \u001b[0m 2.158   \u001b[0m | \u001b[0m 1.359   \u001b[0m | \u001b[0m 0.06543 \u001b[0m |\n",
      "| \u001b[0m 202     \u001b[0m | \u001b[0m 265.0   \u001b[0m | \u001b[0m 0.005423\u001b[0m | \u001b[0m 0.5323  \u001b[0m | \u001b[0m 2.055   \u001b[0m | \u001b[0m 1.394   \u001b[0m | \u001b[0m 0.04546 \u001b[0m |\n",
      "| \u001b[0m 203     \u001b[0m | \u001b[0m-165.0   \u001b[0m | \u001b[0m 0.03376 \u001b[0m | \u001b[0m 0.4844  \u001b[0m | \u001b[0m 2.078   \u001b[0m | \u001b[0m 1.492   \u001b[0m | \u001b[0m 0.04213 \u001b[0m |\n",
      "| \u001b[0m 204     \u001b[0m | \u001b[0m-240.0   \u001b[0m | \u001b[0m 0.04141 \u001b[0m | \u001b[0m 0.5318  \u001b[0m | \u001b[0m 2.082   \u001b[0m | \u001b[0m 1.414   \u001b[0m | \u001b[0m 0.05167 \u001b[0m |\n",
      "| \u001b[0m 205     \u001b[0m | \u001b[0m-140.0   \u001b[0m | \u001b[0m 0.03307 \u001b[0m | \u001b[0m 0.4801  \u001b[0m | \u001b[0m 2.091   \u001b[0m | \u001b[0m 1.344   \u001b[0m | \u001b[0m 0.06769 \u001b[0m |\n",
      "| \u001b[0m 206     \u001b[0m | \u001b[0m-65.0    \u001b[0m | \u001b[0m 0.0311  \u001b[0m | \u001b[0m 0.4837  \u001b[0m | \u001b[0m 2.106   \u001b[0m | \u001b[0m 1.341   \u001b[0m | \u001b[0m 0.09185 \u001b[0m |\n",
      "| \u001b[0m 207     \u001b[0m | \u001b[0m 305.0   \u001b[0m | \u001b[0m 0.01004 \u001b[0m | \u001b[0m 0.4794  \u001b[0m | \u001b[0m 2.133   \u001b[0m | \u001b[0m 1.369   \u001b[0m | \u001b[0m 0.04161 \u001b[0m |\n",
      "| \u001b[0m 208     \u001b[0m | \u001b[0m 210.0   \u001b[0m | \u001b[0m 0.01587 \u001b[0m | \u001b[0m 0.4917  \u001b[0m | \u001b[0m 2.133   \u001b[0m | \u001b[0m 1.374   \u001b[0m | \u001b[0m 0.0543  \u001b[0m |\n",
      "| \u001b[0m 209     \u001b[0m | \u001b[0m-115.0   \u001b[0m | \u001b[0m 0.02983 \u001b[0m | \u001b[0m 0.45    \u001b[0m | \u001b[0m 2.075   \u001b[0m | \u001b[0m 1.463   \u001b[0m | \u001b[0m 0.07448 \u001b[0m |\n",
      "| \u001b[0m 210     \u001b[0m | \u001b[0m-355.0   \u001b[0m | \u001b[0m 0.04244 \u001b[0m | \u001b[0m 0.4661  \u001b[0m | \u001b[0m 2.018   \u001b[0m | \u001b[0m 1.402   \u001b[0m | \u001b[0m 0.05683 \u001b[0m |\n",
      "| \u001b[0m 211     \u001b[0m | \u001b[0m-140.0   \u001b[0m | \u001b[0m 0.03873 \u001b[0m | \u001b[0m 0.5783  \u001b[0m | \u001b[0m 2.072   \u001b[0m | \u001b[0m 1.378   \u001b[0m | \u001b[0m 0.07763 \u001b[0m |\n",
      "| \u001b[0m 212     \u001b[0m | \u001b[0m 265.0   \u001b[0m | \u001b[0m 0.004891\u001b[0m | \u001b[0m 0.4973  \u001b[0m | \u001b[0m 2.067   \u001b[0m | \u001b[0m 1.486   \u001b[0m | \u001b[0m 0.03741 \u001b[0m |\n",
      "| \u001b[0m 213     \u001b[0m | \u001b[0m 295.0   \u001b[0m | \u001b[0m 0.007622\u001b[0m | \u001b[0m 0.5112  \u001b[0m | \u001b[0m 2.114   \u001b[0m | \u001b[0m 1.464   \u001b[0m | \u001b[0m 0.08188 \u001b[0m |\n",
      "| \u001b[0m 214     \u001b[0m | \u001b[0m 135.0   \u001b[0m | \u001b[0m 0.02044 \u001b[0m | \u001b[0m 0.5206  \u001b[0m | \u001b[0m 2.059   \u001b[0m | \u001b[0m 1.407   \u001b[0m | \u001b[0m 0.05653 \u001b[0m |\n",
      "| \u001b[0m 215     \u001b[0m | \u001b[0m-205.0   \u001b[0m | \u001b[0m 0.03554 \u001b[0m | \u001b[0m 0.4971  \u001b[0m | \u001b[0m 2.089   \u001b[0m | \u001b[0m 1.499   \u001b[0m | \u001b[0m 0.03157 \u001b[0m |\n",
      "| \u001b[0m 216     \u001b[0m | \u001b[0m-265.0   \u001b[0m | \u001b[0m 0.04507 \u001b[0m | \u001b[0m 0.5607  \u001b[0m | \u001b[0m 2.079   \u001b[0m | \u001b[0m 1.332   \u001b[0m | \u001b[0m 0.06574 \u001b[0m |\n",
      "| \u001b[0m 217     \u001b[0m | \u001b[0m 295.0   \u001b[0m | \u001b[0m 0.000520\u001b[0m | \u001b[0m 0.5434  \u001b[0m | \u001b[0m 2.033   \u001b[0m | \u001b[0m 1.298   \u001b[0m | \u001b[0m 0.06331 \u001b[0m |\n",
      "| \u001b[0m 218     \u001b[0m | \u001b[0m-215.0   \u001b[0m | \u001b[0m 0.03855 \u001b[0m | \u001b[0m 0.481   \u001b[0m | \u001b[0m 2.063   \u001b[0m | \u001b[0m 1.373   \u001b[0m | \u001b[0m 0.08029 \u001b[0m |\n",
      "| \u001b[0m 219     \u001b[0m | \u001b[0m 160.0   \u001b[0m | \u001b[0m 0.02393 \u001b[0m | \u001b[0m 0.5499  \u001b[0m | \u001b[0m 2.11    \u001b[0m | \u001b[0m 1.423   \u001b[0m | \u001b[0m 0.01355 \u001b[0m |\n",
      "| \u001b[0m 220     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 0.006583\u001b[0m | \u001b[0m 0.5109  \u001b[0m | \u001b[0m 2.116   \u001b[0m | \u001b[0m 1.457   \u001b[0m | \u001b[0m 0.08058 \u001b[0m |\n",
      "| \u001b[0m 221     \u001b[0m | \u001b[0m-15.0    \u001b[0m | \u001b[0m 0.02526 \u001b[0m | \u001b[0m 0.4532  \u001b[0m | \u001b[0m 2.073   \u001b[0m | \u001b[0m 1.459   \u001b[0m | \u001b[0m 0.02828 \u001b[0m |\n",
      "| \u001b[0m 222     \u001b[0m | \u001b[0m-65.0    \u001b[0m | \u001b[0m 0.02868 \u001b[0m | \u001b[0m 0.5074  \u001b[0m | \u001b[0m 2.037   \u001b[0m | \u001b[0m 1.386   \u001b[0m | \u001b[0m 0.04985 \u001b[0m |\n",
      "| \u001b[0m 223     \u001b[0m | \u001b[0m 160.0   \u001b[0m | \u001b[0m 0.02544 \u001b[0m | \u001b[0m 0.581   \u001b[0m | \u001b[0m 2.046   \u001b[0m | \u001b[0m 1.297   \u001b[0m | \u001b[0m 0.06653 \u001b[0m |\n",
      "| \u001b[0m 224     \u001b[0m | \u001b[0m-280.0   \u001b[0m | \u001b[0m 0.03968 \u001b[0m | \u001b[0m 0.4682  \u001b[0m | \u001b[0m 2.06    \u001b[0m | \u001b[0m 1.448   \u001b[0m | \u001b[0m 0.01816 \u001b[0m |\n",
      "| \u001b[0m 225     \u001b[0m | \u001b[0m 185.0   \u001b[0m | \u001b[0m 0.01584 \u001b[0m | \u001b[0m 0.4467  \u001b[0m | \u001b[0m 2.114   \u001b[0m | \u001b[0m 1.405   \u001b[0m | \u001b[0m 0.02771 \u001b[0m |\n",
      "| \u001b[0m 226     \u001b[0m | \u001b[0m-305.0   \u001b[0m | \u001b[0m 0.0363  \u001b[0m | \u001b[0m 0.4462  \u001b[0m | \u001b[0m 2.135   \u001b[0m | \u001b[0m 1.389   \u001b[0m | \u001b[0m 0.0558  \u001b[0m |\n",
      "| \u001b[0m 227     \u001b[0m | \u001b[0m 305.0   \u001b[0m | \u001b[0m 0.006163\u001b[0m | \u001b[0m 0.4594  \u001b[0m | \u001b[0m 2.061   \u001b[0m | \u001b[0m 1.437   \u001b[0m | \u001b[0m 0.01395 \u001b[0m |\n",
      "| \u001b[0m 228     \u001b[0m | \u001b[0m 255.0   \u001b[0m | \u001b[0m 0.001586\u001b[0m | \u001b[0m 0.4819  \u001b[0m | \u001b[0m 2.135   \u001b[0m | \u001b[0m 1.515   \u001b[0m | \u001b[0m 0.03875 \u001b[0m |\n",
      "| \u001b[0m 229     \u001b[0m | \u001b[0m-215.0   \u001b[0m | \u001b[0m 0.03468 \u001b[0m | \u001b[0m 0.4773  \u001b[0m | \u001b[0m 2.087   \u001b[0m | \u001b[0m 1.402   \u001b[0m | \u001b[0m 0.04485 \u001b[0m |\n",
      "| \u001b[0m 230     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 0.02578 \u001b[0m | \u001b[0m 0.4781  \u001b[0m | \u001b[0m 2.117   \u001b[0m | \u001b[0m 1.326   \u001b[0m | \u001b[0m 0.07105 \u001b[0m |\n",
      "| \u001b[0m 231     \u001b[0m | \u001b[0m-65.0    \u001b[0m | \u001b[0m 0.02958 \u001b[0m | \u001b[0m 0.4824  \u001b[0m | \u001b[0m 2.135   \u001b[0m | \u001b[0m 1.402   \u001b[0m | \u001b[0m 0.02394 \u001b[0m |\n",
      "| \u001b[0m 232     \u001b[0m | \u001b[0m-215.0   \u001b[0m | \u001b[0m 0.0395  \u001b[0m | \u001b[0m 0.5275  \u001b[0m | \u001b[0m 2.045   \u001b[0m | \u001b[0m 1.369   \u001b[0m | \u001b[0m 0.07403 \u001b[0m |\n",
      "| \u001b[0m 233     \u001b[0m | \u001b[0m 265.0   \u001b[0m | \u001b[0m 0.002519\u001b[0m | \u001b[0m 0.4586  \u001b[0m | \u001b[0m 2.164   \u001b[0m | \u001b[0m 1.397   \u001b[0m | \u001b[0m 0.02836 \u001b[0m |\n",
      "| \u001b[0m 234     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 0.02497 \u001b[0m | \u001b[0m 0.4825  \u001b[0m | \u001b[0m 2.067   \u001b[0m | \u001b[0m 1.381   \u001b[0m | \u001b[0m 0.08933 \u001b[0m |\n",
      "| \u001b[0m 235     \u001b[0m | \u001b[0m 265.0   \u001b[0m | \u001b[0m 0.001521\u001b[0m | \u001b[0m 0.5364  \u001b[0m | \u001b[0m 2.052   \u001b[0m | \u001b[0m 1.324   \u001b[0m | \u001b[0m 0.09321 \u001b[0m |\n",
      "| \u001b[0m 236     \u001b[0m | \u001b[0m-240.0   \u001b[0m | \u001b[0m 0.04132 \u001b[0m | \u001b[0m 0.5293  \u001b[0m | \u001b[0m 2.161   \u001b[0m | \u001b[0m 1.326   \u001b[0m | \u001b[0m 0.07706 \u001b[0m |\n",
      "| \u001b[0m 237     \u001b[0m | \u001b[0m 280.0   \u001b[0m | \u001b[0m 0.01107 \u001b[0m | \u001b[0m 0.45    \u001b[0m | \u001b[0m 2.045   \u001b[0m | \u001b[0m 1.446   \u001b[0m | \u001b[0m 0.05691 \u001b[0m |\n",
      "| \u001b[0m 238     \u001b[0m | \u001b[0m 235.0   \u001b[0m | \u001b[0m 0.01723 \u001b[0m | \u001b[0m 0.5538  \u001b[0m | \u001b[0m 2.098   \u001b[0m | \u001b[0m 1.366   \u001b[0m | \u001b[0m 0.09294 \u001b[0m |\n",
      "| \u001b[0m 239     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 0.02539 \u001b[0m | \u001b[0m 0.5063  \u001b[0m | \u001b[0m 2.131   \u001b[0m | \u001b[0m 1.341   \u001b[0m | \u001b[0m 0.04997 \u001b[0m |\n",
      "| \u001b[0m 240     \u001b[0m | \u001b[0m 185.0   \u001b[0m | \u001b[0m 0.0233  \u001b[0m | \u001b[0m 0.5872  \u001b[0m | \u001b[0m 2.029   \u001b[0m | \u001b[0m 1.439   \u001b[0m | \u001b[0m 0.02158 \u001b[0m |\n",
      "| \u001b[0m 241     \u001b[0m | \u001b[0m 60.0    \u001b[0m | \u001b[0m 0.0237  \u001b[0m | \u001b[0m 0.4442  \u001b[0m | \u001b[0m 2.122   \u001b[0m | \u001b[0m 1.394   \u001b[0m | \u001b[0m 0.0331  \u001b[0m |\n",
      "| \u001b[0m 242     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 0.01374 \u001b[0m | \u001b[0m 0.5587  \u001b[0m | \u001b[0m 2.09    \u001b[0m | \u001b[0m 1.455   \u001b[0m | \u001b[0m 0.06883 \u001b[0m |\n",
      "| \u001b[0m 243     \u001b[0m | \u001b[0m 305.0   \u001b[0m | \u001b[0m 0.01016 \u001b[0m | \u001b[0m 0.4833  \u001b[0m | \u001b[0m 2.033   \u001b[0m | \u001b[0m 1.434   \u001b[0m | \u001b[0m 0.06631 \u001b[0m |\n",
      "| \u001b[0m 244     \u001b[0m | \u001b[0m 85.0    \u001b[0m | \u001b[0m 0.02411 \u001b[0m | \u001b[0m 0.5026  \u001b[0m | \u001b[0m 2.04    \u001b[0m | \u001b[0m 1.408   \u001b[0m | \u001b[0m 0.04008 \u001b[0m |\n",
      "| \u001b[0m 245     \u001b[0m | \u001b[0m 135.0   \u001b[0m | \u001b[0m 0.02295 \u001b[0m | \u001b[0m 0.4976  \u001b[0m | \u001b[0m 2.048   \u001b[0m | \u001b[0m 1.441   \u001b[0m | \u001b[0m 0.04377 \u001b[0m |\n",
      "| \u001b[0m 246     \u001b[0m | \u001b[0m 305.0   \u001b[0m | \u001b[0m 0.01052 \u001b[0m | \u001b[0m 0.4891  \u001b[0m | \u001b[0m 2.053   \u001b[0m | \u001b[0m 1.437   \u001b[0m | \u001b[0m 0.02675 \u001b[0m |\n",
      "| \u001b[0m 247     \u001b[0m | \u001b[0m 295.0   \u001b[0m | \u001b[0m 0.009652\u001b[0m | \u001b[0m 0.5078  \u001b[0m | \u001b[0m 2.108   \u001b[0m | \u001b[0m 1.419   \u001b[0m | \u001b[0m 0.02043 \u001b[0m |\n",
      "| \u001b[0m 248     \u001b[0m | \u001b[0m 265.0   \u001b[0m | \u001b[0m 0.01353 \u001b[0m | \u001b[0m 0.4854  \u001b[0m | \u001b[0m 2.112   \u001b[0m | \u001b[0m 1.308   \u001b[0m | \u001b[0m 0.07359 \u001b[0m |\n",
      "| \u001b[0m 249     \u001b[0m | \u001b[0m 270.0   \u001b[0m | \u001b[0m 0.01036 \u001b[0m | \u001b[0m 0.517   \u001b[0m | \u001b[0m 2.065   \u001b[0m | \u001b[0m 1.377   \u001b[0m | \u001b[0m 0.07088 \u001b[0m |\n",
      "| \u001b[0m 250     \u001b[0m | \u001b[0m 235.0   \u001b[0m | \u001b[0m 0.01565 \u001b[0m | \u001b[0m 0.521   \u001b[0m | \u001b[0m 2.071   \u001b[0m | \u001b[0m 1.464   \u001b[0m | \u001b[0m 0.01463 \u001b[0m |\n",
      "| \u001b[0m 251     \u001b[0m | \u001b[0m 290.0   \u001b[0m | \u001b[0m 0.01164 \u001b[0m | \u001b[0m 0.4512  \u001b[0m | \u001b[0m 2.045   \u001b[0m | \u001b[0m 1.446   \u001b[0m | \u001b[0m 0.05614 \u001b[0m |\n",
      "| \u001b[0m 252     \u001b[0m | \u001b[0m-40.0    \u001b[0m | \u001b[0m 0.03245 \u001b[0m | \u001b[0m 0.5623  \u001b[0m | \u001b[0m 2.082   \u001b[0m | \u001b[0m 1.439   \u001b[0m | \u001b[0m 0.05352 \u001b[0m |\n",
      "| \u001b[0m 253     \u001b[0m | \u001b[0m 135.0   \u001b[0m | \u001b[0m 0.01989 \u001b[0m | \u001b[0m 0.4588  \u001b[0m | \u001b[0m 2.038   \u001b[0m | \u001b[0m 1.462   \u001b[0m | \u001b[0m 0.05926 \u001b[0m |\n",
      "| \u001b[0m 254     \u001b[0m | \u001b[0m 305.0   \u001b[0m | \u001b[0m 0.007176\u001b[0m | \u001b[0m 0.4677  \u001b[0m | \u001b[0m 2.048   \u001b[0m | \u001b[0m 1.507   \u001b[0m | \u001b[0m 0.02066 \u001b[0m |\n",
      "| \u001b[0m 255     \u001b[0m | \u001b[0m-215.0   \u001b[0m | \u001b[0m 0.03587 \u001b[0m | \u001b[0m 0.4935  \u001b[0m | \u001b[0m 2.049   \u001b[0m | \u001b[0m 1.432   \u001b[0m | \u001b[0m 0.05172 \u001b[0m |\n",
      "=====================================================================================\n"
     ]
    }
   ],
   "source": [
    "optimization_sgd = BayesianOptimization(evaluateSgd, params_sgd, random_state=231)\n",
    "optimization_sgd.maximize(n_iter=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': 305.0,\n",
       " 'params': {'alpha': 0.005854021438338096,\n",
       "  'l1_ratio': 0.4547722688881384,\n",
       "  'loss': 2.0803138889905366,\n",
       "  'penalty': 1.4688569955709672,\n",
       "  'tol': 0.02336999122867795}}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimization_sgd.max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateSvm(C, gamma):\n",
    "    \n",
    "    model = SVC(C=C, gamma=gamma, random_state=231)\n",
    "    \n",
    "    return cross_val_imbalanced(model, X_train_prepared, y_train, SMOTE(random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_svm = {\n",
    "    'C': (1, 1000),\n",
    "    'gamma': (0.001, 10)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |     C     |   gamma   |\n",
      "-------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-510.0   \u001b[0m | \u001b[0m 781.7   \u001b[0m | \u001b[0m 5.843   \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m-485.0   \u001b[0m | \u001b[95m 427.3   \u001b[0m | \u001b[95m 3.154   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-510.0   \u001b[0m | \u001b[0m 827.1   \u001b[0m | \u001b[0m 9.034   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-510.0   \u001b[0m | \u001b[0m 39.9    \u001b[0m | \u001b[0m 9.152   \u001b[0m |\n",
      "| \u001b[95m 5       \u001b[0m | \u001b[95m-410.0   \u001b[0m | \u001b[95m 61.44   \u001b[0m | \u001b[95m 1.808   \u001b[0m |\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m-400.0   \u001b[0m | \u001b[95m 61.44   \u001b[0m | \u001b[95m 1.782   \u001b[0m |\n",
      "| \u001b[95m 7       \u001b[0m | \u001b[95m-350.0   \u001b[0m | \u001b[95m 61.51   \u001b[0m | \u001b[95m 1.587   \u001b[0m |\n",
      "| \u001b[95m 8       \u001b[0m | \u001b[95m-340.0   \u001b[0m | \u001b[95m 61.35   \u001b[0m | \u001b[95m 1.567   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-370.0   \u001b[0m | \u001b[0m 61.49   \u001b[0m | \u001b[0m 1.629   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-370.0   \u001b[0m | \u001b[0m 61.05   \u001b[0m | \u001b[0m 1.639   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-350.0   \u001b[0m | \u001b[0m 61.43   \u001b[0m | \u001b[0m 1.589   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-340.0   \u001b[0m | \u001b[0m 61.37   \u001b[0m | \u001b[0m 1.564   \u001b[0m |\n",
      "| \u001b[95m 13      \u001b[0m | \u001b[95m-275.0   \u001b[0m | \u001b[95m 61.47   \u001b[0m | \u001b[95m 1.345   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-370.0   \u001b[0m | \u001b[0m 61.21   \u001b[0m | \u001b[0m 1.623   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-355.0   \u001b[0m | \u001b[0m 61.46   \u001b[0m | \u001b[0m 1.52    \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-275.0   \u001b[0m | \u001b[0m 61.39   \u001b[0m | \u001b[0m 1.349   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-285.0   \u001b[0m | \u001b[0m 61.45   \u001b[0m | \u001b[0m 1.35    \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-285.0   \u001b[0m | \u001b[0m 61.33   \u001b[0m | \u001b[0m 1.353   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-305.0   \u001b[0m | \u001b[0m 61.41   \u001b[0m | \u001b[0m 1.41    \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-290.0   \u001b[0m | \u001b[0m 61.58   \u001b[0m | \u001b[0m 1.303   \u001b[0m |\n",
      "| \u001b[95m 21      \u001b[0m | \u001b[95m-260.0   \u001b[0m | \u001b[95m 61.57   \u001b[0m | \u001b[95m 1.26    \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-285.0   \u001b[0m | \u001b[0m 61.48   \u001b[0m | \u001b[0m 1.374   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-265.0   \u001b[0m | \u001b[0m 61.54   \u001b[0m | \u001b[0m 1.219   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-290.0   \u001b[0m | \u001b[0m 61.49   \u001b[0m | \u001b[0m 1.292   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-355.0   \u001b[0m | \u001b[0m 61.7    \u001b[0m | \u001b[0m 1.517   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m-345.0   \u001b[0m | \u001b[0m 61.25   \u001b[0m | \u001b[0m 1.498   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m-315.0   \u001b[0m | \u001b[0m 61.32   \u001b[0m | \u001b[0m 1.465   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m-270.0   \u001b[0m | \u001b[0m 61.56   \u001b[0m | \u001b[0m 1.266   \u001b[0m |\n",
      "| \u001b[95m 29      \u001b[0m | \u001b[95m-255.0   \u001b[0m | \u001b[95m 61.66   \u001b[0m | \u001b[95m 1.18    \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m-275.0   \u001b[0m | \u001b[0m 61.31   \u001b[0m | \u001b[0m 1.341   \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m-300.0   \u001b[0m | \u001b[0m 61.47   \u001b[0m | \u001b[0m 1.335   \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m-265.0   \u001b[0m | \u001b[0m 61.43   \u001b[0m | \u001b[0m 1.22    \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m-290.0   \u001b[0m | \u001b[0m 61.3    \u001b[0m | \u001b[0m 1.296   \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m-315.0   \u001b[0m | \u001b[0m 61.38   \u001b[0m | \u001b[0m 1.464   \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m-260.0   \u001b[0m | \u001b[0m 61.74   \u001b[0m | \u001b[0m 1.15    \u001b[0m |\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m-255.0   \u001b[0m | \u001b[0m 61.64   \u001b[0m | \u001b[0m 1.193   \u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m-265.0   \u001b[0m | \u001b[0m 61.27   \u001b[0m | \u001b[0m 1.222   \u001b[0m |\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m-255.0   \u001b[0m | \u001b[0m 61.29   \u001b[0m | \u001b[0m 1.193   \u001b[0m |\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m-265.0   \u001b[0m | \u001b[0m 61.66   \u001b[0m | \u001b[0m 1.224   \u001b[0m |\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m-275.0   \u001b[0m | \u001b[0m 61.33   \u001b[0m | \u001b[0m 1.115   \u001b[0m |\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m-255.0   \u001b[0m | \u001b[0m 61.58   \u001b[0m | \u001b[0m 1.195   \u001b[0m |\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m-265.0   \u001b[0m | \u001b[0m 61.64   \u001b[0m | \u001b[0m 1.088   \u001b[0m |\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m-265.0   \u001b[0m | \u001b[0m 61.35   \u001b[0m | \u001b[0m 1.225   \u001b[0m |\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m-290.0   \u001b[0m | \u001b[0m 61.25   \u001b[0m | \u001b[0m 1.294   \u001b[0m |\n",
      "| \u001b[0m 45      \u001b[0m | \u001b[0m-300.0   \u001b[0m | \u001b[0m 61.56   \u001b[0m | \u001b[0m 1.338   \u001b[0m |\n",
      "| \u001b[95m 46      \u001b[0m | \u001b[95m-250.0   \u001b[0m | \u001b[95m 61.75   \u001b[0m | \u001b[95m 1.125   \u001b[0m |\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m-285.0   \u001b[0m | \u001b[0m 61.51   \u001b[0m | \u001b[0m 1.351   \u001b[0m |\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m-260.0   \u001b[0m | \u001b[0m 61.6    \u001b[0m | \u001b[0m 1.261   \u001b[0m |\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m-255.0   \u001b[0m | \u001b[0m 61.74   \u001b[0m | \u001b[0m 1.039   \u001b[0m |\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m-265.0   \u001b[0m | \u001b[0m 61.62   \u001b[0m | \u001b[0m 1.213   \u001b[0m |\n",
      "| \u001b[0m 51      \u001b[0m | \u001b[0m-285.0   \u001b[0m | \u001b[0m 61.25   \u001b[0m | \u001b[0m 1.364   \u001b[0m |\n",
      "| \u001b[0m 52      \u001b[0m | \u001b[0m-250.0   \u001b[0m | \u001b[0m 61.67   \u001b[0m | \u001b[0m 1.125   \u001b[0m |\n",
      "| \u001b[0m 53      \u001b[0m | \u001b[0m-255.0   \u001b[0m | \u001b[0m 61.56   \u001b[0m | \u001b[0m 1.047   \u001b[0m |\n",
      "| \u001b[0m 54      \u001b[0m | \u001b[0m-265.0   \u001b[0m | \u001b[0m 61.63   \u001b[0m | \u001b[0m 1.098   \u001b[0m |\n",
      "| \u001b[95m 55      \u001b[0m | \u001b[95m-235.0   \u001b[0m | \u001b[95m 61.51   \u001b[0m | \u001b[95m 0.997   \u001b[0m |\n",
      "| \u001b[0m 56      \u001b[0m | \u001b[0m-260.0   \u001b[0m | \u001b[0m 61.69   \u001b[0m | \u001b[0m 1.152   \u001b[0m |\n",
      "| \u001b[0m 57      \u001b[0m | \u001b[0m-290.0   \u001b[0m | \u001b[0m 61.46   \u001b[0m | \u001b[0m 0.9412  \u001b[0m |\n",
      "| \u001b[0m 58      \u001b[0m | \u001b[0m-265.0   \u001b[0m | \u001b[0m 61.73   \u001b[0m | \u001b[0m 1.079   \u001b[0m |\n",
      "| \u001b[0m 59      \u001b[0m | \u001b[0m-255.0   \u001b[0m | \u001b[0m 61.19   \u001b[0m | \u001b[0m 1.041   \u001b[0m |\n",
      "| \u001b[0m 60      \u001b[0m | \u001b[0m-260.0   \u001b[0m | \u001b[0m 61.7    \u001b[0m | \u001b[0m 1.145   \u001b[0m |\n",
      "| \u001b[0m 61      \u001b[0m | \u001b[0m-240.0   \u001b[0m | \u001b[0m 61.52   \u001b[0m | \u001b[0m 0.8755  \u001b[0m |\n",
      "| \u001b[0m 62      \u001b[0m | \u001b[0m-250.0   \u001b[0m | \u001b[0m 61.74   \u001b[0m | \u001b[0m 1.125   \u001b[0m |\n",
      "| \u001b[0m 63      \u001b[0m | \u001b[0m-255.0   \u001b[0m | \u001b[0m 61.78   \u001b[0m | \u001b[0m 1.043   \u001b[0m |\n",
      "| \u001b[0m 64      \u001b[0m | \u001b[0m-265.0   \u001b[0m | \u001b[0m 61.31   \u001b[0m | \u001b[0m 1.077   \u001b[0m |\n",
      "| \u001b[0m 65      \u001b[0m | \u001b[0m-265.0   \u001b[0m | \u001b[0m 61.55   \u001b[0m | \u001b[0m 1.221   \u001b[0m |\n",
      "| \u001b[0m 66      \u001b[0m | \u001b[0m-250.0   \u001b[0m | \u001b[0m 61.73   \u001b[0m | \u001b[0m 1.12    \u001b[0m |\n",
      "| \u001b[0m 67      \u001b[0m | \u001b[0m-250.0   \u001b[0m | \u001b[0m 61.67   \u001b[0m | \u001b[0m 1.119   \u001b[0m |\n",
      "| \u001b[0m 68      \u001b[0m | \u001b[0m-250.0   \u001b[0m | \u001b[0m 61.66   \u001b[0m | \u001b[0m 1.131   \u001b[0m |\n",
      "| \u001b[0m 69      \u001b[0m | \u001b[0m-265.0   \u001b[0m | \u001b[0m 61.71   \u001b[0m | \u001b[0m 1.077   \u001b[0m |\n",
      "| \u001b[0m 70      \u001b[0m | \u001b[0m-285.0   \u001b[0m | \u001b[0m 61.42   \u001b[0m | \u001b[0m 1.375   \u001b[0m |\n",
      "| \u001b[0m 71      \u001b[0m | \u001b[0m-255.0   \u001b[0m | \u001b[0m 61.47   \u001b[0m | \u001b[0m 1.032   \u001b[0m |\n",
      "| \u001b[0m 72      \u001b[0m | \u001b[0m-265.0   \u001b[0m | \u001b[0m 61.73   \u001b[0m | \u001b[0m 1.06    \u001b[0m |\n",
      "| \u001b[0m 73      \u001b[0m | \u001b[0m-265.0   \u001b[0m | \u001b[0m 61.16   \u001b[0m | \u001b[0m 1.099   \u001b[0m |\n",
      "| \u001b[0m 74      \u001b[0m | \u001b[0m-255.0   \u001b[0m | \u001b[0m 61.29   \u001b[0m | \u001b[0m 1.044   \u001b[0m |\n",
      "| \u001b[0m 75      \u001b[0m | \u001b[0m-265.0   \u001b[0m | \u001b[0m 61.26   \u001b[0m | \u001b[0m 1.061   \u001b[0m |\n",
      "| \u001b[0m 76      \u001b[0m | \u001b[0m-265.0   \u001b[0m | \u001b[0m 61.76   \u001b[0m | \u001b[0m 1.057   \u001b[0m |\n",
      "| \u001b[0m 77      \u001b[0m | \u001b[0m-260.0   \u001b[0m | \u001b[0m 61.71   \u001b[0m | \u001b[0m 1.15    \u001b[0m |\n",
      "| \u001b[0m 78      \u001b[0m | \u001b[0m-265.0   \u001b[0m | \u001b[0m 61.31   \u001b[0m | \u001b[0m 1.227   \u001b[0m |\n",
      "| \u001b[0m 79      \u001b[0m | \u001b[0m-290.0   \u001b[0m | \u001b[0m 61.61   \u001b[0m | \u001b[0m 0.9209  \u001b[0m |\n",
      "| \u001b[0m 80      \u001b[0m | \u001b[0m-270.0   \u001b[0m | \u001b[0m 61.54   \u001b[0m | \u001b[0m 0.8989  \u001b[0m |\n",
      "| \u001b[0m 81      \u001b[0m | \u001b[0m-255.0   \u001b[0m | \u001b[0m 61.3    \u001b[0m | \u001b[0m 1.184   \u001b[0m |\n",
      "| \u001b[0m 82      \u001b[0m | \u001b[0m-280.0   \u001b[0m | \u001b[0m 61.55   \u001b[0m | \u001b[0m 1.176   \u001b[0m |\n",
      "| \u001b[0m 83      \u001b[0m | \u001b[0m-250.0   \u001b[0m | \u001b[0m 61.18   \u001b[0m | \u001b[0m 1.117   \u001b[0m |\n",
      "| \u001b[0m 84      \u001b[0m | \u001b[0m-265.0   \u001b[0m | \u001b[0m 61.17   \u001b[0m | \u001b[0m 1.087   \u001b[0m |\n",
      "| \u001b[0m 85      \u001b[0m | \u001b[0m-240.0   \u001b[0m | \u001b[0m 61.52   \u001b[0m | \u001b[0m 0.8706  \u001b[0m |\n",
      "| \u001b[0m 86      \u001b[0m | \u001b[0m-260.0   \u001b[0m | \u001b[0m 61.42   \u001b[0m | \u001b[0m 0.9779  \u001b[0m |\n",
      "| \u001b[0m 87      \u001b[0m | \u001b[0m-250.0   \u001b[0m | \u001b[0m 61.13   \u001b[0m | \u001b[0m 1.12    \u001b[0m |\n",
      "| \u001b[0m 88      \u001b[0m | \u001b[0m-275.0   \u001b[0m | \u001b[0m 61.33   \u001b[0m | \u001b[0m 1.234   \u001b[0m |\n",
      "| \u001b[0m 89      \u001b[0m | \u001b[0m-260.0   \u001b[0m | \u001b[0m 61.81   \u001b[0m | \u001b[0m 1.163   \u001b[0m |\n",
      "| \u001b[0m 90      \u001b[0m | \u001b[0m-260.0   \u001b[0m | \u001b[0m 61.66   \u001b[0m | \u001b[0m 1.256   \u001b[0m |\n",
      "| \u001b[0m 91      \u001b[0m | \u001b[0m-265.0   \u001b[0m | \u001b[0m 61.2    \u001b[0m | \u001b[0m 1.101   \u001b[0m |\n",
      "| \u001b[0m 92      \u001b[0m | \u001b[0m-235.0   \u001b[0m | \u001b[0m 61.55   \u001b[0m | \u001b[0m 0.9939  \u001b[0m |\n",
      "| \u001b[0m 93      \u001b[0m | \u001b[0m-265.0   \u001b[0m | \u001b[0m 61.09   \u001b[0m | \u001b[0m 1.197   \u001b[0m |\n",
      "| \u001b[0m 94      \u001b[0m | \u001b[0m-290.0   \u001b[0m | \u001b[0m 61.7    \u001b[0m | \u001b[0m 1.29    \u001b[0m |\n",
      "| \u001b[0m 95      \u001b[0m | \u001b[0m-275.0   \u001b[0m | \u001b[0m 61.14   \u001b[0m | \u001b[0m 1.114   \u001b[0m |\n",
      "| \u001b[0m 96      \u001b[0m | \u001b[0m-245.0   \u001b[0m | \u001b[0m 61.5    \u001b[0m | \u001b[0m 1.004   \u001b[0m |\n",
      "| \u001b[0m 97      \u001b[0m | \u001b[0m-275.0   \u001b[0m | \u001b[0m 61.3    \u001b[0m | \u001b[0m 1.346   \u001b[0m |\n",
      "| \u001b[0m 98      \u001b[0m | \u001b[0m-290.0   \u001b[0m | \u001b[0m 61.62   \u001b[0m | \u001b[0m 1.307   \u001b[0m |\n",
      "| \u001b[0m 99      \u001b[0m | \u001b[0m-260.0   \u001b[0m | \u001b[0m 61.54   \u001b[0m | \u001b[0m 0.958   \u001b[0m |\n",
      "| \u001b[0m 100     \u001b[0m | \u001b[0m-255.0   \u001b[0m | \u001b[0m 61.54   \u001b[0m | \u001b[0m 1.048   \u001b[0m |\n",
      "| \u001b[0m 101     \u001b[0m | \u001b[0m-280.0   \u001b[0m | \u001b[0m 61.23   \u001b[0m | \u001b[0m 1.174   \u001b[0m |\n",
      "| \u001b[0m 102     \u001b[0m | \u001b[0m-250.0   \u001b[0m | \u001b[0m 61.76   \u001b[0m | \u001b[0m 1.139   \u001b[0m |\n",
      "| \u001b[0m 103     \u001b[0m | \u001b[0m-260.0   \u001b[0m | \u001b[0m 61.01   \u001b[0m | \u001b[0m 1.161   \u001b[0m |\n",
      "| \u001b[0m 104     \u001b[0m | \u001b[0m-270.0   \u001b[0m | \u001b[0m 61.04   \u001b[0m | \u001b[0m 1.17    \u001b[0m |\n",
      "| \u001b[0m 105     \u001b[0m | \u001b[0m-300.0   \u001b[0m | \u001b[0m 61.33   \u001b[0m | \u001b[0m 1.335   \u001b[0m |\n",
      "| \u001b[0m 106     \u001b[0m | \u001b[0m-265.0   \u001b[0m | \u001b[0m 61.07   \u001b[0m | \u001b[0m 1.09    \u001b[0m |\n",
      "| \u001b[0m 107     \u001b[0m | \u001b[0m-265.0   \u001b[0m | \u001b[0m 61.33   \u001b[0m | \u001b[0m 1.09    \u001b[0m |\n",
      "| \u001b[0m 108     \u001b[0m | \u001b[0m-255.0   \u001b[0m | \u001b[0m 61.74   \u001b[0m | \u001b[0m 1.048   \u001b[0m |\n",
      "| \u001b[0m 109     \u001b[0m | \u001b[0m-250.0   \u001b[0m | \u001b[0m 61.02   \u001b[0m | \u001b[0m 1.141   \u001b[0m |\n",
      "| \u001b[0m 110     \u001b[0m | \u001b[0m-255.0   \u001b[0m | \u001b[0m 61.33   \u001b[0m | \u001b[0m 1.05    \u001b[0m |\n",
      "| \u001b[0m 111     \u001b[0m | \u001b[0m-255.0   \u001b[0m | \u001b[0m 61.14   \u001b[0m | \u001b[0m 1.033   \u001b[0m |\n",
      "| \u001b[95m 112     \u001b[0m | \u001b[95m-200.0   \u001b[0m | \u001b[95m 61.53   \u001b[0m | \u001b[95m 0.803   \u001b[0m |\n",
      "| \u001b[0m 113     \u001b[0m | \u001b[0m-260.0   \u001b[0m | \u001b[0m 61.83   \u001b[0m | \u001b[0m 1.149   \u001b[0m |\n",
      "| \u001b[0m 114     \u001b[0m | \u001b[0m-250.0   \u001b[0m | \u001b[0m 61.78   \u001b[0m | \u001b[0m 1.117   \u001b[0m |\n",
      "| \u001b[0m 115     \u001b[0m | \u001b[0m-260.0   \u001b[0m | \u001b[0m 61.17   \u001b[0m | \u001b[0m 0.9723  \u001b[0m |\n",
      "| \u001b[0m 116     \u001b[0m | \u001b[0m-245.0   \u001b[0m | \u001b[0m 61.56   \u001b[0m | \u001b[0m 1.006   \u001b[0m |\n",
      "| \u001b[0m 117     \u001b[0m | \u001b[0m-265.0   \u001b[0m | \u001b[0m 61.56   \u001b[0m | \u001b[0m 0.9486  \u001b[0m |\n",
      "| \u001b[0m 118     \u001b[0m | \u001b[0m-265.0   \u001b[0m | \u001b[0m 61.53   \u001b[0m | \u001b[0m 1.22    \u001b[0m |\n",
      "| \u001b[0m 119     \u001b[0m | \u001b[0m-255.0   \u001b[0m | \u001b[0m 61.77   \u001b[0m | \u001b[0m 1.015   \u001b[0m |\n",
      "| \u001b[0m 120     \u001b[0m | \u001b[0m-265.0   \u001b[0m | \u001b[0m 61.3    \u001b[0m | \u001b[0m 1.06    \u001b[0m |\n",
      "| \u001b[0m 121     \u001b[0m | \u001b[0m-250.0   \u001b[0m | \u001b[0m 61.56   \u001b[0m | \u001b[0m 0.9516  \u001b[0m |\n",
      "| \u001b[0m 122     \u001b[0m | \u001b[0m-260.0   \u001b[0m | \u001b[0m 61.04   \u001b[0m | \u001b[0m 1.143   \u001b[0m |\n",
      "| \u001b[0m 123     \u001b[0m | \u001b[0m-260.0   \u001b[0m | \u001b[0m 61.13   \u001b[0m | \u001b[0m 0.9677  \u001b[0m |\n",
      "| \u001b[0m 124     \u001b[0m | \u001b[0m-245.0   \u001b[0m | \u001b[0m 61.18   \u001b[0m | \u001b[0m 1.007   \u001b[0m |\n",
      "| \u001b[0m 125     \u001b[0m | \u001b[0m-290.0   \u001b[0m | \u001b[0m 61.53   \u001b[0m | \u001b[0m 0.904   \u001b[0m |\n",
      "| \u001b[0m 126     \u001b[0m | \u001b[0m-265.0   \u001b[0m | \u001b[0m 61.13   \u001b[0m | \u001b[0m 0.9477  \u001b[0m |\n",
      "| \u001b[0m 127     \u001b[0m | \u001b[0m-245.0   \u001b[0m | \u001b[0m 61.3    \u001b[0m | \u001b[0m 1.003   \u001b[0m |\n",
      "| \u001b[0m 128     \u001b[0m | \u001b[0m-265.0   \u001b[0m | \u001b[0m 61.46   \u001b[0m | \u001b[0m 1.211   \u001b[0m |\n",
      "| \u001b[0m 129     \u001b[0m | \u001b[0m-265.0   \u001b[0m | \u001b[0m 61.65   \u001b[0m | \u001b[0m 1.086   \u001b[0m |\n",
      "| \u001b[0m 130     \u001b[0m | \u001b[0m-260.0   \u001b[0m | \u001b[0m 61.1    \u001b[0m | \u001b[0m 0.9812  \u001b[0m |\n",
      "| \u001b[0m 131     \u001b[0m | \u001b[0m-265.0   \u001b[0m | \u001b[0m 61.63   \u001b[0m | \u001b[0m 1.212   \u001b[0m |\n",
      "| \u001b[0m 132     \u001b[0m | \u001b[0m-265.0   \u001b[0m | \u001b[0m 61.27   \u001b[0m | \u001b[0m 1.078   \u001b[0m |\n",
      "| \u001b[0m 133     \u001b[0m | \u001b[0m-260.0   \u001b[0m | \u001b[0m 61.87   \u001b[0m | \u001b[0m 1.152   \u001b[0m |\n",
      "| \u001b[0m 134     \u001b[0m | \u001b[0m-265.0   \u001b[0m | \u001b[0m 60.99   \u001b[0m | \u001b[0m 1.222   \u001b[0m |\n",
      "| \u001b[0m 135     \u001b[0m | \u001b[0m-265.0   \u001b[0m | \u001b[0m 61.83   \u001b[0m | \u001b[0m 1.085   \u001b[0m |\n",
      "| \u001b[0m 136     \u001b[0m | \u001b[0m-260.0   \u001b[0m | \u001b[0m 61.2    \u001b[0m | \u001b[0m 1.16    \u001b[0m |\n",
      "| \u001b[0m 137     \u001b[0m | \u001b[0m-250.0   \u001b[0m | \u001b[0m 61.12   \u001b[0m | \u001b[0m 1.251   \u001b[0m |\n",
      "| \u001b[0m 138     \u001b[0m | \u001b[0m-265.0   \u001b[0m | \u001b[0m 61.45   \u001b[0m | \u001b[0m 1.212   \u001b[0m |\n",
      "| \u001b[0m 139     \u001b[0m | \u001b[0m-265.0   \u001b[0m | \u001b[0m 61.2    \u001b[0m | \u001b[0m 1.068   \u001b[0m |\n",
      "| \u001b[0m 140     \u001b[0m | \u001b[0m-255.0   \u001b[0m | \u001b[0m 61.29   \u001b[0m | \u001b[0m 1.046   \u001b[0m |\n",
      "| \u001b[0m 141     \u001b[0m | \u001b[0m-275.0   \u001b[0m | \u001b[0m 61.4    \u001b[0m | \u001b[0m 1.234   \u001b[0m |\n",
      "| \u001b[0m 142     \u001b[0m | \u001b[0m-245.0   \u001b[0m | \u001b[0m 61.51   \u001b[0m | \u001b[0m 1.007   \u001b[0m |\n",
      "| \u001b[0m 143     \u001b[0m | \u001b[0m-250.0   \u001b[0m | \u001b[0m 61.25   \u001b[0m | \u001b[0m 1.137   \u001b[0m |\n",
      "| \u001b[0m 144     \u001b[0m | \u001b[0m-255.0   \u001b[0m | \u001b[0m 61.62   \u001b[0m | \u001b[0m 1.188   \u001b[0m |\n",
      "| \u001b[0m 145     \u001b[0m | \u001b[0m-250.0   \u001b[0m | \u001b[0m 61.19   \u001b[0m | \u001b[0m 1.118   \u001b[0m |\n",
      "| \u001b[0m 146     \u001b[0m | \u001b[0m-255.0   \u001b[0m | \u001b[0m 61.49   \u001b[0m | \u001b[0m 1.043   \u001b[0m |\n",
      "| \u001b[0m 147     \u001b[0m | \u001b[0m-235.0   \u001b[0m | \u001b[0m 61.27   \u001b[0m | \u001b[0m 0.9931  \u001b[0m |\n",
      "| \u001b[0m 148     \u001b[0m | \u001b[0m-250.0   \u001b[0m | \u001b[0m 61.08   \u001b[0m | \u001b[0m 1.123   \u001b[0m |\n",
      "| \u001b[0m 149     \u001b[0m | \u001b[0m-260.0   \u001b[0m | \u001b[0m 61.65   \u001b[0m | \u001b[0m 1.15    \u001b[0m |\n",
      "| \u001b[0m 150     \u001b[0m | \u001b[0m-265.0   \u001b[0m | \u001b[0m 61.43   \u001b[0m | \u001b[0m 1.227   \u001b[0m |\n",
      "| \u001b[0m 151     \u001b[0m | \u001b[0m-260.0   \u001b[0m | \u001b[0m 61.4    \u001b[0m | \u001b[0m 0.974   \u001b[0m |\n",
      "| \u001b[0m 152     \u001b[0m | \u001b[0m-265.0   \u001b[0m | \u001b[0m 61.77   \u001b[0m | \u001b[0m 1.085   \u001b[0m |\n",
      "| \u001b[0m 153     \u001b[0m | \u001b[0m-260.0   \u001b[0m | \u001b[0m 61.92   \u001b[0m | \u001b[0m 1.157   \u001b[0m |\n",
      "| \u001b[0m 154     \u001b[0m | \u001b[0m-240.0   \u001b[0m | \u001b[0m 61.54   \u001b[0m | \u001b[0m 0.86    \u001b[0m |\n",
      "| \u001b[0m 155     \u001b[0m | \u001b[0m-265.0   \u001b[0m | \u001b[0m 61.77   \u001b[0m | \u001b[0m 1.075   \u001b[0m |\n",
      "| \u001b[0m 156     \u001b[0m | \u001b[0m-255.0   \u001b[0m | \u001b[0m 61.54   \u001b[0m | \u001b[0m 1.017   \u001b[0m |\n",
      "| \u001b[0m 157     \u001b[0m | \u001b[0m-260.0   \u001b[0m | \u001b[0m 61.32   \u001b[0m | \u001b[0m 0.9794  \u001b[0m |\n",
      "| \u001b[0m 158     \u001b[0m | \u001b[0m-265.0   \u001b[0m | \u001b[0m 61.59   \u001b[0m | \u001b[0m 1.216   \u001b[0m |\n",
      "| \u001b[0m 159     \u001b[0m | \u001b[0m-250.0   \u001b[0m | \u001b[0m 61.25   \u001b[0m | \u001b[0m 1.119   \u001b[0m |\n",
      "| \u001b[0m 160     \u001b[0m | \u001b[0m-260.0   \u001b[0m | \u001b[0m 61.65   \u001b[0m | \u001b[0m 1.146   \u001b[0m |\n",
      "| \u001b[0m 161     \u001b[0m | \u001b[0m-260.0   \u001b[0m | \u001b[0m 61.9    \u001b[0m | \u001b[0m 1.155   \u001b[0m |\n",
      "| \u001b[0m 162     \u001b[0m | \u001b[0m-260.0   \u001b[0m | \u001b[0m 61.19   \u001b[0m | \u001b[0m 1.159   \u001b[0m |\n",
      "| \u001b[0m 163     \u001b[0m | \u001b[0m-255.0   \u001b[0m | \u001b[0m 61.8    \u001b[0m | \u001b[0m 1.017   \u001b[0m |\n",
      "| \u001b[0m 164     \u001b[0m | \u001b[0m-260.0   \u001b[0m | \u001b[0m 61.0    \u001b[0m | \u001b[0m 1.146   \u001b[0m |\n",
      "| \u001b[0m 165     \u001b[0m | \u001b[0m-275.0   \u001b[0m | \u001b[0m 61.22   \u001b[0m | \u001b[0m 0.9507  \u001b[0m |\n",
      "| \u001b[0m 166     \u001b[0m | \u001b[0m-255.0   \u001b[0m | \u001b[0m 61.34   \u001b[0m | \u001b[0m 1.021   \u001b[0m |\n",
      "| \u001b[0m 167     \u001b[0m | \u001b[0m-240.0   \u001b[0m | \u001b[0m 61.54   \u001b[0m | \u001b[0m 0.8618  \u001b[0m |\n",
      "| \u001b[0m 168     \u001b[0m | \u001b[0m-270.0   \u001b[0m | \u001b[0m 61.53   \u001b[0m | \u001b[0m 0.897   \u001b[0m |\n",
      "| \u001b[0m 169     \u001b[0m | \u001b[0m-265.0   \u001b[0m | \u001b[0m 61.77   \u001b[0m | \u001b[0m 1.195   \u001b[0m |\n",
      "| \u001b[0m 170     \u001b[0m | \u001b[0m-260.0   \u001b[0m | \u001b[0m 61.03   \u001b[0m | \u001b[0m 1.159   \u001b[0m |\n",
      "| \u001b[0m 171     \u001b[0m | \u001b[0m-275.0   \u001b[0m | \u001b[0m 61.12   \u001b[0m | \u001b[0m 1.232   \u001b[0m |\n",
      "| \u001b[0m 172     \u001b[0m | \u001b[0m-290.0   \u001b[0m | \u001b[0m 61.15   \u001b[0m | \u001b[0m 1.289   \u001b[0m |\n",
      "| \u001b[0m 173     \u001b[0m | \u001b[0m-235.0   \u001b[0m | \u001b[0m 61.55   \u001b[0m | \u001b[0m 0.9973  \u001b[0m |\n",
      "| \u001b[0m 174     \u001b[0m | \u001b[0m-260.0   \u001b[0m | \u001b[0m 61.13   \u001b[0m | \u001b[0m 1.146   \u001b[0m |\n",
      "| \u001b[0m 175     \u001b[0m | \u001b[0m-265.0   \u001b[0m | \u001b[0m 61.59   \u001b[0m | \u001b[0m 1.207   \u001b[0m |\n",
      "| \u001b[0m 176     \u001b[0m | \u001b[0m-245.0   \u001b[0m | \u001b[0m 61.31   \u001b[0m | \u001b[0m 1.002   \u001b[0m |\n",
      "| \u001b[0m 177     \u001b[0m | \u001b[0m-255.0   \u001b[0m | \u001b[0m 61.86   \u001b[0m | \u001b[0m 1.03    \u001b[0m |\n",
      "| \u001b[0m 178     \u001b[0m | \u001b[0m-260.0   \u001b[0m | \u001b[0m 61.14   \u001b[0m | \u001b[0m 0.9699  \u001b[0m |\n",
      "| \u001b[0m 179     \u001b[0m | \u001b[0m-260.0   \u001b[0m | \u001b[0m 61.65   \u001b[0m | \u001b[0m 1.151   \u001b[0m |\n",
      "| \u001b[0m 180     \u001b[0m | \u001b[0m-275.0   \u001b[0m | \u001b[0m 61.08   \u001b[0m | \u001b[0m 1.107   \u001b[0m |\n",
      "| \u001b[0m 181     \u001b[0m | \u001b[0m-275.0   \u001b[0m | \u001b[0m 61.8    \u001b[0m | \u001b[0m 1.11    \u001b[0m |\n",
      "| \u001b[0m 182     \u001b[0m | \u001b[0m-245.0   \u001b[0m | \u001b[0m 61.28   \u001b[0m | \u001b[0m 1.01    \u001b[0m |\n",
      "| \u001b[0m 183     \u001b[0m | \u001b[0m-260.0   \u001b[0m | \u001b[0m 61.07   \u001b[0m | \u001b[0m 1.147   \u001b[0m |\n",
      "| \u001b[0m 184     \u001b[0m | \u001b[0m-255.0   \u001b[0m | \u001b[0m 61.39   \u001b[0m | \u001b[0m 1.029   \u001b[0m |\n",
      "| \u001b[0m 185     \u001b[0m | \u001b[0m-250.0   \u001b[0m | \u001b[0m 61.11   \u001b[0m | \u001b[0m 1.252   \u001b[0m |\n",
      "| \u001b[0m 186     \u001b[0m | \u001b[0m-250.0   \u001b[0m | \u001b[0m 61.31   \u001b[0m | \u001b[0m 1.14    \u001b[0m |\n",
      "| \u001b[95m 187     \u001b[0m | \u001b[95m-155.0   \u001b[0m | \u001b[95m 61.53   \u001b[0m | \u001b[95m 0.7749  \u001b[0m |\n",
      "| \u001b[0m 188     \u001b[0m | \u001b[0m-245.0   \u001b[0m | \u001b[0m 61.57   \u001b[0m | \u001b[0m 1.007   \u001b[0m |\n",
      "| \u001b[0m 189     \u001b[0m | \u001b[0m-155.0   \u001b[0m | \u001b[0m 61.51   \u001b[0m | \u001b[0m 0.7666  \u001b[0m |\n",
      "| \u001b[0m 190     \u001b[0m | \u001b[0m-250.0   \u001b[0m | \u001b[0m 61.14   \u001b[0m | \u001b[0m 1.141   \u001b[0m |\n",
      "| \u001b[0m 191     \u001b[0m | \u001b[0m-270.0   \u001b[0m | \u001b[0m 61.93   \u001b[0m | \u001b[0m 1.169   \u001b[0m |\n",
      "| \u001b[0m 192     \u001b[0m | \u001b[0m-255.0   \u001b[0m | \u001b[0m 61.15   \u001b[0m | \u001b[0m 1.018   \u001b[0m |\n",
      "| \u001b[0m 193     \u001b[0m | \u001b[0m-255.0   \u001b[0m | \u001b[0m 61.59   \u001b[0m | \u001b[0m 1.192   \u001b[0m |\n",
      "| \u001b[0m 194     \u001b[0m | \u001b[0m-250.0   \u001b[0m | \u001b[0m 61.24   \u001b[0m | \u001b[0m 1.118   \u001b[0m |\n",
      "| \u001b[0m 195     \u001b[0m | \u001b[0m-250.0   \u001b[0m | \u001b[0m 61.12   \u001b[0m | \u001b[0m 1.119   \u001b[0m |\n",
      "| \u001b[0m 196     \u001b[0m | \u001b[0m-275.0   \u001b[0m | \u001b[0m 61.23   \u001b[0m | \u001b[0m 1.105   \u001b[0m |\n",
      "| \u001b[0m 197     \u001b[0m | \u001b[0m-265.0   \u001b[0m | \u001b[0m 61.55   \u001b[0m | \u001b[0m 1.23    \u001b[0m |\n",
      "| \u001b[0m 198     \u001b[0m | \u001b[0m-250.0   \u001b[0m | \u001b[0m 61.67   \u001b[0m | \u001b[0m 1.121   \u001b[0m |\n",
      "| \u001b[95m 199     \u001b[0m | \u001b[95m-125.0   \u001b[0m | \u001b[95m 61.58   \u001b[0m | \u001b[95m 0.7182  \u001b[0m |\n",
      "| \u001b[0m 200     \u001b[0m | \u001b[0m-255.0   \u001b[0m | \u001b[0m 61.56   \u001b[0m | \u001b[0m 1.055   \u001b[0m |\n",
      "| \u001b[0m 201     \u001b[0m | \u001b[0m-255.0   \u001b[0m | \u001b[0m 61.74   \u001b[0m | \u001b[0m 1.041   \u001b[0m |\n",
      "| \u001b[0m 202     \u001b[0m | \u001b[0m-125.0   \u001b[0m | \u001b[0m 61.49   \u001b[0m | \u001b[0m 0.7351  \u001b[0m |\n",
      "| \u001b[0m 203     \u001b[0m | \u001b[0m-250.0   \u001b[0m | \u001b[0m 61.58   \u001b[0m | \u001b[0m 1.251   \u001b[0m |\n",
      "| \u001b[0m 204     \u001b[0m | \u001b[0m-260.0   \u001b[0m | \u001b[0m 61.58   \u001b[0m | \u001b[0m 1.257   \u001b[0m |\n",
      "| \u001b[0m 205     \u001b[0m | \u001b[0m-250.0   \u001b[0m | \u001b[0m 61.11   \u001b[0m | \u001b[0m 1.121   \u001b[0m |\n",
      "| \u001b[0m 206     \u001b[0m | \u001b[0m-125.0   \u001b[0m | \u001b[0m 61.32   \u001b[0m | \u001b[0m 0.7331  \u001b[0m |\n",
      "| \u001b[0m 207     \u001b[0m | \u001b[0m-265.0   \u001b[0m | \u001b[0m 61.19   \u001b[0m | \u001b[0m 1.063   \u001b[0m |\n",
      "| \u001b[0m 208     \u001b[0m | \u001b[0m-260.0   \u001b[0m | \u001b[0m 61.01   \u001b[0m | \u001b[0m 1.145   \u001b[0m |\n",
      "| \u001b[0m 209     \u001b[0m | \u001b[0m-155.0   \u001b[0m | \u001b[0m 61.49   \u001b[0m | \u001b[0m 0.7588  \u001b[0m |\n",
      "| \u001b[0m 210     \u001b[0m | \u001b[0m-200.0   \u001b[0m | \u001b[0m 61.45   \u001b[0m | \u001b[0m 0.7996  \u001b[0m |\n",
      "| \u001b[0m 211     \u001b[0m | \u001b[0m-255.0   \u001b[0m | \u001b[0m 61.26   \u001b[0m | \u001b[0m 1.025   \u001b[0m |\n",
      "| \u001b[0m 212     \u001b[0m | \u001b[0m-165.0   \u001b[0m | \u001b[0m 61.5    \u001b[0m | \u001b[0m 0.7793  \u001b[0m |\n",
      "| \u001b[0m 213     \u001b[0m | \u001b[0m-260.0   \u001b[0m | \u001b[0m 60.99   \u001b[0m | \u001b[0m 1.154   \u001b[0m |\n",
      "| \u001b[0m 214     \u001b[0m | \u001b[0m-250.0   \u001b[0m | \u001b[0m 61.65   \u001b[0m | \u001b[0m 1.121   \u001b[0m |\n",
      "| \u001b[0m 215     \u001b[0m | \u001b[0m-245.0   \u001b[0m | \u001b[0m 61.24   \u001b[0m | \u001b[0m 1.005   \u001b[0m |\n",
      "| \u001b[0m 216     \u001b[0m | \u001b[0m-125.0   \u001b[0m | \u001b[0m 61.34   \u001b[0m | \u001b[0m 0.7088  \u001b[0m |\n",
      "| \u001b[0m 217     \u001b[0m | \u001b[0m-260.0   \u001b[0m | \u001b[0m 61.3    \u001b[0m | \u001b[0m 0.9633  \u001b[0m |\n",
      "| \u001b[0m 218     \u001b[0m | \u001b[0m-200.0   \u001b[0m | \u001b[0m 61.35   \u001b[0m | \u001b[0m 0.8167  \u001b[0m |\n",
      "| \u001b[0m 219     \u001b[0m | \u001b[0m-260.0   \u001b[0m | \u001b[0m 61.31   \u001b[0m | \u001b[0m 0.9823  \u001b[0m |\n",
      "| \u001b[0m 220     \u001b[0m | \u001b[0m-150.0   \u001b[0m | \u001b[0m 61.55   \u001b[0m | \u001b[0m 0.6887  \u001b[0m |\n",
      "| \u001b[0m 221     \u001b[0m | \u001b[0m-260.0   \u001b[0m | \u001b[0m 61.0    \u001b[0m | \u001b[0m 1.154   \u001b[0m |\n",
      "| \u001b[0m 222     \u001b[0m | \u001b[0m-130.0   \u001b[0m | \u001b[0m 61.34   \u001b[0m | \u001b[0m 0.6664  \u001b[0m |\n",
      "| \u001b[95m 223     \u001b[0m | \u001b[95m-120.0   \u001b[0m | \u001b[95m 61.56   \u001b[0m | \u001b[95m 0.6413  \u001b[0m |\n",
      "| \u001b[0m 224     \u001b[0m | \u001b[0m-250.0   \u001b[0m | \u001b[0m 61.68   \u001b[0m | \u001b[0m 1.129   \u001b[0m |\n",
      "| \u001b[0m 225     \u001b[0m | \u001b[0m-250.0   \u001b[0m | \u001b[0m 61.84   \u001b[0m | \u001b[0m 1.135   \u001b[0m |\n",
      "| \u001b[0m 226     \u001b[0m | \u001b[0m-120.0   \u001b[0m | \u001b[0m 61.36   \u001b[0m | \u001b[0m 0.6532  \u001b[0m |\n",
      "| \u001b[0m 227     \u001b[0m | \u001b[0m-155.0   \u001b[0m | \u001b[0m 61.32   \u001b[0m | \u001b[0m 0.7631  \u001b[0m |\n",
      "| \u001b[0m 228     \u001b[0m | \u001b[0m-255.0   \u001b[0m | \u001b[0m 61.53   \u001b[0m | \u001b[0m 1.048   \u001b[0m |\n",
      "| \u001b[0m 229     \u001b[0m | \u001b[0m-265.0   \u001b[0m | \u001b[0m 61.05   \u001b[0m | \u001b[0m 1.078   \u001b[0m |\n",
      "| \u001b[0m 230     \u001b[0m | \u001b[0m-125.0   \u001b[0m | \u001b[0m 61.55   \u001b[0m | \u001b[0m 0.7194  \u001b[0m |\n",
      "| \u001b[0m 231     \u001b[0m | \u001b[0m-125.0   \u001b[0m | \u001b[0m 61.33   \u001b[0m | \u001b[0m 0.7184  \u001b[0m |\n",
      "| \u001b[0m 232     \u001b[0m | \u001b[0m-135.0   \u001b[0m | \u001b[0m 61.29   \u001b[0m | \u001b[0m 0.749   \u001b[0m |\n",
      "| \u001b[0m 233     \u001b[0m | \u001b[0m-220.0   \u001b[0m | \u001b[0m 61.53   \u001b[0m | \u001b[0m 0.8291  \u001b[0m |\n",
      "| \u001b[0m 234     \u001b[0m | \u001b[0m-140.0   \u001b[0m | \u001b[0m 61.76   \u001b[0m | \u001b[0m 0.6773  \u001b[0m |\n",
      "| \u001b[0m 235     \u001b[0m | \u001b[0m-275.0   \u001b[0m | \u001b[0m 61.69   \u001b[0m | \u001b[0m 1.112   \u001b[0m |\n",
      "| \u001b[0m 236     \u001b[0m | \u001b[0m-125.0   \u001b[0m | \u001b[0m 61.37   \u001b[0m | \u001b[0m 0.6005  \u001b[0m |\n",
      "| \u001b[0m 237     \u001b[0m | \u001b[0m-250.0   \u001b[0m | \u001b[0m 61.84   \u001b[0m | \u001b[0m 1.13    \u001b[0m |\n",
      "| \u001b[0m 238     \u001b[0m | \u001b[0m-120.0   \u001b[0m | \u001b[0m 61.34   \u001b[0m | \u001b[0m 0.6406  \u001b[0m |\n",
      "| \u001b[0m 239     \u001b[0m | \u001b[0m-130.0   \u001b[0m | \u001b[0m 61.58   \u001b[0m | \u001b[0m 0.6731  \u001b[0m |\n",
      "| \u001b[0m 240     \u001b[0m | \u001b[0m-120.0   \u001b[0m | \u001b[0m 61.75   \u001b[0m | \u001b[0m 0.6504  \u001b[0m |\n",
      "| \u001b[0m 241     \u001b[0m | \u001b[0m-250.0   \u001b[0m | \u001b[0m 61.27   \u001b[0m | \u001b[0m 1.136   \u001b[0m |\n",
      "| \u001b[0m 242     \u001b[0m | \u001b[0m-125.0   \u001b[0m | \u001b[0m 61.58   \u001b[0m | \u001b[0m 0.7353  \u001b[0m |\n",
      "| \u001b[0m 243     \u001b[0m | \u001b[0m-120.0   \u001b[0m | \u001b[0m 61.66   \u001b[0m | \u001b[0m 0.639   \u001b[0m |\n",
      "| \u001b[0m 244     \u001b[0m | \u001b[0m-260.0   \u001b[0m | \u001b[0m 61.29   \u001b[0m | \u001b[0m 0.9628  \u001b[0m |\n",
      "| \u001b[0m 245     \u001b[0m | \u001b[0m-150.0   \u001b[0m | \u001b[0m 61.71   \u001b[0m | \u001b[0m 0.6911  \u001b[0m |\n",
      "| \u001b[0m 246     \u001b[0m | \u001b[0m-135.0   \u001b[0m | \u001b[0m 61.67   \u001b[0m | \u001b[0m 0.6349  \u001b[0m |\n",
      "| \u001b[0m 247     \u001b[0m | \u001b[0m-125.0   \u001b[0m | \u001b[0m 61.37   \u001b[0m | \u001b[0m 0.7137  \u001b[0m |\n",
      "| \u001b[0m 248     \u001b[0m | \u001b[0m-200.0   \u001b[0m | \u001b[0m 61.53   \u001b[0m | \u001b[0m 0.8004  \u001b[0m |\n",
      "| \u001b[0m 249     \u001b[0m | \u001b[0m-165.0   \u001b[0m | \u001b[0m 61.69   \u001b[0m | \u001b[0m 0.781   \u001b[0m |\n",
      "| \u001b[0m 250     \u001b[0m | \u001b[0m-135.0   \u001b[0m | \u001b[0m 61.35   \u001b[0m | \u001b[0m 0.6245  \u001b[0m |\n",
      "| \u001b[0m 251     \u001b[0m | \u001b[0m-130.0   \u001b[0m | \u001b[0m 61.79   \u001b[0m | \u001b[0m 0.6631  \u001b[0m |\n",
      "| \u001b[0m 252     \u001b[0m | \u001b[0m-125.0   \u001b[0m | \u001b[0m 61.34   \u001b[0m | \u001b[0m 0.7121  \u001b[0m |\n",
      "| \u001b[0m 253     \u001b[0m | \u001b[0m-200.0   \u001b[0m | \u001b[0m 61.48   \u001b[0m | \u001b[0m 0.7961  \u001b[0m |\n",
      "| \u001b[0m 254     \u001b[0m | \u001b[0m-200.0   \u001b[0m | \u001b[0m 61.69   \u001b[0m | \u001b[0m 0.8033  \u001b[0m |\n",
      "| \u001b[0m 255     \u001b[0m | \u001b[0m-120.0   \u001b[0m | \u001b[0m 61.48   \u001b[0m | \u001b[0m 0.6411  \u001b[0m |\n",
      "=================================================\n"
     ]
    }
   ],
   "source": [
    "optimization_svm = BayesianOptimization(evaluateSvm, params_svm, random_state=231)\n",
    "optimization_svm.maximize(n_iter=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': -120.0,\n",
       " 'params': {'C': 61.559671025178, 'gamma': 0.6412512564360546}}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimization_svm.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM - Poly kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateSvm_Poly(C, gamma, degree):\n",
    "    \n",
    "    model = SVC(C=C, gamma=gamma, degree=degree, kernel='poly', random_state=231)\n",
    "    \n",
    "    return cross_val_imbalanced(model, X_train_prepared, y_train, SMOTE(random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_svm_poly = {\n",
    "    'C': (1, 1000),\n",
    "    'gamma': (0.001, 10),\n",
    "    'degree': (1, 10)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'evaluateSvm_Poly' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-b911941e91d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moptimization_svm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBayesianOptimization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluateSvm_Poly\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_svm_poly\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m231\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0moptimization_svm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'evaluateSvm_Poly' is not defined"
     ]
    }
   ],
   "source": [
    "optimization_svm = BayesianOptimization(evaluateSvm_Poly, params_svm_poly, random_state=231)\n",
    "optimization_svm.maximize(n_iter=250, init_points=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': -120.0,\n",
       " 'params': {'C': 61.559671025178, 'gamma': 0.6412512564360546}}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimization_svm.max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateXgb(max_depth, n_estimators, gamma, reg_alpha, reg_lambda):\n",
    "    \n",
    "    model = XGBClassifier(max_depth=int(max_depth), n_estimators=int(n_estimators), gamma=gamma,\n",
    "                          reg_alpha=reg_alpha, reg_lambda=reg_lambda, n_jobs=-1, random_state=231)\n",
    "    \n",
    "    return cross_val_imbalanced(model, X_train_prepared, y_train, SMOTE(random_state=42))\n",
    "    \n",
    "#     cv_results = cross_val_score(model, X_train_prepared, y_train, cv=10, scoring=profit_scoring)\n",
    "    \n",
    "#     return np.mean(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_xgb = {\n",
    "    'max_depth': (1, 10),\n",
    "    'n_estimators': (25, 500),\n",
    "    'gamma': (0, 1),\n",
    "    'reg_alpha': (1e-9, 0.1),\n",
    "    'reg_lambda': (1e-9, 0.1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |   gamma   | max_depth | n_esti... | reg_alpha | reg_la... |\n",
      "-------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 80.0    \u001b[0m | \u001b[0m 0.7815  \u001b[0m | \u001b[0m 6.258   \u001b[0m | \u001b[0m 227.7   \u001b[0m | \u001b[0m 0.03153 \u001b[0m | \u001b[0m 0.08269 \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-45.0    \u001b[0m | \u001b[0m 0.9034  \u001b[0m | \u001b[0m 1.35    \u001b[0m | \u001b[0m 459.7   \u001b[0m | \u001b[0m 0.006051\u001b[0m | \u001b[0m 0.01807 \u001b[0m |\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m 85.0    \u001b[0m | \u001b[95m 0.0723  \u001b[0m | \u001b[95m 5.129   \u001b[0m | \u001b[95m 361.5   \u001b[0m | \u001b[95m 0.04832 \u001b[0m | \u001b[95m 0.002545\u001b[0m |\n",
      "| \u001b[95m 4       \u001b[0m | \u001b[95m 90.0    \u001b[0m | \u001b[95m 0.0669  \u001b[0m | \u001b[95m 4.833   \u001b[0m | \u001b[95m 129.1   \u001b[0m | \u001b[95m 0.08101 \u001b[0m | \u001b[95m 0.01401 \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 70.0    \u001b[0m | \u001b[0m 0.7512  \u001b[0m | \u001b[0m 3.512   \u001b[0m | \u001b[0m 475.8   \u001b[0m | \u001b[0m 0.0885  \u001b[0m | \u001b[0m 0.06102 \u001b[0m |\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m 105.0   \u001b[0m | \u001b[95m 0.7949  \u001b[0m | \u001b[95m 2.237   \u001b[0m | \u001b[95m 482.8   \u001b[0m | \u001b[95m 0.04659 \u001b[0m | \u001b[95m 0.02334 \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 80.0    \u001b[0m | \u001b[0m 0.7867  \u001b[0m | \u001b[0m 2.412   \u001b[0m | \u001b[0m 482.8   \u001b[0m | \u001b[0m 0.04806 \u001b[0m | \u001b[0m 0.0264  \u001b[0m |\n",
      "| \u001b[95m 8       \u001b[0m | \u001b[95m 130.0   \u001b[0m | \u001b[95m 0.7563  \u001b[0m | \u001b[95m 2.265   \u001b[0m | \u001b[95m 482.7   \u001b[0m | \u001b[95m 0.000928\u001b[0m | \u001b[95m 0.02224 \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 80.0    \u001b[0m | \u001b[0m 0.8811  \u001b[0m | \u001b[0m 2.218   \u001b[0m | \u001b[0m 482.9   \u001b[0m | \u001b[0m 0.09351 \u001b[0m | \u001b[0m 0.06362 \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 80.0    \u001b[0m | \u001b[0m 0.8012  \u001b[0m | \u001b[0m 2.075   \u001b[0m | \u001b[0m 482.6   \u001b[0m | \u001b[0m 0.08242 \u001b[0m | \u001b[0m 0.01291 \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 90.0    \u001b[0m | \u001b[0m 0.07755 \u001b[0m | \u001b[0m 4.842   \u001b[0m | \u001b[0m 129.1   \u001b[0m | \u001b[0m 0.03552 \u001b[0m | \u001b[0m 0.07211 \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 105.0   \u001b[0m | \u001b[0m 0.7582  \u001b[0m | \u001b[0m 2.26    \u001b[0m | \u001b[0m 482.7   \u001b[0m | \u001b[0m 0.003281\u001b[0m | \u001b[0m 0.02194 \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 105.0   \u001b[0m | \u001b[0m 0.7614  \u001b[0m | \u001b[0m 2.244   \u001b[0m | \u001b[0m 482.9   \u001b[0m | \u001b[0m 0.09751 \u001b[0m | \u001b[0m 0.02839 \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 85.0    \u001b[0m | \u001b[0m 0.04125 \u001b[0m | \u001b[0m 5.21    \u001b[0m | \u001b[0m 361.6   \u001b[0m | \u001b[0m 0.09202 \u001b[0m | \u001b[0m 0.005598\u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 70.0    \u001b[0m | \u001b[0m 0.7836  \u001b[0m | \u001b[0m 2.314   \u001b[0m | \u001b[0m 482.9   \u001b[0m | \u001b[0m 0.01484 \u001b[0m | \u001b[0m 0.06957 \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 70.0    \u001b[0m | \u001b[0m 0.4586  \u001b[0m | \u001b[0m 8.163   \u001b[0m | \u001b[0m 453.7   \u001b[0m | \u001b[0m 0.002367\u001b[0m | \u001b[0m 0.0334  \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 80.0    \u001b[0m | \u001b[0m 0.3857  \u001b[0m | \u001b[0m 9.066   \u001b[0m | \u001b[0m 166.0   \u001b[0m | \u001b[0m 0.01486 \u001b[0m | \u001b[0m 0.03448 \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 80.0    \u001b[0m | \u001b[0m 0.7626  \u001b[0m | \u001b[0m 2.232   \u001b[0m | \u001b[0m 482.8   \u001b[0m | \u001b[0m 0.05525 \u001b[0m | \u001b[0m 0.01901 \u001b[0m |\n",
      "| \u001b[95m 19      \u001b[0m | \u001b[95m 135.0   \u001b[0m | \u001b[95m 0.3537  \u001b[0m | \u001b[95m 3.118   \u001b[0m | \u001b[95m 227.4   \u001b[0m | \u001b[95m 0.07415 \u001b[0m | \u001b[95m 0.05123 \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-45.0    \u001b[0m | \u001b[0m 0.7707  \u001b[0m | \u001b[0m 2.024   \u001b[0m | \u001b[0m 100.4   \u001b[0m | \u001b[0m 0.09377 \u001b[0m | \u001b[0m 0.05643 \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 105.0   \u001b[0m | \u001b[0m 0.7579  \u001b[0m | \u001b[0m 2.102   \u001b[0m | \u001b[0m 482.6   \u001b[0m | \u001b[0m 0.08173 \u001b[0m | \u001b[0m 0.006715\u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 90.0    \u001b[0m | \u001b[0m 0.03078 \u001b[0m | \u001b[0m 4.882   \u001b[0m | \u001b[0m 129.1   \u001b[0m | \u001b[0m 0.01928 \u001b[0m | \u001b[0m 0.07614 \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 85.0    \u001b[0m | \u001b[0m 0.1429  \u001b[0m | \u001b[0m 5.082   \u001b[0m | \u001b[0m 361.5   \u001b[0m | \u001b[0m 0.004594\u001b[0m | \u001b[0m 0.0198  \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 90.0    \u001b[0m | \u001b[0m 0.7836  \u001b[0m | \u001b[0m 2.037   \u001b[0m | \u001b[0m 482.6   \u001b[0m | \u001b[0m 0.08373 \u001b[0m | \u001b[0m 0.01961 \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 80.0    \u001b[0m | \u001b[0m 0.7628  \u001b[0m | \u001b[0m 2.184   \u001b[0m | \u001b[0m 482.8   \u001b[0m | \u001b[0m 0.0442  \u001b[0m | \u001b[0m 0.03754 \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 80.0    \u001b[0m | \u001b[0m 0.7165  \u001b[0m | \u001b[0m 2.296   \u001b[0m | \u001b[0m 482.8   \u001b[0m | \u001b[0m 0.05906 \u001b[0m | \u001b[0m 0.03799 \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 120.0   \u001b[0m | \u001b[0m 0.6639  \u001b[0m | \u001b[0m 2.166   \u001b[0m | \u001b[0m 482.8   \u001b[0m | \u001b[0m 0.03271 \u001b[0m | \u001b[0m 0.006578\u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 95.0    \u001b[0m | \u001b[0m 0.1955  \u001b[0m | \u001b[0m 5.12    \u001b[0m | \u001b[0m 361.4   \u001b[0m | \u001b[0m 0.0916  \u001b[0m | \u001b[0m 0.03953 \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 95.0    \u001b[0m | \u001b[0m 0.2595  \u001b[0m | \u001b[0m 5.122   \u001b[0m | \u001b[0m 361.4   \u001b[0m | \u001b[0m 0.0666  \u001b[0m | \u001b[0m 0.09352 \u001b[0m |\n",
      "| \u001b[95m 30      \u001b[0m | \u001b[95m 160.0   \u001b[0m | \u001b[95m 0.308   \u001b[0m | \u001b[95m 3.169   \u001b[0m | \u001b[95m 227.4   \u001b[0m | \u001b[95m 0.04137 \u001b[0m | \u001b[95m 0.03117 \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m 55.0    \u001b[0m | \u001b[0m 0.2159  \u001b[0m | \u001b[0m 8.521   \u001b[0m | \u001b[0m 442.0   \u001b[0m | \u001b[0m 0.01847 \u001b[0m | \u001b[0m 0.03674 \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 150.0   \u001b[0m | \u001b[0m 0.3697  \u001b[0m | \u001b[0m 3.059   \u001b[0m | \u001b[0m 227.4   \u001b[0m | \u001b[0m 0.0123  \u001b[0m | \u001b[0m 0.09239 \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 80.0    \u001b[0m | \u001b[0m 0.8226  \u001b[0m | \u001b[0m 2.466   \u001b[0m | \u001b[0m 259.0   \u001b[0m | \u001b[0m 0.02269 \u001b[0m | \u001b[0m 0.08692 \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m 90.0    \u001b[0m | \u001b[0m 0.06842 \u001b[0m | \u001b[0m 9.801   \u001b[0m | \u001b[0m 151.8   \u001b[0m | \u001b[0m 0.07577 \u001b[0m | \u001b[0m 0.01566 \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m-110.0   \u001b[0m | \u001b[0m 0.8896  \u001b[0m | \u001b[0m 6.646   \u001b[0m | \u001b[0m 28.57   \u001b[0m | \u001b[0m 0.05794 \u001b[0m | \u001b[0m 0.05679 \u001b[0m |\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m 35.0    \u001b[0m | \u001b[0m 0.8302  \u001b[0m | \u001b[0m 6.304   \u001b[0m | \u001b[0m 227.7   \u001b[0m | \u001b[0m 0.06812 \u001b[0m | \u001b[0m 0.05741 \u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m 135.0   \u001b[0m | \u001b[0m 0.2985  \u001b[0m | \u001b[0m 3.096   \u001b[0m | \u001b[0m 227.4   \u001b[0m | \u001b[0m 0.00945 \u001b[0m | \u001b[0m 0.03164 \u001b[0m |\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m 75.0    \u001b[0m | \u001b[0m 0.09201 \u001b[0m | \u001b[0m 5.139   \u001b[0m | \u001b[0m 361.4   \u001b[0m | \u001b[0m 0.04372 \u001b[0m | \u001b[0m 0.01814 \u001b[0m |\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m 145.0   \u001b[0m | \u001b[0m 0.2607  \u001b[0m | \u001b[0m 3.044   \u001b[0m | \u001b[0m 227.3   \u001b[0m | \u001b[0m 0.04456 \u001b[0m | \u001b[0m 0.04098 \u001b[0m |\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m 85.0    \u001b[0m | \u001b[0m 0.0513  \u001b[0m | \u001b[0m 5.829   \u001b[0m | \u001b[0m 269.5   \u001b[0m | \u001b[0m 0.02437 \u001b[0m | \u001b[0m 0.05527 \u001b[0m |\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m 105.0   \u001b[0m | \u001b[0m 0.7144  \u001b[0m | \u001b[0m 2.089   \u001b[0m | \u001b[0m 482.7   \u001b[0m | \u001b[0m 0.04701 \u001b[0m | \u001b[0m 0.01032 \u001b[0m |\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m 115.0   \u001b[0m | \u001b[0m 0.2964  \u001b[0m | \u001b[0m 3.144   \u001b[0m | \u001b[0m 227.5   \u001b[0m | \u001b[0m 0.02615 \u001b[0m | \u001b[0m 0.01304 \u001b[0m |\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m 160.0   \u001b[0m | \u001b[0m 0.2476  \u001b[0m | \u001b[0m 3.11    \u001b[0m | \u001b[0m 227.4   \u001b[0m | \u001b[0m 0.05001 \u001b[0m | \u001b[0m 0.02669 \u001b[0m |\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m 55.0    \u001b[0m | \u001b[0m 0.8958  \u001b[0m | \u001b[0m 3.176   \u001b[0m | \u001b[0m 419.0   \u001b[0m | \u001b[0m 0.02402 \u001b[0m | \u001b[0m 0.04087 \u001b[0m |\n",
      "| \u001b[0m 45      \u001b[0m | \u001b[0m 90.0    \u001b[0m | \u001b[0m 0.09298 \u001b[0m | \u001b[0m 4.859   \u001b[0m | \u001b[0m 129.2   \u001b[0m | \u001b[0m 0.008801\u001b[0m | \u001b[0m 0.04748 \u001b[0m |\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m 90.0    \u001b[0m | \u001b[0m 0.02642 \u001b[0m | \u001b[0m 4.9     \u001b[0m | \u001b[0m 129.1   \u001b[0m | \u001b[0m 0.05403 \u001b[0m | \u001b[0m 0.08028 \u001b[0m |\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m 85.0    \u001b[0m | \u001b[0m 0.06502 \u001b[0m | \u001b[0m 5.746   \u001b[0m | \u001b[0m 269.5   \u001b[0m | \u001b[0m 0.04349 \u001b[0m | \u001b[0m 0.0427  \u001b[0m |\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m-650.0   \u001b[0m | \u001b[0m 0.537   \u001b[0m | \u001b[0m 3.777   \u001b[0m | \u001b[0m 33.97   \u001b[0m | \u001b[0m 0.002813\u001b[0m | \u001b[0m 0.07109 \u001b[0m |\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m 125.0   \u001b[0m | \u001b[0m 0.3628  \u001b[0m | \u001b[0m 3.135   \u001b[0m | \u001b[0m 227.4   \u001b[0m | \u001b[0m 0.05098 \u001b[0m | \u001b[0m 0.08359 \u001b[0m |\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m 125.0   \u001b[0m | \u001b[0m 0.3519  \u001b[0m | \u001b[0m 3.012   \u001b[0m | \u001b[0m 227.4   \u001b[0m | \u001b[0m 0.02264 \u001b[0m | \u001b[0m 0.04756 \u001b[0m |\n",
      "| \u001b[0m 51      \u001b[0m | \u001b[0m 75.0    \u001b[0m | \u001b[0m 0.06786 \u001b[0m | \u001b[0m 5.836   \u001b[0m | \u001b[0m 269.4   \u001b[0m | \u001b[0m 0.02671 \u001b[0m | \u001b[0m 0.0517  \u001b[0m |\n",
      "| \u001b[0m 52      \u001b[0m | \u001b[0m 90.0    \u001b[0m | \u001b[0m 0.7781  \u001b[0m | \u001b[0m 2.07    \u001b[0m | \u001b[0m 482.7   \u001b[0m | \u001b[0m 0.04909 \u001b[0m | \u001b[0m 0.06209 \u001b[0m |\n",
      "| \u001b[0m 53      \u001b[0m | \u001b[0m 95.0    \u001b[0m | \u001b[0m 0.2599  \u001b[0m | \u001b[0m 5.214   \u001b[0m | \u001b[0m 361.4   \u001b[0m | \u001b[0m 0.006053\u001b[0m | \u001b[0m 0.06969 \u001b[0m |\n",
      "| \u001b[0m 54      \u001b[0m | \u001b[0m 75.0    \u001b[0m | \u001b[0m 0.4019  \u001b[0m | \u001b[0m 3.109   \u001b[0m | \u001b[0m 227.4   \u001b[0m | \u001b[0m 0.02574 \u001b[0m | \u001b[0m 0.06566 \u001b[0m |\n",
      "| \u001b[0m 55      \u001b[0m | \u001b[0m 95.0    \u001b[0m | \u001b[0m 0.1823  \u001b[0m | \u001b[0m 5.307   \u001b[0m | \u001b[0m 361.4   \u001b[0m | \u001b[0m 0.09713 \u001b[0m | \u001b[0m 0.07147 \u001b[0m |\n",
      "| \u001b[0m 56      \u001b[0m | \u001b[0m 125.0   \u001b[0m | \u001b[0m 0.3781  \u001b[0m | \u001b[0m 3.067   \u001b[0m | \u001b[0m 227.4   \u001b[0m | \u001b[0m 0.000681\u001b[0m | \u001b[0m 0.02061 \u001b[0m |\n",
      "| \u001b[0m 57      \u001b[0m | \u001b[0m 55.0    \u001b[0m | \u001b[0m 0.8453  \u001b[0m | \u001b[0m 2.412   \u001b[0m | \u001b[0m 259.0   \u001b[0m | \u001b[0m 0.02947 \u001b[0m | \u001b[0m 0.09447 \u001b[0m |\n",
      "| \u001b[0m 58      \u001b[0m | \u001b[0m 110.0   \u001b[0m | \u001b[0m 0.4482  \u001b[0m | \u001b[0m 3.158   \u001b[0m | \u001b[0m 227.4   \u001b[0m | \u001b[0m 0.06775 \u001b[0m | \u001b[0m 0.09154 \u001b[0m |\n",
      "| \u001b[0m 59      \u001b[0m | \u001b[0m 75.0    \u001b[0m | \u001b[0m 0.128   \u001b[0m | \u001b[0m 5.136   \u001b[0m | \u001b[0m 361.4   \u001b[0m | \u001b[0m 0.04023 \u001b[0m | \u001b[0m 0.08371 \u001b[0m |\n",
      "| \u001b[0m 60      \u001b[0m | \u001b[0m 110.0   \u001b[0m | \u001b[0m 0.3443  \u001b[0m | \u001b[0m 3.064   \u001b[0m | \u001b[0m 227.2   \u001b[0m | \u001b[0m 0.09344 \u001b[0m | \u001b[0m 0.05405 \u001b[0m |\n",
      "| \u001b[0m 61      \u001b[0m | \u001b[0m 120.0   \u001b[0m | \u001b[0m 0.2218  \u001b[0m | \u001b[0m 2.945   \u001b[0m | \u001b[0m 227.3   \u001b[0m | \u001b[0m 0.07709 \u001b[0m | \u001b[0m 0.04987 \u001b[0m |\n",
      "| \u001b[0m 62      \u001b[0m | \u001b[0m 135.0   \u001b[0m | \u001b[0m 0.4927  \u001b[0m | \u001b[0m 3.11    \u001b[0m | \u001b[0m 227.5   \u001b[0m | \u001b[0m 0.06353 \u001b[0m | \u001b[0m 0.05694 \u001b[0m |\n",
      "| \u001b[0m 63      \u001b[0m | \u001b[0m 130.0   \u001b[0m | \u001b[0m 0.6178  \u001b[0m | \u001b[0m 3.112   \u001b[0m | \u001b[0m 227.4   \u001b[0m | \u001b[0m 0.06595 \u001b[0m | \u001b[0m 0.08276 \u001b[0m |\n",
      "| \u001b[0m 64      \u001b[0m | \u001b[0m 155.0   \u001b[0m | \u001b[0m 0.2778  \u001b[0m | \u001b[0m 2.995   \u001b[0m | \u001b[0m 227.4   \u001b[0m | \u001b[0m 0.03037 \u001b[0m | \u001b[0m 0.04811 \u001b[0m |\n",
      "| \u001b[0m 65      \u001b[0m | \u001b[0m 105.0   \u001b[0m | \u001b[0m 0.6613  \u001b[0m | \u001b[0m 2.105   \u001b[0m | \u001b[0m 482.7   \u001b[0m | \u001b[0m 0.07105 \u001b[0m | \u001b[0m 0.06607 \u001b[0m |\n",
      "| \u001b[0m 66      \u001b[0m | \u001b[0m 80.0    \u001b[0m | \u001b[0m 0.7038  \u001b[0m | \u001b[0m 2.18    \u001b[0m | \u001b[0m 482.7   \u001b[0m | \u001b[0m 0.07722 \u001b[0m | \u001b[0m 0.09384 \u001b[0m |\n",
      "| \u001b[0m 67      \u001b[0m | \u001b[0m 120.0   \u001b[0m | \u001b[0m 0.57    \u001b[0m | \u001b[0m 2.122   \u001b[0m | \u001b[0m 482.9   \u001b[0m | \u001b[0m 0.03129 \u001b[0m | \u001b[0m 0.03831 \u001b[0m |\n",
      "| \u001b[0m 68      \u001b[0m | \u001b[0m 130.0   \u001b[0m | \u001b[0m 0.1974  \u001b[0m | \u001b[0m 2.876   \u001b[0m | \u001b[0m 227.3   \u001b[0m | \u001b[0m 0.05652 \u001b[0m | \u001b[0m 0.0691  \u001b[0m |\n",
      "| \u001b[0m 69      \u001b[0m | \u001b[0m 145.0   \u001b[0m | \u001b[0m 0.4626  \u001b[0m | \u001b[0m 3.008   \u001b[0m | \u001b[0m 227.5   \u001b[0m | \u001b[0m 0.03202 \u001b[0m | \u001b[0m 0.07708 \u001b[0m |\n",
      "| \u001b[0m 70      \u001b[0m | \u001b[0m 110.0   \u001b[0m | \u001b[0m 0.2256  \u001b[0m | \u001b[0m 2.845   \u001b[0m | \u001b[0m 227.2   \u001b[0m | \u001b[0m 0.0523  \u001b[0m | \u001b[0m 0.07526 \u001b[0m |\n",
      "| \u001b[0m 71      \u001b[0m | \u001b[0m 85.0    \u001b[0m | \u001b[0m 0.1854  \u001b[0m | \u001b[0m 5.063   \u001b[0m | \u001b[0m 361.5   \u001b[0m | \u001b[0m 0.04756 \u001b[0m | \u001b[0m 0.04637 \u001b[0m |\n",
      "| \u001b[0m 72      \u001b[0m | \u001b[0m 105.0   \u001b[0m | \u001b[0m 0.7235  \u001b[0m | \u001b[0m 2.11    \u001b[0m | \u001b[0m 482.6   \u001b[0m | \u001b[0m 0.09305 \u001b[0m | \u001b[0m 0.02697 \u001b[0m |\n",
      "| \u001b[0m 73      \u001b[0m | \u001b[0m 80.0    \u001b[0m | \u001b[0m 0.546   \u001b[0m | \u001b[0m 3.124   \u001b[0m | \u001b[0m 227.4   \u001b[0m | \u001b[0m 0.09209 \u001b[0m | \u001b[0m 0.08875 \u001b[0m |\n",
      "| \u001b[0m 74      \u001b[0m | \u001b[0m 105.0   \u001b[0m | \u001b[0m 0.6515  \u001b[0m | \u001b[0m 2.348   \u001b[0m | \u001b[0m 482.7   \u001b[0m | \u001b[0m 0.02524 \u001b[0m | \u001b[0m 0.05517 \u001b[0m |\n",
      "| \u001b[0m 75      \u001b[0m | \u001b[0m 125.0   \u001b[0m | \u001b[0m 0.2227  \u001b[0m | \u001b[0m 3.07    \u001b[0m | \u001b[0m 227.3   \u001b[0m | \u001b[0m 0.09584 \u001b[0m | \u001b[0m 0.07154 \u001b[0m |\n",
      "| \u001b[0m 76      \u001b[0m | \u001b[0m 90.0    \u001b[0m | \u001b[0m 0.05347 \u001b[0m | \u001b[0m 4.797   \u001b[0m | \u001b[0m 129.1   \u001b[0m | \u001b[0m 0.06159 \u001b[0m | \u001b[0m 0.08816 \u001b[0m |\n",
      "| \u001b[0m 77      \u001b[0m | \u001b[0m 90.0    \u001b[0m | \u001b[0m 0.08133 \u001b[0m | \u001b[0m 4.774   \u001b[0m | \u001b[0m 129.2   \u001b[0m | \u001b[0m 0.01859 \u001b[0m | \u001b[0m 0.04312 \u001b[0m |\n",
      "| \u001b[0m 78      \u001b[0m | \u001b[0m 90.0    \u001b[0m | \u001b[0m 0.04171 \u001b[0m | \u001b[0m 4.842   \u001b[0m | \u001b[0m 129.2   \u001b[0m | \u001b[0m 0.02037 \u001b[0m | \u001b[0m 0.07469 \u001b[0m |\n",
      "| \u001b[0m 79      \u001b[0m | \u001b[0m 145.0   \u001b[0m | \u001b[0m 0.2005  \u001b[0m | \u001b[0m 2.998   \u001b[0m | \u001b[0m 227.3   \u001b[0m | \u001b[0m 0.07049 \u001b[0m | \u001b[0m 0.01817 \u001b[0m |\n",
      "| \u001b[0m 80      \u001b[0m | \u001b[0m 120.0   \u001b[0m | \u001b[0m 0.3647  \u001b[0m | \u001b[0m 2.93    \u001b[0m | \u001b[0m 227.5   \u001b[0m | \u001b[0m 0.037   \u001b[0m | \u001b[0m 0.02305 \u001b[0m |\n",
      "| \u001b[0m 81      \u001b[0m | \u001b[0m-125.0   \u001b[0m | \u001b[0m 0.5754  \u001b[0m | \u001b[0m 6.297   \u001b[0m | \u001b[0m 27.52   \u001b[0m | \u001b[0m 0.07274 \u001b[0m | \u001b[0m 0.0089  \u001b[0m |\n",
      "| \u001b[0m 82      \u001b[0m | \u001b[0m 135.0   \u001b[0m | \u001b[0m 0.2811  \u001b[0m | \u001b[0m 3.103   \u001b[0m | \u001b[0m 227.5   \u001b[0m | \u001b[0m 0.07521 \u001b[0m | \u001b[0m 0.005545\u001b[0m |\n",
      "| \u001b[0m 83      \u001b[0m | \u001b[0m 130.0   \u001b[0m | \u001b[0m 0.6717  \u001b[0m | \u001b[0m 2.136   \u001b[0m | \u001b[0m 482.8   \u001b[0m | \u001b[0m 0.04814 \u001b[0m | \u001b[0m 0.06532 \u001b[0m |\n",
      "| \u001b[0m 84      \u001b[0m | \u001b[0m 125.0   \u001b[0m | \u001b[0m 0.1711  \u001b[0m | \u001b[0m 3.172   \u001b[0m | \u001b[0m 227.4   \u001b[0m | \u001b[0m 0.06727 \u001b[0m | \u001b[0m 0.02501 \u001b[0m |\n",
      "| \u001b[0m 85      \u001b[0m | \u001b[0m 135.0   \u001b[0m | \u001b[0m 0.314   \u001b[0m | \u001b[0m 3.028   \u001b[0m | \u001b[0m 227.5   \u001b[0m | \u001b[0m 0.07352 \u001b[0m | \u001b[0m 0.02878 \u001b[0m |\n",
      "| \u001b[0m 86      \u001b[0m | \u001b[0m 130.0   \u001b[0m | \u001b[0m 0.5973  \u001b[0m | \u001b[0m 3.017   \u001b[0m | \u001b[0m 227.4   \u001b[0m | \u001b[0m 0.03192 \u001b[0m | \u001b[0m 0.003065\u001b[0m |\n",
      "| \u001b[0m 87      \u001b[0m | \u001b[0m 145.0   \u001b[0m | \u001b[0m 0.2891  \u001b[0m | \u001b[0m 2.942   \u001b[0m | \u001b[0m 227.3   \u001b[0m | \u001b[0m 0.01146 \u001b[0m | \u001b[0m 0.03601 \u001b[0m |\n",
      "| \u001b[0m 88      \u001b[0m | \u001b[0m 125.0   \u001b[0m | \u001b[0m 0.3662  \u001b[0m | \u001b[0m 3.093   \u001b[0m | \u001b[0m 227.5   \u001b[0m | \u001b[0m 0.07295 \u001b[0m | \u001b[0m 0.03057 \u001b[0m |\n",
      "| \u001b[0m 89      \u001b[0m | \u001b[0m 135.0   \u001b[0m | \u001b[0m 0.3328  \u001b[0m | \u001b[0m 3.187   \u001b[0m | \u001b[0m 227.5   \u001b[0m | \u001b[0m 0.06366 \u001b[0m | \u001b[0m 0.05599 \u001b[0m |\n",
      "| \u001b[0m 90      \u001b[0m | \u001b[0m 115.0   \u001b[0m | \u001b[0m 0.144   \u001b[0m | \u001b[0m 3.166   \u001b[0m | \u001b[0m 227.5   \u001b[0m | \u001b[0m 0.08384 \u001b[0m | \u001b[0m 0.03079 \u001b[0m |\n",
      "| \u001b[0m 91      \u001b[0m | \u001b[0m 115.0   \u001b[0m | \u001b[0m 0.2311  \u001b[0m | \u001b[0m 3.035   \u001b[0m | \u001b[0m 227.4   \u001b[0m | \u001b[0m 0.08    \u001b[0m | \u001b[0m 0.0992  \u001b[0m |\n",
      "| \u001b[0m 92      \u001b[0m | \u001b[0m 110.0   \u001b[0m | \u001b[0m 0.1304  \u001b[0m | \u001b[0m 3.081   \u001b[0m | \u001b[0m 227.4   \u001b[0m | \u001b[0m 0.02584 \u001b[0m | \u001b[0m 0.006363\u001b[0m |\n",
      "| \u001b[0m 93      \u001b[0m | \u001b[0m 130.0   \u001b[0m | \u001b[0m 0.6213  \u001b[0m | \u001b[0m 2.116   \u001b[0m | \u001b[0m 482.8   \u001b[0m | \u001b[0m 0.01644 \u001b[0m | \u001b[0m 0.06201 \u001b[0m |\n",
      "| \u001b[0m 94      \u001b[0m | \u001b[0m 135.0   \u001b[0m | \u001b[0m 0.389   \u001b[0m | \u001b[0m 3.05    \u001b[0m | \u001b[0m 227.5   \u001b[0m | \u001b[0m 0.03029 \u001b[0m | \u001b[0m 0.09658 \u001b[0m |\n",
      "| \u001b[0m 95      \u001b[0m | \u001b[0m-20.0    \u001b[0m | \u001b[0m 0.7353  \u001b[0m | \u001b[0m 1.986   \u001b[0m | \u001b[0m 482.7   \u001b[0m | \u001b[0m 0.0409  \u001b[0m | \u001b[0m 0.08496 \u001b[0m |\n",
      "| \u001b[0m 96      \u001b[0m | \u001b[0m 155.0   \u001b[0m | \u001b[0m 0.6084  \u001b[0m | \u001b[0m 2.142   \u001b[0m | \u001b[0m 482.7   \u001b[0m | \u001b[0m 0.05207 \u001b[0m | \u001b[0m 0.07628 \u001b[0m |\n",
      "| \u001b[0m 97      \u001b[0m | \u001b[0m 85.0    \u001b[0m | \u001b[0m 0.1946  \u001b[0m | \u001b[0m 5.298   \u001b[0m | \u001b[0m 361.4   \u001b[0m | \u001b[0m 0.08995 \u001b[0m | \u001b[0m 0.07088 \u001b[0m |\n",
      "| \u001b[0m 98      \u001b[0m | \u001b[0m 135.0   \u001b[0m | \u001b[0m 0.3795  \u001b[0m | \u001b[0m 3.127   \u001b[0m | \u001b[0m 227.6   \u001b[0m | \u001b[0m 0.04962 \u001b[0m | \u001b[0m 0.05581 \u001b[0m |\n",
      "| \u001b[0m 99      \u001b[0m | \u001b[0m 135.0   \u001b[0m | \u001b[0m 0.3359  \u001b[0m | \u001b[0m 3.057   \u001b[0m | \u001b[0m 227.5   \u001b[0m | \u001b[0m 0.05195 \u001b[0m | \u001b[0m 0.01711 \u001b[0m |\n",
      "| \u001b[0m 100     \u001b[0m | \u001b[0m 160.0   \u001b[0m | \u001b[0m 0.2287  \u001b[0m | \u001b[0m 3.177   \u001b[0m | \u001b[0m 227.5   \u001b[0m | \u001b[0m 0.05183 \u001b[0m | \u001b[0m 0.02367 \u001b[0m |\n",
      "| \u001b[0m 101     \u001b[0m | \u001b[0m 145.0   \u001b[0m | \u001b[0m 0.2542  \u001b[0m | \u001b[0m 2.956   \u001b[0m | \u001b[0m 227.4   \u001b[0m | \u001b[0m 0.009158\u001b[0m | \u001b[0m 0.09346 \u001b[0m |\n",
      "| \u001b[0m 102     \u001b[0m | \u001b[0m 160.0   \u001b[0m | \u001b[0m 0.3448  \u001b[0m | \u001b[0m 3.061   \u001b[0m | \u001b[0m 227.3   \u001b[0m | \u001b[0m 0.005576\u001b[0m | \u001b[0m 0.06853 \u001b[0m |\n",
      "| \u001b[0m 103     \u001b[0m | \u001b[0m 135.0   \u001b[0m | \u001b[0m 0.4203  \u001b[0m | \u001b[0m 3.102   \u001b[0m | \u001b[0m 227.6   \u001b[0m | \u001b[0m 3.077e-0\u001b[0m | \u001b[0m 0.01938 \u001b[0m |\n",
      "| \u001b[0m 104     \u001b[0m | \u001b[0m 125.0   \u001b[0m | \u001b[0m 0.3785  \u001b[0m | \u001b[0m 3.016   \u001b[0m | \u001b[0m 227.6   \u001b[0m | \u001b[0m 0.01781 \u001b[0m | \u001b[0m 0.01908 \u001b[0m |\n",
      "| \u001b[0m 105     \u001b[0m | \u001b[0m 125.0   \u001b[0m | \u001b[0m 0.2953  \u001b[0m | \u001b[0m 3.145   \u001b[0m | \u001b[0m 227.4   \u001b[0m | \u001b[0m 0.04685 \u001b[0m | \u001b[0m 0.03491 \u001b[0m |\n",
      "=====================================================================================\n"
     ]
    }
   ],
   "source": [
    "optimization_xgb = BayesianOptimization(evaluateXgb, params_xgb, random_state=231)\n",
    "optimization_xgb.maximize(n_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': 160.0,\n",
       " 'params': {'gamma': 0.3079585481450413,\n",
       "  'max_depth': 3.1686809206091557,\n",
       "  'n_estimators': 227.39776966615537,\n",
       "  'reg_alpha': 0.0413745206438609,\n",
       "  'reg_lambda': 0.031173917414878148}}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimization_xgb.max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateLogReg(C):\n",
    "    \n",
    "#     if penalty < 0.5:\n",
    "#         penalty = 'l1'\n",
    "#     else:\n",
    "#         penalty = 'l2'\n",
    "    \n",
    "    model = LogisticRegression(C=C, max_iter=1000, solver='lbfgs')\n",
    "    \n",
    "    return cross_val_imbalanced(model, X_train_prepared, y_train, SMOTE(random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_logreg = {\n",
    "#     'penalty': (0, 1),\n",
    "    'C': (0.0001, 10000)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |     C     |\n",
      "-------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 255.0   \u001b[0m | \u001b[0m 7.815e+0\u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 255.0   \u001b[0m | \u001b[0m 5.842e+0\u001b[0m |\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m 265.0   \u001b[0m | \u001b[95m 4.267e+0\u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 240.0   \u001b[0m | \u001b[0m 3.153e+0\u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 255.0   \u001b[0m | \u001b[0m 8.269e+0\u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 255.0   \u001b[0m | \u001b[0m 9.034e+0\u001b[0m |\n",
      "| \u001b[95m 7       \u001b[0m | \u001b[95m 275.0   \u001b[0m | \u001b[95m 389.4   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 255.0   \u001b[0m | \u001b[0m 9.152e+0\u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 250.0   \u001b[0m | \u001b[0m 605.1   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 225.0   \u001b[0m | \u001b[0m 1.807e+0\u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 250.0   \u001b[0m | \u001b[0m 723.0   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 265.0   \u001b[0m | \u001b[0m 4.588e+0\u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 255.0   \u001b[0m | \u001b[0m 7.084e+0\u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 265.0   \u001b[0m | \u001b[0m 4.832e+0\u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 254.5   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 250.0   \u001b[0m | \u001b[0m 669.0   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 265.0   \u001b[0m | \u001b[0m 4.259e+0\u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 250.0   \u001b[0m | \u001b[0m 2.192e+0\u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 255.0   \u001b[0m | \u001b[0m 8.101e+0\u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 200.0   \u001b[0m | \u001b[0m 1.401e+0\u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 326.7   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 364.7   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 283.6   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 379.2   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 266.8   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 345.1   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 305.0   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 294.3   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 384.7   \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 354.9   \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 316.1   \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 259.9   \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 244.3   \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 335.7   \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 232.8   \u001b[0m |\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m 250.0   \u001b[0m | \u001b[0m 220.2   \u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 237.3   \u001b[0m |\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 288.6   \u001b[0m |\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 249.0   \u001b[0m |\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 234.7   \u001b[0m |\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 360.1   \u001b[0m |\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 310.6   \u001b[0m |\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 331.1   \u001b[0m |\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 349.7   \u001b[0m |\n",
      "| \u001b[0m 45      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 299.6   \u001b[0m |\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 372.8   \u001b[0m |\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 263.7   \u001b[0m |\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 321.3   \u001b[0m |\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 340.6   \u001b[0m |\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 240.7   \u001b[0m |\n",
      "| \u001b[0m 51      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 368.8   \u001b[0m |\n",
      "| \u001b[0m 52      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 387.5   \u001b[0m |\n",
      "| \u001b[0m 53      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 285.9   \u001b[0m |\n",
      "| \u001b[0m 54      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 273.5   \u001b[0m |\n",
      "| \u001b[0m 55      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 278.1   \u001b[0m |\n",
      "| \u001b[0m 56      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 270.3   \u001b[0m |\n",
      "| \u001b[0m 57      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 376.0   \u001b[0m |\n",
      "| \u001b[0m 58      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 307.8   \u001b[0m |\n",
      "| \u001b[0m 59      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 296.9   \u001b[0m |\n",
      "| \u001b[0m 60      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 251.8   \u001b[0m |\n",
      "| \u001b[0m 61      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 318.6   \u001b[0m |\n",
      "| \u001b[0m 62      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 352.3   \u001b[0m |\n",
      "| \u001b[0m 63      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 382.0   \u001b[0m |\n",
      "| \u001b[0m 64      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 280.7   \u001b[0m |\n",
      "| \u001b[0m 65      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 324.1   \u001b[0m |\n",
      "| \u001b[0m 66      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 291.5   \u001b[0m |\n",
      "| \u001b[0m 67      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 257.3   \u001b[0m |\n",
      "| \u001b[0m 68      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 338.2   \u001b[0m |\n",
      "| \u001b[0m 69      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 357.7   \u001b[0m |\n",
      "| \u001b[0m 70      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 313.3   \u001b[0m |\n",
      "| \u001b[0m 71      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 302.3   \u001b[0m |\n",
      "| \u001b[0m 72      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 246.6   \u001b[0m |\n",
      "| \u001b[0m 73      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 347.3   \u001b[0m |\n",
      "| \u001b[0m 74      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 362.5   \u001b[0m |\n",
      "| \u001b[0m 75      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 333.2   \u001b[0m |\n",
      "| \u001b[0m 76      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 275.7   \u001b[0m |\n",
      "| \u001b[0m 77      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 342.8   \u001b[0m |\n",
      "| \u001b[0m 78      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 328.9   \u001b[0m |\n",
      "| \u001b[0m 79      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 370.8   \u001b[0m |\n",
      "| \u001b[0m 80      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 239.1   \u001b[0m |\n",
      "| \u001b[0m 81      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 261.9   \u001b[0m |\n",
      "| \u001b[0m 82      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 366.7   \u001b[0m |\n",
      "| \u001b[0m 83      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 233.6   \u001b[0m |\n",
      "| \u001b[0m 84      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 391.8   \u001b[0m |\n",
      "| \u001b[0m 85      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 394.3   \u001b[0m |\n",
      "| \u001b[0m 86      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 396.7   \u001b[0m |\n",
      "| \u001b[0m 87      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 399.2   \u001b[0m |\n",
      "| \u001b[0m 88      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 402.0   \u001b[0m |\n",
      "| \u001b[0m 89      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 404.4   \u001b[0m |\n",
      "| \u001b[0m 90      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 407.0   \u001b[0m |\n",
      "| \u001b[0m 91      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 409.7   \u001b[0m |\n",
      "| \u001b[0m 92      \u001b[0m | \u001b[0m 250.0   \u001b[0m | \u001b[0m 412.4   \u001b[0m |\n",
      "| \u001b[0m 93      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 408.6   \u001b[0m |\n",
      "| \u001b[0m 94      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 268.5   \u001b[0m |\n",
      "| \u001b[0m 95      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 405.9   \u001b[0m |\n",
      "| \u001b[0m 96      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 377.6   \u001b[0m |\n",
      "| \u001b[0m 97      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 290.0   \u001b[0m |\n",
      "| \u001b[0m 98      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 242.6   \u001b[0m |\n",
      "| \u001b[0m 99      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 309.2   \u001b[0m |\n",
      "| \u001b[0m 100     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 383.4   \u001b[0m |\n",
      "| \u001b[0m 101     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 322.7   \u001b[0m |\n",
      "| \u001b[0m 102     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 255.9   \u001b[0m |\n",
      "| \u001b[0m 103     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 282.2   \u001b[0m |\n",
      "| \u001b[0m 104     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 314.7   \u001b[0m |\n",
      "| \u001b[0m 105     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 271.9   \u001b[0m |\n",
      "| \u001b[0m 106     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 301.0   \u001b[0m |\n",
      "| \u001b[0m 107     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 250.4   \u001b[0m |\n",
      "| \u001b[0m 108     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 374.3   \u001b[0m |\n",
      "| \u001b[0m 109     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 295.6   \u001b[0m |\n",
      "| \u001b[0m 110     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 409.2   \u001b[0m |\n",
      "| \u001b[0m 111     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 400.6   \u001b[0m |\n",
      "| \u001b[0m 112     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 356.3   \u001b[0m |\n",
      "| \u001b[0m 113     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 351.0   \u001b[0m |\n",
      "| \u001b[0m 114     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 265.2   \u001b[0m |\n",
      "| \u001b[0m 115     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 306.2   \u001b[0m |\n",
      "| \u001b[0m 116     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 319.9   \u001b[0m |\n",
      "| \u001b[0m 117     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 337.0   \u001b[0m |\n",
      "| \u001b[0m 118     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 393.0   \u001b[0m |\n",
      "| \u001b[0m 119     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 287.2   \u001b[0m |\n",
      "| \u001b[0m 120     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 361.4   \u001b[0m |\n",
      "| \u001b[0m 121     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 279.4   \u001b[0m |\n",
      "| \u001b[0m 122     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 386.1   \u001b[0m |\n",
      "| \u001b[0m 123     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 292.9   \u001b[0m |\n",
      "| \u001b[0m 124     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 380.6   \u001b[0m |\n",
      "| \u001b[0m 125     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 258.6   \u001b[0m |\n",
      "| \u001b[0m 126     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 397.8   \u001b[0m |\n",
      "| \u001b[0m 127     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 325.4   \u001b[0m |\n",
      "| \u001b[0m 128     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 311.9   \u001b[0m |\n",
      "| \u001b[0m 129     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 236.0   \u001b[0m |\n",
      "| \u001b[0m 130     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 247.8   \u001b[0m |\n",
      "| \u001b[0m 131     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 253.1   \u001b[0m |\n",
      "| \u001b[0m 132     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 334.4   \u001b[0m |\n",
      "| \u001b[0m 133     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 298.2   \u001b[0m |\n",
      "| \u001b[0m 134     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 341.7   \u001b[0m |\n",
      "| \u001b[0m 135     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 346.2   \u001b[0m |\n",
      "| \u001b[0m 136     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 353.6   \u001b[0m |\n",
      "| \u001b[0m 137     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 303.7   \u001b[0m |\n",
      "| \u001b[0m 138     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 330.1   \u001b[0m |\n",
      "| \u001b[0m 139     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 276.9   \u001b[0m |\n",
      "| \u001b[0m 140     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 317.4   \u001b[0m |\n",
      "| \u001b[0m 141     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 390.5   \u001b[0m |\n",
      "| \u001b[0m 142     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 403.3   \u001b[0m |\n",
      "| \u001b[0m 143     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 358.9   \u001b[0m |\n",
      "| \u001b[0m 144     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 348.5   \u001b[0m |\n",
      "| \u001b[0m 145     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 395.5   \u001b[0m |\n",
      "| \u001b[0m 146     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 339.4   \u001b[0m |\n",
      "| \u001b[0m 147     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 367.8   \u001b[0m |\n",
      "| \u001b[0m 148     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 284.8   \u001b[0m |\n",
      "| \u001b[0m 149     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 245.4   \u001b[0m |\n",
      "| \u001b[0m 150     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 363.6   \u001b[0m |\n",
      "| \u001b[0m 151     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 274.7   \u001b[0m |\n",
      "| \u001b[0m 152     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 344.0   \u001b[0m |\n",
      "| \u001b[0m 153     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 327.7   \u001b[0m |\n",
      "| \u001b[0m 154     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 371.8   \u001b[0m |\n",
      "| \u001b[0m 155     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 260.9   \u001b[0m |\n",
      "| \u001b[0m 156     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 332.2   \u001b[0m |\n",
      "| \u001b[0m 157     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 241.7   \u001b[0m |\n",
      "| \u001b[0m 158     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 365.7   \u001b[0m |\n",
      "| \u001b[0m 159     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 388.3   \u001b[0m |\n",
      "| \u001b[0m 160     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 269.4   \u001b[0m |\n",
      "| \u001b[0m 161     \u001b[0m | \u001b[0m 250.0   \u001b[0m | \u001b[0m 231.4   \u001b[0m |\n",
      "| \u001b[0m 162     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 233.1   \u001b[0m |\n",
      "| \u001b[0m 163     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 375.2   \u001b[0m |\n",
      "| \u001b[0m 164     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 238.2   \u001b[0m |\n",
      "| \u001b[0m 165     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 266.0   \u001b[0m |\n",
      "| \u001b[0m 166     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 378.4   \u001b[0m |\n",
      "| \u001b[0m 167     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 262.8   \u001b[0m |\n",
      "| \u001b[0m 168     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 272.7   \u001b[0m |\n",
      "| \u001b[0m 169     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 369.9   \u001b[0m |\n",
      "| \u001b[0m 170     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 281.4   \u001b[0m |\n",
      "| \u001b[0m 171     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 307.0   \u001b[0m |\n",
      "| \u001b[0m 172     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 290.7   \u001b[0m |\n",
      "| \u001b[0m 173     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 243.5   \u001b[0m |\n",
      "| \u001b[0m 174     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 407.8   \u001b[0m |\n",
      "| \u001b[0m 175     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 315.4   \u001b[0m |\n",
      "| \u001b[0m 176     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 381.3   \u001b[0m |\n",
      "| \u001b[0m 177     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 267.7   \u001b[0m |\n",
      "| \u001b[0m 178     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 309.9   \u001b[0m |\n",
      "| \u001b[0m 179     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 323.4   \u001b[0m |\n",
      "| \u001b[0m 180     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 239.9   \u001b[0m |\n",
      "| \u001b[0m 181     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 293.5   \u001b[0m |\n",
      "| \u001b[0m 182     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 399.9   \u001b[0m |\n",
      "| \u001b[0m 183     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 385.4   \u001b[0m |\n",
      "| \u001b[0m 184     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 255.2   \u001b[0m |\n",
      "| \u001b[0m 185     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 301.7   \u001b[0m |\n",
      "| \u001b[0m 186     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 373.6   \u001b[0m |\n",
      "| \u001b[0m 187     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 249.7   \u001b[0m |\n",
      "| \u001b[0m 188     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 320.6   \u001b[0m |\n",
      "| \u001b[0m 189     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 287.9   \u001b[0m |\n",
      "| \u001b[0m 190     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 298.9   \u001b[0m |\n",
      "| \u001b[0m 191     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 405.2   \u001b[0m |\n",
      "| \u001b[0m 192     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 355.6   \u001b[0m |\n",
      "| \u001b[0m 193     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 312.7   \u001b[0m |\n",
      "| \u001b[0m 194     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 252.4   \u001b[0m |\n",
      "| \u001b[0m 195     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 271.1   \u001b[0m |\n",
      "| \u001b[0m 196     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 376.9   \u001b[0m |\n",
      "| \u001b[0m 197     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 257.9   \u001b[0m |\n",
      "| \u001b[0m 198     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 282.9   \u001b[0m |\n",
      "| \u001b[0m 199     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 264.5   \u001b[0m |\n",
      "| \u001b[0m 200     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 350.4   \u001b[0m |\n",
      "| \u001b[0m 201     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 402.6   \u001b[0m |\n",
      "| \u001b[0m 202     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 382.7   \u001b[0m |\n",
      "| \u001b[0m 203     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 335.1   \u001b[0m |\n",
      "| \u001b[0m 204     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 304.4   \u001b[0m |\n",
      "| \u001b[0m 205     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 353.0   \u001b[0m |\n",
      "| \u001b[0m 206     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 398.5   \u001b[0m |\n",
      "| \u001b[0m 207     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 236.6   \u001b[0m |\n",
      "| \u001b[0m 208     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 296.3   \u001b[0m |\n",
      "| \u001b[0m 209     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 280.0   \u001b[0m |\n",
      "| \u001b[0m 210     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 357.0   \u001b[0m |\n",
      "| \u001b[0m 211     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 326.0   \u001b[0m |\n",
      "| \u001b[0m 212     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 289.3   \u001b[0m |\n",
      "| \u001b[0m 213     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 234.1   \u001b[0m |\n",
      "| \u001b[0m 214     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 318.0   \u001b[0m |\n",
      "| \u001b[0m 215     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 394.9   \u001b[0m |\n",
      "| \u001b[0m 216     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 360.7   \u001b[0m |\n",
      "| \u001b[0m 217     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 292.2   \u001b[0m |\n",
      "| \u001b[0m 218     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 308.5   \u001b[0m |\n",
      "| \u001b[0m 219     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 392.4   \u001b[0m |\n",
      "| \u001b[0m 220     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 338.8   \u001b[0m |\n",
      "| \u001b[0m 221     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 256.6   \u001b[0m |\n",
      "| \u001b[0m 222     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 311.3   \u001b[0m |\n",
      "| \u001b[0m 223     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 386.8   \u001b[0m |\n",
      "| \u001b[0m 224     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 300.3   \u001b[0m |\n",
      "| \u001b[0m 225     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 259.3   \u001b[0m |\n",
      "| \u001b[0m 226     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 347.9   \u001b[0m |\n",
      "| \u001b[0m 227     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 401.3   \u001b[0m |\n",
      "| \u001b[0m 228     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 251.1   \u001b[0m |\n",
      "| \u001b[0m 229     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 379.9   \u001b[0m |\n",
      "| \u001b[0m 230     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 314.0   \u001b[0m |\n",
      "| \u001b[0m 231     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 277.5   \u001b[0m |\n",
      "| \u001b[0m 232     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 322.0   \u001b[0m |\n",
      "| \u001b[0m 233     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 294.9   \u001b[0m |\n",
      "| \u001b[0m 234     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 384.1   \u001b[0m |\n",
      "| \u001b[0m 235     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 247.1   \u001b[0m |\n",
      "| \u001b[0m 236     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 286.6   \u001b[0m |\n",
      "| \u001b[0m 237     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 303.0   \u001b[0m |\n",
      "| \u001b[0m 238     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 329.4   \u001b[0m |\n",
      "| \u001b[0m 239     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 343.4   \u001b[0m |\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/bayes_opt/target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: (235.33615694515152,)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-dc93a99b5578>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moptimization_logreg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBayesianOptimization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluateLogReg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_logreg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m231\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moptimization_logreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[0;34m(self, init_points, n_iter, acq, kappa, xi, **gp_params)\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0miteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_probe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlazy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOPTMIZATION_END\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mprobe\u001b[0;34m(self, params, lazy)\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOPTMIZATION_STEP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/bayes_opt/target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-58-ab1d3cc40a68>\u001b[0m in \u001b[0;36mevaluateLogReg\u001b[0;34m(C)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lbfgs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcross_val_imbalanced\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_prepared\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-31-504ff46384d1>\u001b[0m in \u001b[0;36mcross_val_imbalanced\u001b[0;34m(classifier, X, y, sampler)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# training the model on oversampled 4 folds of training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#         classifier.fit(train, target_train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_res\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_res\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;31m# testing on 1 fold of validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mtest_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1358\u001b[0m                       \u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1359\u001b[0m                       sample_weight=sample_weight)\n\u001b[0;32m-> 1360\u001b[0;31m             for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n\u001b[0m\u001b[1;32m   1361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m         \u001b[0mfold_coefs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfold_coefs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    915\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mlogistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight)\u001b[0m\n\u001b[1;32m    753\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfprime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 755\u001b[0;31m                 iprint=iprint, pgtol=tol, maxiter=max_iter)\n\u001b[0m\u001b[1;32m    756\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"warnflag\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m                 warnings.warn(\"lbfgs failed to converge. Increase the number \"\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfmin_l_bfgs_b\u001b[0;34m(func, x0, fprime, args, approx_grad, bounds, m, factr, pgtol, epsilon, iprint, maxfun, maxiter, disp, callback, maxls)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     res = _minimize_lbfgsb(fun, x0, args=args, jac=jac, bounds=bounds,\n\u001b[0;32m--> 199\u001b[0;31m                            **opts)\n\u001b[0m\u001b[1;32m    200\u001b[0m     d = {'grad': res['jac'],\n\u001b[1;32m    201\u001b[0m          \u001b[0;34m'task'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'message'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36m_logistic_loss_and_grad\u001b[0;34m(w, X, y, alpha, sample_weight)\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_intercept_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36m_intercept_dot\u001b[0;34m(w, X, y)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m     \u001b[0myz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimization_logreg = BayesianOptimization(evaluateLogReg, params_logreg, random_state=231)\n",
    "optimization_logreg.maximize(n_iter=1000, init_points=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "275"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "275"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking SGDClassifier and Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGDClassifier(alpha=0.0026265889414660943, l1_ratio=0.40452166539879963, loss='modified_huber',\n",
    "                    penalty='elasticnet', tol=0.09572138646802396, random_state=231)\n",
    "log_reg = LogisticRegression(C=389.4, max_iter=1000, solver='lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_pipeline = make_pipeline(RandomOverSampler(random_state=42),\n",
    "                             SGDClassifier(alpha=0.0026265889414660943, l1_ratio=0.40452166539879963, \n",
    "                                           loss='modified_huber', penalty='elasticnet', \n",
    "                                           tol=0.09572138646802396, random_state=231))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_pipeline = make_pipeline(RandomOverSampler(random_state=42),\n",
    "                                LogisticRegression(C=389.4, max_iter=1000, solver='lbfgs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('randomoversampler', RandomOverSampler(random_state=42, ratio=None, return_indices=False,\n",
       "         sampling_strategy='auto')), ('sgdclassifier', SGDClassifier(alpha=0.0026265889414660943, average=False, class_weight=None,\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True...huffle=True, tol=0.09572138646802396,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_pipeline.fit(X_train_prepared, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('randomoversampler', RandomOverSampler(random_state=42, ratio=None, return_indices=False,\n",
       "         sampling_strategy='auto')), ('logisticregression', LogisticRegression(C=389.4, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=1000, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_pipeline.fit(X_train_prepared, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlens.ensemble import SuperLearner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SuperLearner(array_check=None, backend=None, folds=2,\n",
       "       layers=[Layer(backend='threading', dtype=<class 'numpy.float32'>, n_jobs=-1,\n",
       "   name='layer-1', propagate_features=None, raise_on_exception=True,\n",
       "   random_state=1200, shuffle=False,\n",
       "   stack=[Group(backend='threading', dtype=<class 'numpy.float32'>,\n",
       "   indexer=FoldIndex(X=None, folds=2, raise_on_ex..._scorer))],\n",
       "   n_jobs=-1, name='group-8', raise_on_exception=True, transformers=[])],\n",
       "   verbose=1)],\n",
       "       model_selection=False, n_jobs=None, raise_on_exception=True,\n",
       "       random_state=231, sample_size=20, scorer=make_scorer(profit_scorer),\n",
       "       shuffle=False, verbose=2)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacking = SuperLearner(scorer=profit_scoring, random_state=231, verbose=2)\n",
    "stacking.add([sgd_pipeline, logreg_pipeline])\n",
    "stacking.add_meta(DecisionTreeClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting 2 layers\n",
      "Processing layer-1             "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/mlens/parallel/_base_functions.py:226: MetricWarning: [pipeline-1.0.2] Could not score pipeline-1. Details:\n",
      "TypeError(\"__call__() missing 1 required positional argument: 'y_true'\")\n",
      "  (name, inst_name, exc), MetricWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/mlens/parallel/_base_functions.py:226: MetricWarning: [pipeline-1.0.1] Could not score pipeline-1. Details:\n",
      "TypeError(\"__call__() missing 1 required positional argument: 'y_true'\")\n",
      "  (name, inst_name, exc), MetricWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/mlens/parallel/_base_functions.py:226: MetricWarning: [pipeline-2.0.2] Could not score pipeline-2. Details:\n",
      "TypeError(\"__call__() missing 1 required positional argument: 'y_true'\")\n",
      "  (name, inst_name, exc), MetricWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/mlens/parallel/_base_functions.py:226: MetricWarning: [pipeline-2.0.1] Could not score pipeline-2. Details:\n",
      "TypeError(\"__call__() missing 1 required positional argument: 'y_true'\")\n",
      "  (name, inst_name, exc), MetricWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/mlens/parallel/_base_functions.py:226: MetricWarning: [decisiontreeclassifier.0.0] Could not score decisiontreeclassifier. Details:\n",
      "TypeError(\"__call__() missing 1 required positional argument: 'y_true'\")\n",
      "  (name, inst_name, exc), MetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Fit complete                        | 00:00:00\n",
      "\n",
      "Predicting 2 layers\n",
      "Processing layer-1             done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Predict complete                    | 00:00:00\n",
      "\n",
      "Fitting 2 layers\n",
      "Processing layer-1             "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/mlens/parallel/_base_functions.py:226: MetricWarning: [pipeline-1.0.1] Could not score pipeline-1. Details:\n",
      "TypeError(\"__call__() missing 1 required positional argument: 'y_true'\")\n",
      "  (name, inst_name, exc), MetricWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/mlens/parallel/_base_functions.py:226: MetricWarning: [pipeline-1.0.2] Could not score pipeline-1. Details:\n",
      "TypeError(\"__call__() missing 1 required positional argument: 'y_true'\")\n",
      "  (name, inst_name, exc), MetricWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/mlens/parallel/_base_functions.py:226: MetricWarning: [pipeline-2.0.2] Could not score pipeline-2. Details:\n",
      "TypeError(\"__call__() missing 1 required positional argument: 'y_true'\")\n",
      "  (name, inst_name, exc), MetricWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/mlens/parallel/_base_functions.py:226: MetricWarning: [pipeline-2.0.1] Could not score pipeline-2. Details:\n",
      "TypeError(\"__call__() missing 1 required positional argument: 'y_true'\")\n",
      "  (name, inst_name, exc), MetricWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/mlens/parallel/_base_functions.py:226: MetricWarning: [decisiontreeclassifier.0.0] Could not score decisiontreeclassifier. Details:\n",
      "TypeError(\"__call__() missing 1 required positional argument: 'y_true'\")\n",
      "  (name, inst_name, exc), MetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Fit complete                        | 00:00:00\n",
      "\n",
      "Predicting 2 layers\n",
      "Processing layer-1             done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Predict complete                    | 00:00:00\n",
      "\n",
      "Fitting 2 layers\n",
      "Processing layer-1             "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/mlens/parallel/_base_functions.py:226: MetricWarning: [pipeline-1.0.1] Could not score pipeline-1. Details:\n",
      "TypeError(\"__call__() missing 1 required positional argument: 'y_true'\")\n",
      "  (name, inst_name, exc), MetricWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/mlens/parallel/_base_functions.py:226: MetricWarning: [pipeline-1.0.2] Could not score pipeline-1. Details:\n",
      "TypeError(\"__call__() missing 1 required positional argument: 'y_true'\")\n",
      "  (name, inst_name, exc), MetricWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/mlens/parallel/_base_functions.py:226: MetricWarning: [pipeline-2.0.1] Could not score pipeline-2. Details:\n",
      "TypeError(\"__call__() missing 1 required positional argument: 'y_true'\")\n",
      "  (name, inst_name, exc), MetricWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/mlens/parallel/_base_functions.py:226: MetricWarning: [pipeline-2.0.2] Could not score pipeline-2. Details:\n",
      "TypeError(\"__call__() missing 1 required positional argument: 'y_true'\")\n",
      "  (name, inst_name, exc), MetricWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/mlens/parallel/_base_functions.py:226: MetricWarning: [decisiontreeclassifier.0.0] Could not score decisiontreeclassifier. Details:\n",
      "TypeError(\"__call__() missing 1 required positional argument: 'y_true'\")\n",
      "  (name, inst_name, exc), MetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Fit complete                        | 00:00:00\n",
      "\n",
      "Predicting 2 layers\n",
      "Processing layer-1             done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Predict complete                    | 00:00:00\n",
      "\n",
      "Fitting 2 layers\n",
      "Processing layer-1             "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/mlens/parallel/_base_functions.py:226: MetricWarning: [pipeline-1.0.2] Could not score pipeline-1. Details:\n",
      "TypeError(\"__call__() missing 1 required positional argument: 'y_true'\")\n",
      "  (name, inst_name, exc), MetricWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/mlens/parallel/_base_functions.py:226: MetricWarning: [pipeline-1.0.1] Could not score pipeline-1. Details:\n",
      "TypeError(\"__call__() missing 1 required positional argument: 'y_true'\")\n",
      "  (name, inst_name, exc), MetricWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/mlens/parallel/_base_functions.py:226: MetricWarning: [pipeline-2.0.1] Could not score pipeline-2. Details:\n",
      "TypeError(\"__call__() missing 1 required positional argument: 'y_true'\")\n",
      "  (name, inst_name, exc), MetricWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/mlens/parallel/_base_functions.py:226: MetricWarning: [pipeline-2.0.2] Could not score pipeline-2. Details:\n",
      "TypeError(\"__call__() missing 1 required positional argument: 'y_true'\")\n",
      "  (name, inst_name, exc), MetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/mlens/parallel/_base_functions.py:226: MetricWarning: [decisiontreeclassifier.0.0] Could not score decisiontreeclassifier. Details:\n",
      "TypeError(\"__call__() missing 1 required positional argument: 'y_true'\")\n",
      "  (name, inst_name, exc), MetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit complete                        | 00:00:00\n",
      "\n",
      "Predicting 2 layers\n",
      "Processing layer-1             done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Predict complete                    | 00:00:00\n",
      "\n",
      "Fitting 2 layers\n",
      "Processing layer-1             "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/mlens/parallel/_base_functions.py:226: MetricWarning: [pipeline-1.0.1] Could not score pipeline-1. Details:\n",
      "TypeError(\"__call__() missing 1 required positional argument: 'y_true'\")\n",
      "  (name, inst_name, exc), MetricWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/mlens/parallel/_base_functions.py:226: MetricWarning: [pipeline-1.0.2] Could not score pipeline-1. Details:\n",
      "TypeError(\"__call__() missing 1 required positional argument: 'y_true'\")\n",
      "  (name, inst_name, exc), MetricWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/mlens/parallel/_base_functions.py:226: MetricWarning: [pipeline-2.0.1] Could not score pipeline-2. Details:\n",
      "TypeError(\"__call__() missing 1 required positional argument: 'y_true'\")\n",
      "  (name, inst_name, exc), MetricWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/mlens/parallel/_base_functions.py:226: MetricWarning: [pipeline-2.0.2] Could not score pipeline-2. Details:\n",
      "TypeError(\"__call__() missing 1 required positional argument: 'y_true'\")\n",
      "  (name, inst_name, exc), MetricWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/mlens/parallel/_base_functions.py:226: MetricWarning: [decisiontreeclassifier.0.0] Could not score decisiontreeclassifier. Details:\n",
      "TypeError(\"__call__() missing 1 required positional argument: 'y_true'\")\n",
      "  (name, inst_name, exc), MetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Fit complete                        | 00:00:00\n",
      "\n",
      "Predicting 2 layers\n",
      "Processing layer-1             done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Predict complete                    | 00:00:00\n",
      "\n",
      "Fitting 2 layers\n",
      "Processing layer-1             "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/mlens/parallel/_base_functions.py:226: MetricWarning: [pipeline-1.0.2] Could not score pipeline-1. Details:\n",
      "TypeError(\"__call__() missing 1 required positional argument: 'y_true'\")\n",
      "  (name, inst_name, exc), MetricWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/mlens/parallel/_base_functions.py:226: MetricWarning: [pipeline-1.0.1] Could not score pipeline-1. Details:\n",
      "TypeError(\"__call__() missing 1 required positional argument: 'y_true'\")\n",
      "  (name, inst_name, exc), MetricWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/mlens/parallel/_base_functions.py:226: MetricWarning: [pipeline-2.0.2] Could not score pipeline-2. Details:\n",
      "TypeError(\"__call__() missing 1 required positional argument: 'y_true'\")\n",
      "  (name, inst_name, exc), MetricWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/mlens/parallel/_base_functions.py:226: MetricWarning: [pipeline-2.0.1] Could not score pipeline-2. Details:\n",
      "TypeError(\"__call__() missing 1 required positional argument: 'y_true'\")\n",
      "  (name, inst_name, exc), MetricWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/mlens/parallel/_base_functions.py:226: MetricWarning: [decisiontreeclassifier.0.0] Could not score decisiontreeclassifier. Details:\n",
      "TypeError(\"__call__() missing 1 required positional argument: 'y_true'\")\n",
      "  (name, inst_name, exc), MetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Fit complete                        | 00:00:00\n",
      "\n",
      "Predicting 2 layers\n",
      "Processing layer-1             done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Predict complete                    | 00:00:00\n",
      "\n",
      "Fitting 2 layers\n",
      "Processing layer-1             "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/mlens/parallel/_base_functions.py:226: MetricWarning: [pipeline-1.0.1] Could not score pipeline-1. Details:\n",
      "TypeError(\"__call__() missing 1 required positional argument: 'y_true'\")\n",
      "  (name, inst_name, exc), MetricWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/mlens/parallel/_base_functions.py:226: MetricWarning: [pipeline-1.0.2] Could not score pipeline-1. Details:\n",
      "TypeError(\"__call__() missing 1 required positional argument: 'y_true'\")\n",
      "  (name, inst_name, exc), MetricWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/mlens/parallel/_base_functions.py:226: MetricWarning: [pipeline-2.0.2] Could not score pipeline-2. Details:\n",
      "TypeError(\"__call__() missing 1 required positional argument: 'y_true'\")\n",
      "  (name, inst_name, exc), MetricWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/mlens/parallel/_base_functions.py:226: MetricWarning: [pipeline-2.0.1] Could not score pipeline-2. Details:\n",
      "TypeError(\"__call__() missing 1 required positional argument: 'y_true'\")\n",
      "  (name, inst_name, exc), MetricWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/mlens/parallel/_base_functions.py:226: MetricWarning: [decisiontreeclassifier.0.0] Could not score decisiontreeclassifier. Details:\n",
      "TypeError(\"__call__() missing 1 required positional argument: 'y_true'\")\n",
      "  (name, inst_name, exc), MetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Fit complete                        | 00:00:00\n",
      "\n",
      "Predicting 2 layers\n",
      "Processing layer-1             done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Predict complete                    | 00:00:00\n",
      "\n",
      "Fitting 2 layers\n",
      "Processing layer-1             "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/mlens/parallel/_base_functions.py:226: MetricWarning: [pipeline-1.0.1] Could not score pipeline-1. Details:\n",
      "TypeError(\"__call__() missing 1 required positional argument: 'y_true'\")\n",
      "  (name, inst_name, exc), MetricWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/mlens/parallel/_base_functions.py:226: MetricWarning: [pipeline-1.0.2] Could not score pipeline-1. Details:\n",
      "TypeError(\"__call__() missing 1 required positional argument: 'y_true'\")\n",
      "  (name, inst_name, exc), MetricWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/mlens/parallel/_base_functions.py:226: MetricWarning: [pipeline-2.0.2] Could not score pipeline-2. Details:\n",
      "TypeError(\"__call__() missing 1 required positional argument: 'y_true'\")\n",
      "  (name, inst_name, exc), MetricWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/mlens/parallel/_base_functions.py:226: MetricWarning: [pipeline-2.0.1] Could not score pipeline-2. Details:\n",
      "TypeError(\"__call__() missing 1 required positional argument: 'y_true'\")\n",
      "  (name, inst_name, exc), MetricWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/mlens/parallel/_base_functions.py:226: MetricWarning: [decisiontreeclassifier.0.0] Could not score decisiontreeclassifier. Details:\n",
      "TypeError(\"__call__() missing 1 required positional argument: 'y_true'\")\n",
      "  (name, inst_name, exc), MetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Fit complete                        | 00:00:00\n",
      "\n",
      "Predicting 2 layers\n",
      "Processing layer-1             done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Predict complete                    | 00:00:00\n",
      "\n",
      "Fitting 2 layers\n",
      "Processing layer-1             "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/mlens/parallel/_base_functions.py:226: MetricWarning: [pipeline-1.0.1] Could not score pipeline-1. Details:\n",
      "TypeError(\"__call__() missing 1 required positional argument: 'y_true'\")\n",
      "  (name, inst_name, exc), MetricWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/mlens/parallel/_base_functions.py:226: MetricWarning: [pipeline-1.0.2] Could not score pipeline-1. Details:\n",
      "TypeError(\"__call__() missing 1 required positional argument: 'y_true'\")\n",
      "  (name, inst_name, exc), MetricWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/mlens/parallel/_base_functions.py:226: MetricWarning: [pipeline-2.0.1] Could not score pipeline-2. Details:\n",
      "TypeError(\"__call__() missing 1 required positional argument: 'y_true'\")\n",
      "  (name, inst_name, exc), MetricWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/mlens/parallel/_base_functions.py:226: MetricWarning: [pipeline-2.0.2] Could not score pipeline-2. Details:\n",
      "TypeError(\"__call__() missing 1 required positional argument: 'y_true'\")\n",
      "  (name, inst_name, exc), MetricWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/mlens/parallel/_base_functions.py:226: MetricWarning: [decisiontreeclassifier.0.0] Could not score decisiontreeclassifier. Details:\n",
      "TypeError(\"__call__() missing 1 required positional argument: 'y_true'\")\n",
      "  (name, inst_name, exc), MetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Fit complete                        | 00:00:00\n",
      "\n",
      "Predicting 2 layers\n",
      "Processing layer-1             done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Predict complete                    | 00:00:00\n",
      "\n",
      "Fitting 2 layers\n",
      "Processing layer-1             "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/mlens/parallel/_base_functions.py:226: MetricWarning: [pipeline-1.0.2] Could not score pipeline-1. Details:\n",
      "TypeError(\"__call__() missing 1 required positional argument: 'y_true'\")\n",
      "  (name, inst_name, exc), MetricWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/mlens/parallel/_base_functions.py:226: MetricWarning: [pipeline-1.0.1] Could not score pipeline-1. Details:\n",
      "TypeError(\"__call__() missing 1 required positional argument: 'y_true'\")\n",
      "  (name, inst_name, exc), MetricWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/mlens/parallel/_base_functions.py:226: MetricWarning: [pipeline-2.0.1] Could not score pipeline-2. Details:\n",
      "TypeError(\"__call__() missing 1 required positional argument: 'y_true'\")\n",
      "  (name, inst_name, exc), MetricWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/mlens/parallel/_base_functions.py:226: MetricWarning: [pipeline-2.0.2] Could not score pipeline-2. Details:\n",
      "TypeError(\"__call__() missing 1 required positional argument: 'y_true'\")\n",
      "  (name, inst_name, exc), MetricWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/mlens/parallel/_base_functions.py:226: MetricWarning: [decisiontreeclassifier.0.0] Could not score decisiontreeclassifier. Details:\n",
      "TypeError(\"__call__() missing 1 required positional argument: 'y_true'\")\n",
      "  (name, inst_name, exc), MetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Fit complete                        | 00:00:00\n",
      "\n",
      "Predicting 2 layers\n",
      "Processing layer-1             done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Predict complete                    | 00:00:00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "265"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_imbalanced(stacking, X_train_prepared, y_train, RandomOverSampler(random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGDClassifier - SMOTE Hyperparam Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import BorderlineSMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateSgdSmote(k_neighbors, m_neighbors):\n",
    "    \n",
    "    model = SGDClassifier(alpha=0.0026265889414660943, l1_ratio=0.40452166539879963, loss='modified_huber',\n",
    "                    penalty='elasticnet', tol=0.09572138646802396, random_state=231)\n",
    "    \n",
    "    \n",
    "    return cross_val_imbalanced(model, X_train_prepared, y_train, BorderlineSMOTE(\n",
    "                                                                        k_neighbors=int(k_neighbors), \n",
    "                                                                        m_neighbors=int(m_neighbors),\n",
    "                                                                        random_state=42))\n",
    "\n",
    "#     cv_results = cross_val_score(model, X_train_prepared, y_train, cv=10, scoring=profit_scoring)\n",
    "    \n",
    "#     return np.mean(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_sgd_smote = {\n",
    "    'k_neighbors': (2, 50),\n",
    "    'm_neighbors': (2, 50)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | k_neig... | m_neig... |\n",
      "-------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 240.0   \u001b[0m | \u001b[0m 19.98   \u001b[0m | \u001b[0m 47.63   \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 255.0   \u001b[0m | \u001b[95m 37.14   \u001b[0m | \u001b[95m 30.74   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 230.0   \u001b[0m | \u001b[0m 9.489   \u001b[0m | \u001b[0m 9.488   \u001b[0m |\n",
      "| \u001b[95m 4       \u001b[0m | \u001b[95m 275.0   \u001b[0m | \u001b[95m 4.788   \u001b[0m | \u001b[95m 43.58   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 30.85   \u001b[0m | \u001b[0m 35.99   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 2.988   \u001b[0m | \u001b[0m 48.56   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 41.96   \u001b[0m | \u001b[0m 12.19   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 245.0   \u001b[0m | \u001b[0m 10.73   \u001b[0m | \u001b[0m 10.8    \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 255.0   \u001b[0m | \u001b[0m 16.6    \u001b[0m | \u001b[0m 27.19   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 265.0   \u001b[0m | \u001b[0m 22.73   \u001b[0m | \u001b[0m 15.98   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 265.0   \u001b[0m | \u001b[0m 31.37   \u001b[0m | \u001b[0m 8.696   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 255.0   \u001b[0m | \u001b[0m 16.02   \u001b[0m | \u001b[0m 19.59   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 265.0   \u001b[0m | \u001b[0m 23.89   \u001b[0m | \u001b[0m 39.69   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 11.58   \u001b[0m | \u001b[0m 26.68   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 30.44   \u001b[0m | \u001b[0m 4.23    \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 265.0   \u001b[0m | \u001b[0m 31.16   \u001b[0m | \u001b[0m 10.19   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 265.0   \u001b[0m | \u001b[0m 5.122   \u001b[0m | \u001b[0m 47.55   \u001b[0m |\n",
      "| \u001b[95m 18      \u001b[0m | \u001b[95m 295.0   \u001b[0m | \u001b[95m 48.35   \u001b[0m | \u001b[95m 40.8    \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 255.0   \u001b[0m | \u001b[0m 16.62   \u001b[0m | \u001b[0m 6.688   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 34.84   \u001b[0m | \u001b[0m 23.13   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 285.0   \u001b[0m | \u001b[0m 7.858   \u001b[0m | \u001b[0m 25.77   \u001b[0m |\n",
      "| \u001b[95m 22      \u001b[0m | \u001b[95m 310.0   \u001b[0m | \u001b[95m 3.651   \u001b[0m | \u001b[95m 45.65   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 285.0   \u001b[0m | \u001b[0m 14.42   \u001b[0m | \u001b[0m 33.8    \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 255.0   \u001b[0m | \u001b[0m 16.96   \u001b[0m | \u001b[0m 26.96   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 265.0   \u001b[0m | \u001b[0m 28.24   \u001b[0m | \u001b[0m 10.87   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 295.0   \u001b[0m | \u001b[0m 48.54   \u001b[0m | \u001b[0m 39.21   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 265.0   \u001b[0m | \u001b[0m 47.1    \u001b[0m | \u001b[0m 44.95   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 30.7    \u001b[0m | \u001b[0m 46.25   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 295.0   \u001b[0m | \u001b[0m 6.248   \u001b[0m | \u001b[0m 11.41   \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 4.171   \u001b[0m | \u001b[0m 17.62   \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m 255.0   \u001b[0m | \u001b[0m 20.66   \u001b[0m | \u001b[0m 15.02   \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 41.78   \u001b[0m | \u001b[0m 19.12   \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 295.0   \u001b[0m | \u001b[0m 15.48   \u001b[0m | \u001b[0m 28.05   \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m 245.0   \u001b[0m | \u001b[0m 8.764   \u001b[0m | \u001b[0m 40.51   \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m 265.0   \u001b[0m | \u001b[0m 5.578   \u001b[0m | \u001b[0m 49.37   \u001b[0m |\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m 245.0   \u001b[0m | \u001b[0m 39.07   \u001b[0m | \u001b[0m 11.54   \u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 2.265   \u001b[0m | \u001b[0m 41.14   \u001b[0m |\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m 285.0   \u001b[0m | \u001b[0m 35.93   \u001b[0m | \u001b[0m 36.99   \u001b[0m |\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m 245.0   \u001b[0m | \u001b[0m 39.02   \u001b[0m | \u001b[0m 5.554   \u001b[0m |\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m 240.0   \u001b[0m | \u001b[0m 19.21   \u001b[0m | \u001b[0m 7.562   \u001b[0m |\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 43.43   \u001b[0m | \u001b[0m 31.92   \u001b[0m |\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m 305.0   \u001b[0m | \u001b[0m 17.88   \u001b[0m | \u001b[0m 5.051   \u001b[0m |\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m 255.0   \u001b[0m | \u001b[0m 16.93   \u001b[0m | \u001b[0m 17.61   \u001b[0m |\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m 255.0   \u001b[0m | \u001b[0m 37.02   \u001b[0m | \u001b[0m 32.6    \u001b[0m |\n",
      "| \u001b[0m 45      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 44.59   \u001b[0m | \u001b[0m 24.67   \u001b[0m |\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m 285.0   \u001b[0m | \u001b[0m 7.741   \u001b[0m | \u001b[0m 36.24   \u001b[0m |\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 38.52   \u001b[0m | \u001b[0m 28.94   \u001b[0m |\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m 245.0   \u001b[0m | \u001b[0m 39.01   \u001b[0m | \u001b[0m 25.7    \u001b[0m |\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 27.09   \u001b[0m | \u001b[0m 22.52   \u001b[0m |\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.22    \u001b[0m | \u001b[0m 7.179   \u001b[0m |\n",
      "| \u001b[0m 51      \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.641   \u001b[0m | \u001b[0m 45.6    \u001b[0m |\n",
      "| \u001b[0m 52      \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.602   \u001b[0m | \u001b[0m 45.63   \u001b[0m |\n",
      "| \u001b[0m 53      \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.242   \u001b[0m | \u001b[0m 7.218   \u001b[0m |\n",
      "| \u001b[0m 54      \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.271   \u001b[0m | \u001b[0m 7.176   \u001b[0m |\n",
      "| \u001b[0m 55      \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.63    \u001b[0m | \u001b[0m 45.63   \u001b[0m |\n",
      "| \u001b[0m 56      \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.247   \u001b[0m | \u001b[0m 7.19    \u001b[0m |\n",
      "| \u001b[0m 57      \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.241   \u001b[0m | \u001b[0m 7.192   \u001b[0m |\n",
      "| \u001b[0m 58      \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.637   \u001b[0m | \u001b[0m 45.62   \u001b[0m |\n",
      "| \u001b[0m 59      \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.246   \u001b[0m | \u001b[0m 7.191   \u001b[0m |\n",
      "| \u001b[0m 60      \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.238   \u001b[0m | \u001b[0m 7.194   \u001b[0m |\n",
      "| \u001b[0m 61      \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.626   \u001b[0m | \u001b[0m 45.63   \u001b[0m |\n",
      "| \u001b[0m 62      \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.634   \u001b[0m | \u001b[0m 45.63   \u001b[0m |\n",
      "| \u001b[0m 63      \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.252   \u001b[0m | \u001b[0m 7.192   \u001b[0m |\n",
      "| \u001b[0m 64      \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.237   \u001b[0m | \u001b[0m 7.207   \u001b[0m |\n",
      "| \u001b[0m 65      \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.642   \u001b[0m | \u001b[0m 45.63   \u001b[0m |\n",
      "| \u001b[0m 66      \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.247   \u001b[0m | \u001b[0m 7.175   \u001b[0m |\n",
      "| \u001b[0m 67      \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.246   \u001b[0m | \u001b[0m 7.191   \u001b[0m |\n",
      "| \u001b[0m 68      \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.622   \u001b[0m | \u001b[0m 45.61   \u001b[0m |\n",
      "| \u001b[0m 69      \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.246   \u001b[0m | \u001b[0m 7.201   \u001b[0m |\n",
      "| \u001b[0m 70      \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.264   \u001b[0m | \u001b[0m 7.196   \u001b[0m |\n",
      "| \u001b[0m 71      \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.632   \u001b[0m | \u001b[0m 45.62   \u001b[0m |\n",
      "| \u001b[0m 72      \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.244   \u001b[0m | \u001b[0m 7.19    \u001b[0m |\n",
      "| \u001b[0m 73      \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.609   \u001b[0m | \u001b[0m 45.62   \u001b[0m |\n",
      "| \u001b[0m 74      \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.277   \u001b[0m | \u001b[0m 7.206   \u001b[0m |\n",
      "| \u001b[0m 75      \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.247   \u001b[0m | \u001b[0m 7.194   \u001b[0m |\n",
      "| \u001b[0m 76      \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.596   \u001b[0m | \u001b[0m 45.62   \u001b[0m |\n",
      "| \u001b[0m 77      \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.639   \u001b[0m | \u001b[0m 45.63   \u001b[0m |\n",
      "| \u001b[0m 78      \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.62    \u001b[0m | \u001b[0m 45.62   \u001b[0m |\n",
      "| \u001b[0m 79      \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.289   \u001b[0m | \u001b[0m 7.221   \u001b[0m |\n",
      "| \u001b[0m 80      \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.265   \u001b[0m | \u001b[0m 7.205   \u001b[0m |\n",
      "| \u001b[0m 81      \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.226   \u001b[0m | \u001b[0m 7.184   \u001b[0m |\n",
      "| \u001b[0m 82      \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.277   \u001b[0m | \u001b[0m 7.207   \u001b[0m |\n",
      "| \u001b[0m 83      \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.279   \u001b[0m | \u001b[0m 7.2     \u001b[0m |\n",
      "| \u001b[0m 84      \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.645   \u001b[0m | \u001b[0m 45.63   \u001b[0m |\n",
      "| \u001b[0m 85      \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.263   \u001b[0m | \u001b[0m 7.186   \u001b[0m |\n",
      "| \u001b[0m 86      \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.621   \u001b[0m | \u001b[0m 45.63   \u001b[0m |\n",
      "| \u001b[0m 87      \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.268   \u001b[0m | \u001b[0m 7.232   \u001b[0m |\n",
      "| \u001b[0m 88      \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.179   \u001b[0m | \u001b[0m 7.158   \u001b[0m |\n",
      "| \u001b[0m 89      \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.179   \u001b[0m | \u001b[0m 7.106   \u001b[0m |\n",
      "| \u001b[0m 90      \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.154   \u001b[0m | \u001b[0m 7.121   \u001b[0m |\n",
      "| \u001b[0m 91      \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.194   \u001b[0m | \u001b[0m 7.14    \u001b[0m |\n",
      "| \u001b[0m 92      \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.175   \u001b[0m | \u001b[0m 7.133   \u001b[0m |\n",
      "| \u001b[0m 93      \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.622   \u001b[0m | \u001b[0m 45.61   \u001b[0m |\n",
      "| \u001b[0m 94      \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.164   \u001b[0m | \u001b[0m 7.066   \u001b[0m |\n",
      "| \u001b[0m 95      \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.134   \u001b[0m | \u001b[0m 7.084   \u001b[0m |\n",
      "| \u001b[0m 96      \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.268   \u001b[0m | \u001b[0m 7.224   \u001b[0m |\n",
      "| \u001b[0m 97      \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.163   \u001b[0m | \u001b[0m 7.151   \u001b[0m |\n",
      "| \u001b[0m 98      \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.181   \u001b[0m | \u001b[0m 7.138   \u001b[0m |\n",
      "| \u001b[0m 99      \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.134   \u001b[0m | \u001b[0m 7.061   \u001b[0m |\n",
      "| \u001b[0m 100     \u001b[0m | \u001b[0m 305.0   \u001b[0m | \u001b[0m 17.99   \u001b[0m | \u001b[0m 4.446   \u001b[0m |\n",
      "| \u001b[0m 101     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.124   \u001b[0m | \u001b[0m 7.085   \u001b[0m |\n",
      "| \u001b[0m 102     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.158   \u001b[0m | \u001b[0m 7.09    \u001b[0m |\n",
      "| \u001b[0m 103     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.243   \u001b[0m | \u001b[0m 7.198   \u001b[0m |\n",
      "| \u001b[0m 104     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.153   \u001b[0m | \u001b[0m 7.075   \u001b[0m |\n",
      "| \u001b[0m 105     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.112   \u001b[0m | \u001b[0m 7.046   \u001b[0m |\n",
      "| \u001b[0m 106     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.645   \u001b[0m | \u001b[0m 45.62   \u001b[0m |\n",
      "| \u001b[0m 107     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.301   \u001b[0m | \u001b[0m 7.231   \u001b[0m |\n",
      "| \u001b[0m 108     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.112   \u001b[0m | \u001b[0m 7.08    \u001b[0m |\n",
      "| \u001b[0m 109     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.146   \u001b[0m | \u001b[0m 7.092   \u001b[0m |\n",
      "| \u001b[0m 110     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.318   \u001b[0m | \u001b[0m 7.275   \u001b[0m |\n",
      "| \u001b[0m 111     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.368   \u001b[0m | \u001b[0m 7.284   \u001b[0m |\n",
      "| \u001b[0m 112     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.311   \u001b[0m | \u001b[0m 7.3     \u001b[0m |\n",
      "| \u001b[0m 113     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.353   \u001b[0m | \u001b[0m 7.345   \u001b[0m |\n",
      "| \u001b[0m 114     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.324   \u001b[0m | \u001b[0m 7.28    \u001b[0m |\n",
      "| \u001b[0m 115     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.352   \u001b[0m | \u001b[0m 7.348   \u001b[0m |\n",
      "| \u001b[0m 116     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.429   \u001b[0m | \u001b[0m 7.365   \u001b[0m |\n",
      "| \u001b[0m 117     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.376   \u001b[0m | \u001b[0m 7.285   \u001b[0m |\n",
      "| \u001b[0m 118     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.408   \u001b[0m | \u001b[0m 7.384   \u001b[0m |\n",
      "| \u001b[0m 119     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.108   \u001b[0m | \u001b[0m 7.014   \u001b[0m |\n",
      "| \u001b[0m 120     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.041   \u001b[0m | \u001b[0m 6.992   \u001b[0m |\n",
      "| \u001b[0m 121     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.055   \u001b[0m | \u001b[0m 7.02    \u001b[0m |\n",
      "| \u001b[0m 122     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.048   \u001b[0m | \u001b[0m 6.935   \u001b[0m |\n",
      "| \u001b[0m 123     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.07    \u001b[0m | \u001b[0m 6.954   \u001b[0m |\n",
      "| \u001b[0m 124     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.183   \u001b[0m | \u001b[0m 7.112   \u001b[0m |\n",
      "| \u001b[0m 125     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.008   \u001b[0m | \u001b[0m 6.952   \u001b[0m |\n",
      "| \u001b[0m 126     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.378   \u001b[0m | \u001b[0m 7.316   \u001b[0m |\n",
      "| \u001b[0m 127     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.074   \u001b[0m | \u001b[0m 7.018   \u001b[0m |\n",
      "| \u001b[0m 128     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.431   \u001b[0m | \u001b[0m 7.352   \u001b[0m |\n",
      "| \u001b[0m 129     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.376   \u001b[0m | \u001b[0m 7.321   \u001b[0m |\n",
      "| \u001b[0m 130     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.402   \u001b[0m | \u001b[0m 7.334   \u001b[0m |\n",
      "| \u001b[0m 131     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 6.896   \u001b[0m |\n",
      "| \u001b[0m 132     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.425   \u001b[0m | \u001b[0m 7.42    \u001b[0m |\n",
      "| \u001b[0m 133     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.343   \u001b[0m | \u001b[0m 7.43    \u001b[0m |\n",
      "| \u001b[0m 134     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.399   \u001b[0m | \u001b[0m 7.173   \u001b[0m |\n",
      "| \u001b[0m 135     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.058   \u001b[0m | \u001b[0m 7.34    \u001b[0m |\n",
      "| \u001b[0m 136     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.309   \u001b[0m | \u001b[0m 6.915   \u001b[0m |\n",
      "| \u001b[0m 137     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 2.826   \u001b[0m | \u001b[0m 7.132   \u001b[0m |\n",
      "| \u001b[0m 138     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.154   \u001b[0m | \u001b[0m 7.34    \u001b[0m |\n",
      "| \u001b[0m 139     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.18    \u001b[0m | \u001b[0m 6.954   \u001b[0m |\n",
      "| \u001b[0m 140     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.353   \u001b[0m | \u001b[0m 7.127   \u001b[0m |\n",
      "| \u001b[0m 141     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.28    \u001b[0m | \u001b[0m 6.993   \u001b[0m |\n",
      "| \u001b[0m 142     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.261   \u001b[0m | \u001b[0m 6.934   \u001b[0m |\n",
      "| \u001b[0m 143     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.322   \u001b[0m | \u001b[0m 6.947   \u001b[0m |\n",
      "| \u001b[0m 144     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.106   \u001b[0m | \u001b[0m 7.3     \u001b[0m |\n",
      "| \u001b[0m 145     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.2     \u001b[0m | \u001b[0m 6.996   \u001b[0m |\n",
      "| \u001b[0m 146     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.146   \u001b[0m | \u001b[0m 7.357   \u001b[0m |\n",
      "| \u001b[0m 147     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.272   \u001b[0m | \u001b[0m 7.075   \u001b[0m |\n",
      "| \u001b[0m 148     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.118   \u001b[0m | \u001b[0m 7.314   \u001b[0m |\n",
      "| \u001b[0m 149     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.312   \u001b[0m | \u001b[0m 7.39    \u001b[0m |\n",
      "| \u001b[0m 150     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.258   \u001b[0m | \u001b[0m 7.389   \u001b[0m |\n",
      "| \u001b[0m 151     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.071   \u001b[0m | \u001b[0m 7.352   \u001b[0m |\n",
      "| \u001b[0m 152     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.373   \u001b[0m | \u001b[0m 7.216   \u001b[0m |\n",
      "| \u001b[0m 153     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.383   \u001b[0m | \u001b[0m 7.428   \u001b[0m |\n",
      "| \u001b[0m 154     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.232   \u001b[0m | \u001b[0m 7.298   \u001b[0m |\n",
      "| \u001b[0m 155     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.356   \u001b[0m | \u001b[0m 7.168   \u001b[0m |\n",
      "| \u001b[0m 156     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.092   \u001b[0m | \u001b[0m 7.323   \u001b[0m |\n",
      "| \u001b[0m 157     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.126   \u001b[0m | \u001b[0m 6.967   \u001b[0m |\n",
      "| \u001b[0m 158     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.284   \u001b[0m | \u001b[0m 7.417   \u001b[0m |\n",
      "| \u001b[0m 159     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.305   \u001b[0m | \u001b[0m 6.933   \u001b[0m |\n",
      "| \u001b[0m 160     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.344   \u001b[0m | \u001b[0m 7.036   \u001b[0m |\n",
      "| \u001b[0m 161     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.196   \u001b[0m | \u001b[0m 7.391   \u001b[0m |\n",
      "| \u001b[0m 162     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.16    \u001b[0m | \u001b[0m 7.254   \u001b[0m |\n",
      "| \u001b[0m 163     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.301   \u001b[0m | \u001b[0m 7.109   \u001b[0m |\n",
      "| \u001b[0m 164     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.211   \u001b[0m | \u001b[0m 7.355   \u001b[0m |\n",
      "| \u001b[0m 165     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.329   \u001b[0m | \u001b[0m 7.089   \u001b[0m |\n",
      "| \u001b[0m 166     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.31    \u001b[0m | \u001b[0m 7.03    \u001b[0m |\n",
      "| \u001b[0m 167     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.426   \u001b[0m | \u001b[0m 7.242   \u001b[0m |\n",
      "| \u001b[0m 168     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.14    \u001b[0m | \u001b[0m 6.993   \u001b[0m |\n",
      "| \u001b[0m 169     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 2.993   \u001b[0m | \u001b[0m 6.92    \u001b[0m |\n",
      "| \u001b[0m 170     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.353   \u001b[0m | \u001b[0m 7.421   \u001b[0m |\n",
      "| \u001b[0m 171     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.292   \u001b[0m | \u001b[0m 6.974   \u001b[0m |\n",
      "| \u001b[0m 172     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.138   \u001b[0m | \u001b[0m 7.045   \u001b[0m |\n",
      "| \u001b[0m 173     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.399   \u001b[0m | \u001b[0m 7.193   \u001b[0m |\n",
      "| \u001b[0m 174     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.176   \u001b[0m | \u001b[0m 7.255   \u001b[0m |\n",
      "| \u001b[0m 175     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.292   \u001b[0m | \u001b[0m 7.048   \u001b[0m |\n",
      "| \u001b[0m 176     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 2.995   \u001b[0m | \u001b[0m 6.871   \u001b[0m |\n",
      "| \u001b[0m 177     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.047   \u001b[0m | \u001b[0m 6.948   \u001b[0m |\n",
      "| \u001b[0m 178     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.271   \u001b[0m | \u001b[0m 7.18    \u001b[0m |\n",
      "| \u001b[0m 179     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.374   \u001b[0m | \u001b[0m 7.162   \u001b[0m |\n",
      "| \u001b[0m 180     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.379   \u001b[0m | \u001b[0m 7.211   \u001b[0m |\n",
      "| \u001b[0m 181     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.342   \u001b[0m | \u001b[0m 7.144   \u001b[0m |\n",
      "| \u001b[0m 182     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.269   \u001b[0m | \u001b[0m 7.402   \u001b[0m |\n",
      "| \u001b[0m 183     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.11    \u001b[0m | \u001b[0m 7.332   \u001b[0m |\n",
      "| \u001b[0m 184     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.364   \u001b[0m | \u001b[0m 7.154   \u001b[0m |\n",
      "| \u001b[0m 185     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.233   \u001b[0m | \u001b[0m 7.173   \u001b[0m |\n",
      "| \u001b[0m 186     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.392   \u001b[0m | \u001b[0m 7.188   \u001b[0m |\n",
      "| \u001b[0m 187     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.059   \u001b[0m | \u001b[0m 7.006   \u001b[0m |\n",
      "| \u001b[0m 188     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.124   \u001b[0m | \u001b[0m 7.086   \u001b[0m |\n",
      "| \u001b[0m 189     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.164   \u001b[0m | \u001b[0m 6.981   \u001b[0m |\n",
      "| \u001b[0m 190     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.104   \u001b[0m | \u001b[0m 7.318   \u001b[0m |\n",
      "| \u001b[0m 191     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.414   \u001b[0m | \u001b[0m 7.242   \u001b[0m |\n",
      "| \u001b[0m 192     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.286   \u001b[0m | \u001b[0m 7.077   \u001b[0m |\n",
      "| \u001b[0m 193     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.408   \u001b[0m | \u001b[0m 7.38    \u001b[0m |\n",
      "| \u001b[0m 194     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.209   \u001b[0m | \u001b[0m 7.366   \u001b[0m |\n",
      "| \u001b[0m 195     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.418   \u001b[0m | \u001b[0m 7.259   \u001b[0m |\n",
      "| \u001b[0m 196     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.023   \u001b[0m | \u001b[0m 6.902   \u001b[0m |\n",
      "| \u001b[0m 197     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.636   \u001b[0m | \u001b[0m 45.62   \u001b[0m |\n",
      "| \u001b[0m 198     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.282   \u001b[0m | \u001b[0m 7.415   \u001b[0m |\n",
      "| \u001b[0m 199     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.016   \u001b[0m | \u001b[0m 6.968   \u001b[0m |\n",
      "| \u001b[0m 200     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.412   \u001b[0m | \u001b[0m 7.364   \u001b[0m |\n",
      "| \u001b[0m 201     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.314   \u001b[0m | \u001b[0m 7.112   \u001b[0m |\n",
      "| \u001b[0m 202     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.418   \u001b[0m | \u001b[0m 7.387   \u001b[0m |\n",
      "| \u001b[0m 203     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.143   \u001b[0m | \u001b[0m 7.339   \u001b[0m |\n",
      "| \u001b[0m 204     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.195   \u001b[0m | \u001b[0m 7.363   \u001b[0m |\n",
      "| \u001b[0m 205     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.118   \u001b[0m | \u001b[0m 7.326   \u001b[0m |\n",
      "| \u001b[0m 206     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.121   \u001b[0m | \u001b[0m 7.335   \u001b[0m |\n",
      "| \u001b[0m 207     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.288   \u001b[0m | \u001b[0m 6.982   \u001b[0m |\n",
      "| \u001b[0m 208     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.347   \u001b[0m | \u001b[0m 7.243   \u001b[0m |\n",
      "| \u001b[0m 209     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.019   \u001b[0m | \u001b[0m 6.964   \u001b[0m |\n",
      "| \u001b[0m 210     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.159   \u001b[0m | \u001b[0m 7.357   \u001b[0m |\n",
      "| \u001b[0m 211     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.333   \u001b[0m | \u001b[0m 7.252   \u001b[0m |\n",
      "| \u001b[0m 212     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.113   \u001b[0m | \u001b[0m 7.034   \u001b[0m |\n",
      "| \u001b[0m 213     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.35    \u001b[0m | \u001b[0m 7.159   \u001b[0m |\n",
      "| \u001b[0m 214     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.421   \u001b[0m | \u001b[0m 7.417   \u001b[0m |\n",
      "| \u001b[0m 215     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.189   \u001b[0m | \u001b[0m 6.965   \u001b[0m |\n",
      "| \u001b[0m 216     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.162   \u001b[0m | \u001b[0m 6.968   \u001b[0m |\n",
      "| \u001b[0m 217     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.324   \u001b[0m | \u001b[0m 7.028   \u001b[0m |\n",
      "| \u001b[0m 218     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.349   \u001b[0m | \u001b[0m 7.262   \u001b[0m |\n",
      "| \u001b[0m 219     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.065   \u001b[0m | \u001b[0m 7.004   \u001b[0m |\n",
      "| \u001b[0m 220     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.057   \u001b[0m | \u001b[0m 6.978   \u001b[0m |\n",
      "| \u001b[0m 221     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.315   \u001b[0m | \u001b[0m 7.401   \u001b[0m |\n",
      "| \u001b[0m 222     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.389   \u001b[0m | \u001b[0m 7.328   \u001b[0m |\n",
      "| \u001b[0m 223     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.311   \u001b[0m | \u001b[0m 7.284   \u001b[0m |\n",
      "| \u001b[0m 224     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.414   \u001b[0m | \u001b[0m 7.342   \u001b[0m |\n",
      "| \u001b[0m 225     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.267   \u001b[0m | \u001b[0m 7.19    \u001b[0m |\n",
      "| \u001b[0m 226     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.156   \u001b[0m | \u001b[0m 7.12    \u001b[0m |\n",
      "| \u001b[0m 227     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.292   \u001b[0m | \u001b[0m 7.414   \u001b[0m |\n",
      "| \u001b[0m 228     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.313   \u001b[0m | \u001b[0m 7.047   \u001b[0m |\n",
      "| \u001b[0m 229     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.324   \u001b[0m | \u001b[0m 7.27    \u001b[0m |\n",
      "| \u001b[0m 230     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.087   \u001b[0m | \u001b[0m 7.344   \u001b[0m |\n",
      "| \u001b[0m 231     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.428   \u001b[0m | \u001b[0m 7.415   \u001b[0m |\n",
      "| \u001b[0m 232     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.317   \u001b[0m | \u001b[0m 7.089   \u001b[0m |\n",
      "| \u001b[0m 233     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.414   \u001b[0m | \u001b[0m 7.352   \u001b[0m |\n",
      "| \u001b[0m 234     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.251   \u001b[0m | \u001b[0m 6.935   \u001b[0m |\n",
      "| \u001b[0m 235     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.055   \u001b[0m | \u001b[0m 6.963   \u001b[0m |\n",
      "| \u001b[0m 236     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.36    \u001b[0m | \u001b[0m 7.245   \u001b[0m |\n",
      "| \u001b[0m 237     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.313   \u001b[0m | \u001b[0m 6.934   \u001b[0m |\n",
      "| \u001b[0m 238     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.062   \u001b[0m | \u001b[0m 7.335   \u001b[0m |\n",
      "| \u001b[0m 239     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.128   \u001b[0m | \u001b[0m 7.336   \u001b[0m |\n",
      "| \u001b[0m 240     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.329   \u001b[0m | \u001b[0m 7.416   \u001b[0m |\n",
      "| \u001b[0m 241     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.329   \u001b[0m | \u001b[0m 7.082   \u001b[0m |\n",
      "| \u001b[0m 242     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.074   \u001b[0m | \u001b[0m 7.337   \u001b[0m |\n",
      "| \u001b[0m 243     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.37    \u001b[0m | \u001b[0m 7.324   \u001b[0m |\n",
      "| \u001b[0m 244     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.153   \u001b[0m | \u001b[0m 6.989   \u001b[0m |\n",
      "| \u001b[0m 245     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.169   \u001b[0m | \u001b[0m 7.26    \u001b[0m |\n",
      "| \u001b[0m 246     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.381   \u001b[0m | \u001b[0m 7.347   \u001b[0m |\n",
      "| \u001b[0m 247     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.237   \u001b[0m | \u001b[0m 7.183   \u001b[0m |\n",
      "| \u001b[0m 248     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.177   \u001b[0m | \u001b[0m 6.965   \u001b[0m |\n",
      "| \u001b[0m 249     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.091   \u001b[0m | \u001b[0m 7.335   \u001b[0m |\n",
      "| \u001b[0m 250     \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.291   \u001b[0m | \u001b[0m 7.062   \u001b[0m |\n",
      "=================================================\n"
     ]
    }
   ],
   "source": [
    "optimization_sgd_smote = BayesianOptimization(evaluateSgdSmote, params_sgd_smote, random_state=42)\n",
    "optimization_sgd_smote.maximize(n_iter=200, init_points=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': 310.0,\n",
       " 'params': {'k_neighbors': 3.650649013530483,\n",
       "  'm_neighbors': 45.64737929978154}}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimization_sgd_smote.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
