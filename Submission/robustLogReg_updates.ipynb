{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "import itertools\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from sklearn import svm as SVM\n",
    "from funcs import cv_profits_for_models, cv_preds_and_confusion_matrix, CustomModelWithThreshold\n",
    "from funcs import profit_scorer, profit_scoring\n",
    "from customClassifiers import OutlierRemover\n",
    "from xgboost import XGBClassifier\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, SelectFromModel\n",
    "from sklearn.feature_selection import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('train.csv' ,delimiter=\"|\")\n",
    "X_test = pd.read_csv('test.csv', delimiter=\"|\")\n",
    "\n",
    "X_train['scannedLineItemsTotal'] = X_train['scannedLineItemsPerSecond'] * X_train['totalScanTimeInSeconds']\n",
    "X_train['valuePerLineItem'] = X_train['grandTotal'] * X_train['scannedLineItemsTotal']\n",
    "X_train['quantityModificationsPerLineItem'] = X_train['quantityModifications'] * X_train['scannedLineItemsTotal']\n",
    "X_train['lineItemVoids*scansWithoutRegistration'] = X_train['lineItemVoids'] * X_train['scansWithoutRegistration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['scannedLineItemsTotal'] = X_test['scannedLineItemsPerSecond'] * X_test['totalScanTimeInSeconds']\n",
    "X_test['valuePerLineItem'] = X_test['grandTotal'] * X_test['scannedLineItemsTotal']\n",
    "X_test['quantityModificationsPerLineItem'] = X_test['quantityModifications'] * X_test['scannedLineItemsTotal']\n",
    "X_test['lineItemVoids*scansWithoutRegistration'] = X_test['lineItemVoids'] * X_test['scansWithoutRegistration']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1 = X_train[X_train['trustLevel']==1]\n",
    "y1 = X_train1.pop('fraud')\n",
    "l=X_train1.pop('trustLevel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test1 = X_test[X_test['trustLevel']==1]\n",
    "l=X_test1.pop('trustLevel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2 = X_train[X_train['trustLevel']==2]\n",
    "y2 = X_train2.pop('fraud')\n",
    "l=X_train2.pop('trustLevel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test2 = X_test[X_test['trustLevel']==2]\n",
    "l=X_test2.pop('trustLevel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_higher = X_test[X_test['trustLevel']>2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trust Level 1 (Calculate Feature Importance with XGboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/html/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/html/anaconda3/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/html/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "# normalize data first to prevent 0's in dataset\n",
    "scaler = StandardScaler()\n",
    "names_X_train1 = X_train1.columns\n",
    "X_train1 = scaler.fit_transform(X_train1)\n",
    "\n",
    "\n",
    "# for test transform with the scaler fitted on train\n",
    "names_X_test1 = X_test1.columns\n",
    "index_X_test1 = X_test1.index\n",
    "X_test1 = scaler.transform(X_test1)\n",
    "\n",
    "# generate features and rescale\n",
    "polyFeatures = PolynomialFeatures(3, interaction_only=False)\n",
    "X_train1_all = polyFeatures.fit_transform(X_train1)\n",
    "X_train1_all = scaler.fit_transform(X_train1_all)\n",
    "\n",
    "# for test transform with the scaler fitted on train\n",
    "X_test1_all = polyFeatures.transform(X_test1)\n",
    "X_test1_all = scaler.transform(X_test1_all)\n",
    "\n",
    "# remove first var (constant term)\n",
    "X_test1_all = X_test1_all[:,1:]\n",
    "features_X_test1_all = polyFeatures.get_feature_names(input_features=names_X_test1)[1:]\n",
    "\n",
    "# remove the first var because it is the constant term\n",
    "X_train1_all = X_train1_all[:,1:]\n",
    "features_X_train1_all = polyFeatures.get_feature_names(input_features=names_X_train1)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain feature importance by xgboost\n",
    "xgb = XGBClassifier(num_estimator=100)\n",
    "xgb.fit(X_train1_all, y1)\n",
    "imp = xgb.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# order the feature indices by importance\n",
    "imp = pd.DataFrame(imp)\n",
    "imp = imp.sort_values(by=0, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose starting model\n",
    "model = CustomModelWithThreshold(LogisticRegression(C=10, solver='lbfgs', max_iter=300), 0.9)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, random_state=42)\n",
    "last_score = -10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-215\n",
      "-135\n",
      "-70\n",
      "-30\n",
      "45\n",
      "65\n",
      "90\n",
      "100\n",
      "140\n",
      "180\n",
      "190\n",
      "230\n",
      "250\n",
      "270\n",
      "290\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n"
     ]
    }
   ],
   "source": [
    "# add most important feature\n",
    "X1_temporary = pd.DataFrame(X_train1_all[:,(list(imp.index))[0]])\n",
    "\n",
    "features_to_use1 = [(list(imp.index))[0]]\n",
    "# iteratively add features one by one\n",
    "for featnum in (list(imp.index))[1:]:\n",
    "    X_check = pd.concat([X1_temporary,pd.Series(X_train1_all[:,featnum])], axis=1)\n",
    "    score = sum(cross_validate(model,X_check, y1, scoring=profit_scoring, cv=cv)['test_score'])\n",
    "    # add the feature ultimatively if score improved\n",
    "    if score > last_score:\n",
    "        X1_temporary = pd.concat([X1_temporary,pd.Series(X_train1_all[:,featnum])], axis=1)\n",
    "        features_to_use1.append(featnum)\n",
    "        last_score = score    \n",
    "        print(last_score)\n",
    "    \n",
    "# for test predictions use features_to_use to select the according features in the test set    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |     C     | pred_t... |\n",
      "-------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 285.0   \u001b[0m | \u001b[0m 3.87    \u001b[0m | \u001b[0m 0.5105  \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 3.955   \u001b[0m | \u001b[0m 0.543   \u001b[0m |\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m 300.0   \u001b[0m | \u001b[95m 0.6032  \u001b[0m | \u001b[95m 0.503   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 2.116   \u001b[0m | \u001b[0m 0.5565  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 3.121   \u001b[0m | \u001b[0m 0.5528  \u001b[0m |\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m 325.0   \u001b[0m | \u001b[95m 1.802   \u001b[0m | \u001b[95m 0.5736  \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 3.826   \u001b[0m | \u001b[0m 0.5452  \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 4.863   \u001b[0m | \u001b[0m 0.5601  \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 3.682   \u001b[0m | \u001b[0m 0.5552  \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 3.916   \u001b[0m | \u001b[0m 0.569   \u001b[0m |\n",
      "| \u001b[95m 11      \u001b[0m | \u001b[95m 345.0   \u001b[0m | \u001b[95m 0.4046  \u001b[0m | \u001b[95m 0.5907  \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 2.086   \u001b[0m | \u001b[0m 0.5435  \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 340.0   \u001b[0m | \u001b[0m 0.2756  \u001b[0m | \u001b[0m 0.5138  \u001b[0m |\n",
      "| \u001b[95m 14      \u001b[0m | \u001b[95m 365.0   \u001b[0m | \u001b[95m 0.8073  \u001b[0m | \u001b[95m 0.5909  \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 350.0   \u001b[0m | \u001b[0m 1.369   \u001b[0m | \u001b[0m 0.553   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 3.569   \u001b[0m | \u001b[0m 0.5955  \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 1.997   \u001b[0m | \u001b[0m 0.5445  \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 2.131   \u001b[0m | \u001b[0m 0.5512  \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 285.0   \u001b[0m | \u001b[0m 3.145   \u001b[0m | \u001b[0m 0.5012  \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 4.158   \u001b[0m | \u001b[0m 0.5998  \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 4.514   \u001b[0m | \u001b[0m 0.5431  \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 4.389   \u001b[0m | \u001b[0m 0.576   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 350.0   \u001b[0m | \u001b[0m 0.8533  \u001b[0m | \u001b[0m 0.534   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 2.591   \u001b[0m | \u001b[0m 0.5489  \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 4.324   \u001b[0m | \u001b[0m 0.5827  \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 320.0   \u001b[0m | \u001b[0m 0.176   \u001b[0m | \u001b[0m 0.5256  \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 4.285   \u001b[0m | \u001b[0m 0.5756  \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 3.331   \u001b[0m | \u001b[0m 0.533   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 300.0   \u001b[0m | \u001b[0m 1.576   \u001b[0m | \u001b[0m 0.5293  \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 4.632   \u001b[0m | \u001b[0m 0.5644  \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 3.105   \u001b[0m | \u001b[0m 0.5517  \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 1.713   \u001b[0m | \u001b[0m 0.5021  \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 300.0   \u001b[0m | \u001b[0m 1.67    \u001b[0m | \u001b[0m 0.5346  \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 3.688   \u001b[0m | \u001b[0m 0.5608  \u001b[0m |\n",
      "| \u001b[95m 35      \u001b[0m | \u001b[95m 375.0   \u001b[0m | \u001b[95m 0.7616  \u001b[0m | \u001b[95m 0.5398  \u001b[0m |\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 2.502   \u001b[0m | \u001b[0m 0.5333  \u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m 355.0   \u001b[0m | \u001b[0m 0.3338  \u001b[0m | \u001b[0m 0.549   \u001b[0m |\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 3.591   \u001b[0m | \u001b[0m 0.5674  \u001b[0m |\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 2.636   \u001b[0m | \u001b[0m 0.5736  \u001b[0m |\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m 335.0   \u001b[0m | \u001b[0m 0.162   \u001b[0m | \u001b[0m 0.5444  \u001b[0m |\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m 365.0   \u001b[0m | \u001b[0m 0.9713  \u001b[0m | \u001b[0m 0.587   \u001b[0m |\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 4.66    \u001b[0m | \u001b[0m 0.5442  \u001b[0m |\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 4.197   \u001b[0m | \u001b[0m 0.5551  \u001b[0m |\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 2.918   \u001b[0m | \u001b[0m 0.5233  \u001b[0m |\n",
      "| \u001b[0m 45      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 3.225   \u001b[0m | \u001b[0m 0.5653  \u001b[0m |\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m 350.0   \u001b[0m | \u001b[0m 1.139   \u001b[0m | \u001b[0m 0.5478  \u001b[0m |\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 4.272   \u001b[0m | \u001b[0m 0.5417  \u001b[0m |\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 3.298   \u001b[0m | \u001b[0m 0.5699  \u001b[0m |\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 4.161   \u001b[0m | \u001b[0m 0.5571  \u001b[0m |\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m 350.0   \u001b[0m | \u001b[0m 0.367   \u001b[0m | \u001b[0m 0.5089  \u001b[0m |\n",
      "| \u001b[0m 51      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 2.077   \u001b[0m | \u001b[0m 0.528   \u001b[0m |\n",
      "| \u001b[0m 52      \u001b[0m | \u001b[0m 350.0   \u001b[0m | \u001b[0m 2.134   \u001b[0m | \u001b[0m 0.5928  \u001b[0m |\n",
      "| \u001b[0m 53      \u001b[0m | \u001b[0m 285.0   \u001b[0m | \u001b[0m 4.805   \u001b[0m | \u001b[0m 0.5255  \u001b[0m |\n",
      "| \u001b[0m 54      \u001b[0m | \u001b[0m 305.0   \u001b[0m | \u001b[0m 0.1207  \u001b[0m | \u001b[0m 0.5881  \u001b[0m |\n",
      "| \u001b[0m 55      \u001b[0m | \u001b[0m 350.0   \u001b[0m | \u001b[0m 0.3734  \u001b[0m | \u001b[0m 0.5069  \u001b[0m |\n",
      "| \u001b[0m 56      \u001b[0m | \u001b[0m 300.0   \u001b[0m | \u001b[0m 0.6266  \u001b[0m | \u001b[0m 0.5026  \u001b[0m |\n",
      "| \u001b[0m 57      \u001b[0m | \u001b[0m 235.0   \u001b[0m | \u001b[0m 4.462   \u001b[0m | \u001b[0m 0.5086  \u001b[0m |\n",
      "| \u001b[0m 58      \u001b[0m | \u001b[0m 325.0   \u001b[0m | \u001b[0m 1.375   \u001b[0m | \u001b[0m 0.5307  \u001b[0m |\n",
      "| \u001b[0m 59      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 3.503   \u001b[0m | \u001b[0m 0.5403  \u001b[0m |\n",
      "| \u001b[0m 60      \u001b[0m | \u001b[0m 365.0   \u001b[0m | \u001b[0m 0.7174  \u001b[0m | \u001b[0m 0.5694  \u001b[0m |\n",
      "| \u001b[0m 61      \u001b[0m | \u001b[0m 285.0   \u001b[0m | \u001b[0m 2.594   \u001b[0m | \u001b[0m 0.5107  \u001b[0m |\n",
      "| \u001b[0m 62      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 3.225   \u001b[0m | \u001b[0m 0.5313  \u001b[0m |\n",
      "| \u001b[0m 63      \u001b[0m | \u001b[0m 325.0   \u001b[0m | \u001b[0m 0.5194  \u001b[0m | \u001b[0m 0.5084  \u001b[0m |\n",
      "| \u001b[0m 64      \u001b[0m | \u001b[0m 285.0   \u001b[0m | \u001b[0m 3.596   \u001b[0m | \u001b[0m 0.5089  \u001b[0m |\n",
      "| \u001b[0m 65      \u001b[0m | \u001b[0m 330.0   \u001b[0m | \u001b[0m 0.2478  \u001b[0m | \u001b[0m 0.5214  \u001b[0m |\n",
      "| \u001b[0m 66      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 4.747   \u001b[0m | \u001b[0m 0.5549  \u001b[0m |\n",
      "| \u001b[0m 67      \u001b[0m | \u001b[0m 375.0   \u001b[0m | \u001b[0m 1.276   \u001b[0m | \u001b[0m 0.5735  \u001b[0m |\n",
      "| \u001b[0m 68      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 4.013   \u001b[0m | \u001b[0m 0.5808  \u001b[0m |\n",
      "| \u001b[0m 69      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 3.214   \u001b[0m | \u001b[0m 0.5826  \u001b[0m |\n",
      "| \u001b[0m 70      \u001b[0m | \u001b[0m 365.0   \u001b[0m | \u001b[0m 0.6236  \u001b[0m | \u001b[0m 0.5671  \u001b[0m |\n",
      "| \u001b[0m 71      \u001b[0m | \u001b[0m 235.0   \u001b[0m | \u001b[0m 4.348   \u001b[0m | \u001b[0m 0.5028  \u001b[0m |\n",
      "| \u001b[0m 72      \u001b[0m | \u001b[0m 350.0   \u001b[0m | \u001b[0m 1.516   \u001b[0m | \u001b[0m 0.5638  \u001b[0m |\n",
      "| \u001b[0m 73      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 2.822   \u001b[0m | \u001b[0m 0.5712  \u001b[0m |\n",
      "| \u001b[0m 74      \u001b[0m | \u001b[0m 350.0   \u001b[0m | \u001b[0m 1.346   \u001b[0m | \u001b[0m 0.5547  \u001b[0m |\n",
      "| \u001b[0m 75      \u001b[0m | \u001b[0m 365.0   \u001b[0m | \u001b[0m 0.6168  \u001b[0m | \u001b[0m 0.5678  \u001b[0m |\n",
      "| \u001b[0m 76      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 2.204   \u001b[0m | \u001b[0m 0.5146  \u001b[0m |\n",
      "| \u001b[0m 77      \u001b[0m | \u001b[0m 345.0   \u001b[0m | \u001b[0m 0.2936  \u001b[0m | \u001b[0m 0.5432  \u001b[0m |\n",
      "| \u001b[0m 78      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 2.957   \u001b[0m | \u001b[0m 0.5673  \u001b[0m |\n",
      "| \u001b[0m 79      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 4.657   \u001b[0m | \u001b[0m 0.5838  \u001b[0m |\n",
      "| \u001b[0m 80      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 2.444   \u001b[0m | \u001b[0m 0.5556  \u001b[0m |\n",
      "| \u001b[0m 81      \u001b[0m | \u001b[0m 300.0   \u001b[0m | \u001b[0m 1.356   \u001b[0m | \u001b[0m 0.5235  \u001b[0m |\n",
      "| \u001b[0m 82      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 2.934   \u001b[0m | \u001b[0m 0.5235  \u001b[0m |\n",
      "| \u001b[0m 83      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 2.109   \u001b[0m | \u001b[0m 0.5101  \u001b[0m |\n",
      "| \u001b[0m 84      \u001b[0m | \u001b[0m 285.0   \u001b[0m | \u001b[0m 4.455   \u001b[0m | \u001b[0m 0.5232  \u001b[0m |\n",
      "| \u001b[0m 85      \u001b[0m | \u001b[0m 375.0   \u001b[0m | \u001b[0m 1.51    \u001b[0m | \u001b[0m 0.5815  \u001b[0m |\n",
      "| \u001b[0m 86      \u001b[0m | \u001b[0m 325.0   \u001b[0m | \u001b[0m 1.953   \u001b[0m | \u001b[0m 0.5794  \u001b[0m |\n",
      "| \u001b[0m 87      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 4.737   \u001b[0m | \u001b[0m 0.563   \u001b[0m |\n",
      "| \u001b[0m 88      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 4.325   \u001b[0m | \u001b[0m 0.5716  \u001b[0m |\n",
      "| \u001b[0m 89      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 3.15    \u001b[0m | \u001b[0m 0.5223  \u001b[0m |\n",
      "| \u001b[0m 90      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 3.958   \u001b[0m | \u001b[0m 0.5427  \u001b[0m |\n",
      "| \u001b[0m 91      \u001b[0m | \u001b[0m 285.0   \u001b[0m | \u001b[0m 3.709   \u001b[0m | \u001b[0m 0.503   \u001b[0m |\n",
      "| \u001b[0m 92      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 3.671   \u001b[0m | \u001b[0m 0.5807  \u001b[0m |\n",
      "| \u001b[0m 93      \u001b[0m | \u001b[0m 285.0   \u001b[0m | \u001b[0m 3.955   \u001b[0m | \u001b[0m 0.5089  \u001b[0m |\n",
      "| \u001b[0m 94      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 3.959   \u001b[0m | \u001b[0m 0.5769  \u001b[0m |\n",
      "| \u001b[0m 95      \u001b[0m | \u001b[0m 365.0   \u001b[0m | \u001b[0m 0.6792  \u001b[0m | \u001b[0m 0.5657  \u001b[0m |\n",
      "| \u001b[0m 96      \u001b[0m | \u001b[0m 285.0   \u001b[0m | \u001b[0m 4.073   \u001b[0m | \u001b[0m 0.5094  \u001b[0m |\n",
      "| \u001b[0m 97      \u001b[0m | \u001b[0m 300.0   \u001b[0m | \u001b[0m 1.586   \u001b[0m | \u001b[0m 0.5021  \u001b[0m |\n",
      "| \u001b[0m 98      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 3.488   \u001b[0m | \u001b[0m 0.5993  \u001b[0m |\n",
      "| \u001b[0m 99      \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 4.404   \u001b[0m | \u001b[0m 0.5921  \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 100     \u001b[0m | \u001b[0m 275.0   \u001b[0m | \u001b[0m 2.095   \u001b[0m | \u001b[0m 0.5499  \u001b[0m |\n",
      "| \u001b[0m 101     \u001b[0m | \u001b[0m 375.0   \u001b[0m | \u001b[0m 0.7609  \u001b[0m | \u001b[0m 0.548   \u001b[0m |\n",
      "| \u001b[0m 102     \u001b[0m | \u001b[0m 375.0   \u001b[0m | \u001b[0m 1.509   \u001b[0m | \u001b[0m 0.5866  \u001b[0m |\n",
      "| \u001b[0m 103     \u001b[0m | \u001b[0m 375.0   \u001b[0m | \u001b[0m 0.7592  \u001b[0m | \u001b[0m 0.5437  \u001b[0m |\n",
      "| \u001b[0m 104     \u001b[0m | \u001b[0m 375.0   \u001b[0m | \u001b[0m 0.7657  \u001b[0m | \u001b[0m 0.5443  \u001b[0m |\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[0;34m(self, init_points, n_iter, acq, kappa, xi, **gp_params)\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m                 \u001b[0mx_probe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Queue is empty, no more objects to retrieve.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStopIteration\u001b[0m: Queue is empty, no more objects to retrieve.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-8914d34d0e1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0moptimization_logreg1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBayesianOptimization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluateLogReg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_logreg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0moptimization_logreg1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[0;34m(self, init_points, n_iter, acq, kappa, xi, **gp_params)\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0mx_probe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m                 \u001b[0mx_probe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m                 \u001b[0miteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36msuggest\u001b[0;34m(self, utility_function)\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0my_max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0mbounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_random_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         )\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/bayes_opt/util.py\u001b[0m in \u001b[0;36macq_max\u001b[0;34m(ac, gp, y_max, bounds, random_state, n_warmup, n_iter)\u001b[0m\n\u001b[1;32m     56\u001b[0m                        \u001b[0mx_try\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                        \u001b[0mbounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                        method=\"L-BFGS-B\")\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# See if success\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0;32m--> 601\u001b[0;31m                                 callback=callback, **options)\n\u001b[0m\u001b[1;32m    602\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tnc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m         return _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_approx_fprime_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_approx_fprime_helper\u001b[0;34m(xk, f, epsilon, args, f0)\u001b[0m\n\u001b[1;32m    668\u001b[0m         \u001b[0mei\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mei\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m         \u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxk\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mf0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m         \u001b[0mei\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/bayes_opt/util.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx_try\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx_seeds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;31m# Find the minimum of minus the acquisition function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         res = minimize(lambda x: -ac(x.reshape(1, -1), gp=gp, y_max=y_max),\n\u001b[0m\u001b[1;32m     56\u001b[0m                        \u001b[0mx_try\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                        \u001b[0mbounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/bayes_opt/util.py\u001b[0m in \u001b[0;36mutility\u001b[0;34m(self, x, gp, y_max)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mutility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'ucb'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ucb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkappa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'ei'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ei\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/bayes_opt/util.py\u001b[0m in \u001b[0;36m_ucb\u001b[0;34m(x, gp, kappa)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_warnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_std\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmean\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mkappa\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, return_std, return_cov)\u001b[0m\n\u001b[1;32m    312\u001b[0m                 \"returning full covariance.\")\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"X_train_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Unfitted;predict based on GP prior\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mdtype_numeric\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflexible\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m             warnings.warn(\n\u001b[1;32m    557\u001b[0m                 \u001b[0;34m\"Beginning in version 0.22, arrays of bytes/strings will be \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/numerictypes.py\u001b[0m in \u001b[0;36missubdtype\u001b[0;34m(arg1, arg2)\u001b[0m\n\u001b[1;32m    423\u001b[0m             )\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def evaluateLogReg(C, pred_threshold):\n",
    "    clf = LogisticRegression(C=C, solver='lbfgs', max_iter=10000)\n",
    "    clf = CustomModelWithThreshold(clf,threshold=pred_threshold)\n",
    "    return sum(cross_validate(clf,X1_temporary, y1, scoring=profit_scoring, cv=cv)['test_score'])\n",
    "\n",
    "\n",
    "params_logreg = {\n",
    "    'C': (0.1, 5),\n",
    "    'pred_threshold': (0.5, 0.6)\n",
    "}\n",
    "\n",
    "optimization_logreg1 = BayesianOptimization(evaluateLogReg, params_logreg)\n",
    "optimization_logreg1.maximize(n_iter=100, init_points=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': 375.0,\n",
       " 'params': {'C': 0.7615716480588779, 'pred_threshold': 0.5397758971971408}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimization_logreg1.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lineItemVoids^2 valuePerSecond',\n",
       " 'scannedLineItemsTotal',\n",
       " 'scannedLineItemsPerSecond scannedLineItemsTotal',\n",
       " 'scannedLineItemsPerSecond valuePerLineItem^2',\n",
       " 'valuePerLineItem^2 lineItemVoids*scansWithoutRegistration',\n",
       " 'totalScanTimeInSeconds^2 lineItemVoids*scansWithoutRegistration',\n",
       " 'valuePerSecond scannedLineItemsTotal^2',\n",
       " 'scansWithoutRegistration scannedLineItemsTotal',\n",
       " 'totalScanTimeInSeconds scannedLineItemsPerSecond lineItemVoidsPerPosition',\n",
       " 'totalScanTimeInSeconds valuePerLineItem^2',\n",
       " 'scannedLineItemsTotal^2',\n",
       " 'valuePerSecond lineItemVoids*scansWithoutRegistration',\n",
       " 'scannedLineItemsTotal valuePerLineItem^2',\n",
       " 'quantityModifications^2 scannedLineItemsTotal',\n",
       " 'totalScanTimeInSeconds scannedLineItemsTotal valuePerLineItem',\n",
       " 'lineItemVoids scansWithoutRegistration quantityModifications',\n",
       " 'lineItemVoids quantityModifications quantityModificationsPerLineItem',\n",
       " 'totalScanTimeInSeconds lineItemVoids^2',\n",
       " 'lineItemVoids lineItemVoidsPerPosition',\n",
       " 'totalScanTimeInSeconds scansWithoutRegistration scannedLineItemsTotal']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# obtain selected feature names\n",
    "features_select_1 = [features_X_train1_all[i] for i in features_to_use1]\n",
    "features_select_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1_all = pd.DataFrame(X_train1_all, columns=features_X_train1_all)\n",
    "X_train1_selected = X_train1_all.loc[:,features_select_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test1_all = pd.DataFrame(X_test1_all, columns=features_X_test1_all)\n",
    "X_test1_selected = X_test1_all.loc[:,features_select_1]\n",
    "X_test1_selected.index = index_X_test1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final score for 'robustLogReg' in Trust=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "375"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify the score obtained from bayesian optimization\n",
    "C1 = optimization_logreg1.max['params']['C']\n",
    "pred_threshold1 = optimization_logreg1.max['params']['pred_threshold']\n",
    "\n",
    "clf1 = LogisticRegression(C=C1, solver='lbfgs', max_iter=10000)\n",
    "clf1 = CustomModelWithThreshold(clf1,threshold=pred_threshold1)\n",
    "# final score for trust=1\n",
    "cv = StratifiedKFold(n_splits=10, random_state=42)\n",
    "sum(cross_validate(clf1,X_train1_selected, y1, scoring=profit_scoring, cv=cv)['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of features used\n",
    "len(X1_temporary.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trust Level 2 (Feature Importance by Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/html/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/html/anaconda3/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/html/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "# normalize data first to prevent 0's in dataset\n",
    "scaler = StandardScaler()\n",
    "names_X_train2 = X_train2.columns\n",
    "X_train2 = scaler.fit_transform(X_train2)\n",
    "\n",
    "\n",
    "# for test transform with the scaler fitted on train\n",
    "names_X_test2 = X_test2.columns\n",
    "index_X_test2 = X_test2.index\n",
    "X_test2 = scaler.transform(X_test2)\n",
    "\n",
    "# generate features and rescale\n",
    "polyFeatures = PolynomialFeatures(3, interaction_only=False)\n",
    "X_train2_all = polyFeatures.fit_transform(X_train2)\n",
    "X_train2_all = scaler.fit_transform(X_train2_all)\n",
    "\n",
    "# for test transform with the scaler fitted on train\n",
    "X_test2_all = polyFeatures.transform(X_test2)\n",
    "X_test2_all = scaler.transform(X_test2_all)\n",
    "\n",
    "# remove first var (constant term)\n",
    "X_test2_all = X_test2_all[:,1:]\n",
    "features_X_test2_all = polyFeatures.get_feature_names(input_features=names_X_test2)[1:]\n",
    "\n",
    "# remove the first var because it is the constant term\n",
    "X_train2_all = X_train2_all[:,1:]\n",
    "features_X_train2_all = polyFeatures.get_feature_names(input_features=names_X_train2)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance with logistic Regression\n",
    "lr = LogisticRegression(C=20, solver='lbfgs')\n",
    "lr.fit(X_train2_all, y2)\n",
    "imp = lr.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# order the feature indices by importance\n",
    "imp = pd.DataFrame(imp)\n",
    "imp = imp.sort_values(by=0, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose starting model\n",
    "model = CustomModelWithThreshold(LogisticRegression(C=10, solver='lbfgs', max_iter=300), 0.9)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, random_state=42)\n",
    "last_score = -10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-75\n",
      "-55\n",
      "-45\n",
      "-25\n",
      "15\n",
      "35\n"
     ]
    }
   ],
   "source": [
    "# add most important feature\n",
    "X2_temporary = pd.DataFrame(X_train2_all[:,(list(imp.index))[0]])\n",
    "\n",
    "features_to_use2 = [(list(imp.index))[0]]\n",
    "# iteratively add features one by one\n",
    "for featnum in (list(imp.index))[1:]:\n",
    "    X_check = pd.concat([X2_temporary,pd.Series(X_train2_all[:,featnum])], axis=1)\n",
    "    score = sum(cross_validate(model,X_check, y2, scoring=profit_scoring, cv=cv)['test_score'])\n",
    "    # add the feature ultimatively if score improved\n",
    "    if score > last_score:\n",
    "        X2_temporary = pd.concat([X2_temporary,pd.Series(X_train2_all[:,featnum])], axis=1)\n",
    "        features_to_use2.append(featnum)\n",
    "        last_score = score    \n",
    "        print(last_score)\n",
    "    \n",
    "# for test predictions use features_to_use to select the according features in the test set    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |     C     | pred_t... |\n",
      "-------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 35.0    \u001b[0m | \u001b[0m 40.34   \u001b[0m | \u001b[0m 0.881   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 44.83   \u001b[0m | \u001b[0m 0.8641  \u001b[0m |\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m 45.0    \u001b[0m | \u001b[95m 2.262   \u001b[0m | \u001b[95m 0.5954  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 35.0    \u001b[0m | \u001b[0m 28.01   \u001b[0m | \u001b[0m 0.9039  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 29.4    \u001b[0m | \u001b[0m 0.7576  \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 25.0    \u001b[0m | \u001b[0m 12.3    \u001b[0m | \u001b[0m 0.9471  \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 38.09   \u001b[0m | \u001b[0m 0.7607  \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 39.75   \u001b[0m | \u001b[0m 0.6307  \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 35.0    \u001b[0m | \u001b[0m 45.56   \u001b[0m | \u001b[0m 0.8975  \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 30.41   \u001b[0m | \u001b[0m 0.827   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 19.46   \u001b[0m | \u001b[0m 0.7188  \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 35.0    \u001b[0m | \u001b[0m 7.44    \u001b[0m | \u001b[0m 0.7615  \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 25.0    \u001b[0m | \u001b[0m 7.712   \u001b[0m | \u001b[0m 0.9154  \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 33.24   \u001b[0m | \u001b[0m 0.7963  \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 35.0    \u001b[0m | \u001b[0m 42.07   \u001b[0m | \u001b[0m 0.9605  \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 35.0    \u001b[0m | \u001b[0m 5.126   \u001b[0m | \u001b[0m 0.7611  \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 35.0    \u001b[0m | \u001b[0m 19.52   \u001b[0m | \u001b[0m 0.8866  \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 42.02   \u001b[0m | \u001b[0m 0.7871  \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 16.28   \u001b[0m | \u001b[0m 0.7217  \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-15.0    \u001b[0m | \u001b[0m 24.49   \u001b[0m | \u001b[0m 0.5253  \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 40.49   \u001b[0m | \u001b[0m 0.6242  \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-15.0    \u001b[0m | \u001b[0m 35.99   \u001b[0m | \u001b[0m 0.5297  \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 13.67   \u001b[0m | \u001b[0m 0.619   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 31.64   \u001b[0m | \u001b[0m 0.7398  \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 12.25   \u001b[0m | \u001b[0m 0.6879  \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 33.49   \u001b[0m | \u001b[0m 0.7373  \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m-15.0    \u001b[0m | \u001b[0m 28.51   \u001b[0m | \u001b[0m 0.5238  \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 35.0    \u001b[0m | \u001b[0m 11.87   \u001b[0m | \u001b[0m 0.8053  \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 38.65   \u001b[0m | \u001b[0m 0.7055  \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 39.71   \u001b[0m | \u001b[0m 0.8343  \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 35.91   \u001b[0m | \u001b[0m 0.6987  \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 29.4    \u001b[0m | \u001b[0m 0.5892  \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 29.33   \u001b[0m | \u001b[0m 0.5974  \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 30.41   \u001b[0m | \u001b[0m 0.639   \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m 35.0    \u001b[0m | \u001b[0m 3.452   \u001b[0m | \u001b[0m 0.6367  \u001b[0m |\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 33.34   \u001b[0m | \u001b[0m 0.735   \u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m-15.0    \u001b[0m | \u001b[0m 27.39   \u001b[0m | \u001b[0m 0.5381  \u001b[0m |\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m 35.0    \u001b[0m | \u001b[0m 6.159   \u001b[0m | \u001b[0m 0.7108  \u001b[0m |\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m 35.0    \u001b[0m | \u001b[0m 11.27   \u001b[0m | \u001b[0m 0.8937  \u001b[0m |\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 25.82   \u001b[0m | \u001b[0m 0.6608  \u001b[0m |\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m 25.0    \u001b[0m | \u001b[0m 45.67   \u001b[0m | \u001b[0m 0.9726  \u001b[0m |\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 49.72   \u001b[0m | \u001b[0m 0.8842  \u001b[0m |\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 30.49   \u001b[0m | \u001b[0m 0.6524  \u001b[0m |\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m-15.0    \u001b[0m | \u001b[0m 30.2    \u001b[0m | \u001b[0m 0.507   \u001b[0m |\n",
      "| \u001b[0m 45      \u001b[0m | \u001b[0m 35.0    \u001b[0m | \u001b[0m 34.89   \u001b[0m | \u001b[0m 0.8751  \u001b[0m |\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m 35.0    \u001b[0m | \u001b[0m 31.68   \u001b[0m | \u001b[0m 0.8636  \u001b[0m |\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 7.507   \u001b[0m | \u001b[0m 0.5963  \u001b[0m |\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 34.49   \u001b[0m | \u001b[0m 0.8221  \u001b[0m |\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 43.86   \u001b[0m | \u001b[0m 0.8424  \u001b[0m |\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 44.89   \u001b[0m | \u001b[0m 0.8652  \u001b[0m |\n",
      "| \u001b[0m 51      \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 8.964   \u001b[0m | \u001b[0m 0.9885  \u001b[0m |\n",
      "| \u001b[0m 52      \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 22.95   \u001b[0m | \u001b[0m 0.6733  \u001b[0m |\n",
      "| \u001b[0m 53      \u001b[0m | \u001b[0m 35.0    \u001b[0m | \u001b[0m 19.39   \u001b[0m | \u001b[0m 0.9085  \u001b[0m |\n",
      "| \u001b[0m 54      \u001b[0m | \u001b[0m-15.0    \u001b[0m | \u001b[0m 46.4    \u001b[0m | \u001b[0m 0.5607  \u001b[0m |\n",
      "| \u001b[0m 55      \u001b[0m | \u001b[0m 35.0    \u001b[0m | \u001b[0m 3.729   \u001b[0m | \u001b[0m 0.6798  \u001b[0m |\n",
      "| \u001b[0m 56      \u001b[0m | \u001b[0m 35.0    \u001b[0m | \u001b[0m 48.41   \u001b[0m | \u001b[0m 0.9008  \u001b[0m |\n",
      "| \u001b[0m 57      \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 16.0    \u001b[0m | \u001b[0m 0.6404  \u001b[0m |\n",
      "| \u001b[0m 58      \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 42.22   \u001b[0m | \u001b[0m 0.7654  \u001b[0m |\n",
      "| \u001b[0m 59      \u001b[0m | \u001b[0m 35.0    \u001b[0m | \u001b[0m 8.93    \u001b[0m | \u001b[0m 0.7316  \u001b[0m |\n",
      "| \u001b[0m 60      \u001b[0m | \u001b[0m 35.0    \u001b[0m | \u001b[0m 11.48   \u001b[0m | \u001b[0m 0.7951  \u001b[0m |\n",
      "| \u001b[0m 61      \u001b[0m | \u001b[0m 35.0    \u001b[0m | \u001b[0m 38.03   \u001b[0m | \u001b[0m 0.9657  \u001b[0m |\n",
      "| \u001b[0m 62      \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 49.62   \u001b[0m | \u001b[0m 0.6525  \u001b[0m |\n",
      "| \u001b[0m 63      \u001b[0m | \u001b[0m 35.0    \u001b[0m | \u001b[0m 25.83   \u001b[0m | \u001b[0m 0.9326  \u001b[0m |\n",
      "| \u001b[0m 64      \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 18.55   \u001b[0m | \u001b[0m 0.6465  \u001b[0m |\n",
      "| \u001b[0m 65      \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 47.65   \u001b[0m | \u001b[0m 0.8119  \u001b[0m |\n",
      "| \u001b[0m 66      \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 33.69   \u001b[0m | \u001b[0m 0.8477  \u001b[0m |\n",
      "| \u001b[0m 67      \u001b[0m | \u001b[0m 35.0    \u001b[0m | \u001b[0m 31.74   \u001b[0m | \u001b[0m 0.9269  \u001b[0m |\n",
      "| \u001b[0m 68      \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 37.07   \u001b[0m | \u001b[0m 0.688   \u001b[0m |\n",
      "| \u001b[0m 69      \u001b[0m | \u001b[0m-15.0    \u001b[0m | \u001b[0m 23.5    \u001b[0m | \u001b[0m 0.5421  \u001b[0m |\n",
      "| \u001b[0m 70      \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 9.326   \u001b[0m | \u001b[0m 0.6276  \u001b[0m |\n",
      "| \u001b[0m 71      \u001b[0m | \u001b[0m 35.0    \u001b[0m | \u001b[0m 36.19   \u001b[0m | \u001b[0m 0.9528  \u001b[0m |\n",
      "| \u001b[0m 72      \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 3.329   \u001b[0m | \u001b[0m 0.92    \u001b[0m |\n",
      "| \u001b[0m 73      \u001b[0m | \u001b[0m 35.0    \u001b[0m | \u001b[0m 41.18   \u001b[0m | \u001b[0m 0.8944  \u001b[0m |\n",
      "| \u001b[0m 74      \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 43.18   \u001b[0m | \u001b[0m 0.6696  \u001b[0m |\n",
      "| \u001b[0m 75      \u001b[0m | \u001b[0m-15.0    \u001b[0m | \u001b[0m 14.91   \u001b[0m | \u001b[0m 0.5126  \u001b[0m |\n",
      "| \u001b[0m 76      \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 11.36   \u001b[0m | \u001b[0m 0.5374  \u001b[0m |\n",
      "| \u001b[0m 77      \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 45.46   \u001b[0m | \u001b[0m 0.8332  \u001b[0m |\n",
      "| \u001b[0m 78      \u001b[0m | \u001b[0m 35.0    \u001b[0m | \u001b[0m 7.013   \u001b[0m | \u001b[0m 0.6974  \u001b[0m |\n",
      "| \u001b[0m 79      \u001b[0m | \u001b[0m 35.0    \u001b[0m | \u001b[0m 17.58   \u001b[0m | \u001b[0m 0.8388  \u001b[0m |\n",
      "| \u001b[0m 80      \u001b[0m | \u001b[0m 25.0    \u001b[0m | \u001b[0m 11.11   \u001b[0m | \u001b[0m 0.9355  \u001b[0m |\n",
      "| \u001b[0m 81      \u001b[0m | \u001b[0m 35.0    \u001b[0m | \u001b[0m 32.53   \u001b[0m | \u001b[0m 0.916   \u001b[0m |\n",
      "| \u001b[0m 82      \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 36.42   \u001b[0m | \u001b[0m 0.7421  \u001b[0m |\n",
      "| \u001b[0m 83      \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 28.18   \u001b[0m | \u001b[0m 0.5685  \u001b[0m |\n",
      "| \u001b[0m 84      \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 18.56   \u001b[0m | \u001b[0m 0.5488  \u001b[0m |\n",
      "| \u001b[0m 85      \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 11.14   \u001b[0m | \u001b[0m 0.6845  \u001b[0m |\n",
      "| \u001b[0m 86      \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 27.53   \u001b[0m | \u001b[0m 0.8039  \u001b[0m |\n",
      "| \u001b[0m 87      \u001b[0m | \u001b[0m-15.0    \u001b[0m | \u001b[0m 13.58   \u001b[0m | \u001b[0m 0.501   \u001b[0m |\n",
      "| \u001b[0m 88      \u001b[0m | \u001b[0m-15.0    \u001b[0m | \u001b[0m 46.25   \u001b[0m | \u001b[0m 0.5469  \u001b[0m |\n",
      "| \u001b[0m 89      \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 20.04   \u001b[0m | \u001b[0m 0.6318  \u001b[0m |\n",
      "| \u001b[0m 90      \u001b[0m | \u001b[0m 35.0    \u001b[0m | \u001b[0m 12.66   \u001b[0m | \u001b[0m 0.8738  \u001b[0m |\n",
      "| \u001b[0m 91      \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 16.68   \u001b[0m | \u001b[0m 0.5846  \u001b[0m |\n",
      "| \u001b[0m 92      \u001b[0m | \u001b[0m 25.0    \u001b[0m | \u001b[0m 43.17   \u001b[0m | \u001b[0m 0.9763  \u001b[0m |\n",
      "| \u001b[0m 93      \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 19.34   \u001b[0m | \u001b[0m 0.7745  \u001b[0m |\n",
      "| \u001b[0m 94      \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 11.16   \u001b[0m | \u001b[0m 0.5794  \u001b[0m |\n",
      "| \u001b[0m 95      \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 18.24   \u001b[0m | \u001b[0m 0.6959  \u001b[0m |\n",
      "| \u001b[0m 96      \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 30.0    \u001b[0m | \u001b[0m 0.7301  \u001b[0m |\n",
      "| \u001b[0m 97      \u001b[0m | \u001b[0m 25.0    \u001b[0m | \u001b[0m 24.1    \u001b[0m | \u001b[0m 0.983   \u001b[0m |\n",
      "| \u001b[0m 98      \u001b[0m | \u001b[0m 35.0    \u001b[0m | \u001b[0m 34.18   \u001b[0m | \u001b[0m 0.8642  \u001b[0m |\n",
      "| \u001b[0m 99      \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 22.56   \u001b[0m | \u001b[0m 0.8084  \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 100     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 47.41   \u001b[0m | \u001b[0m 0.7219  \u001b[0m |\n",
      "| \u001b[0m 101     \u001b[0m | \u001b[0m 45.0    \u001b[0m | \u001b[0m 2.256   \u001b[0m | \u001b[0m 0.5966  \u001b[0m |\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[0;34m(self, init_points, n_iter, acq, kappa, xi, **gp_params)\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m                 \u001b[0mx_probe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Queue is empty, no more objects to retrieve.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStopIteration\u001b[0m: Queue is empty, no more objects to retrieve.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-37234c8ea531>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0moptimization_logreg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBayesianOptimization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluateLogReg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_logreg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0moptimization_logreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[0;34m(self, init_points, n_iter, acq, kappa, xi, **gp_params)\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0mx_probe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m                 \u001b[0mx_probe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m                 \u001b[0miteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36msuggest\u001b[0;34m(self, utility_function)\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0my_max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0mbounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_random_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         )\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/bayes_opt/util.py\u001b[0m in \u001b[0;36macq_max\u001b[0;34m(ac, gp, y_max, bounds, random_state, n_warmup, n_iter)\u001b[0m\n\u001b[1;32m     44\u001b[0m     x_tries = random_state.uniform(bounds[:, 0], bounds[:, 1],\n\u001b[1;32m     45\u001b[0m                                    size=(n_warmup, bounds.shape[0]))\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mac\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0mx_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_tries\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mmax_acq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/bayes_opt/util.py\u001b[0m in \u001b[0;36mutility\u001b[0;34m(self, x, gp, y_max)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mutility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'ucb'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ucb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkappa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'ei'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ei\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/bayes_opt/util.py\u001b[0m in \u001b[0;36m_ucb\u001b[0;34m(x, gp, kappa)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_warnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_std\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmean\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mkappa\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, return_std, return_cov)\u001b[0m\n\u001b[1;32m    349\u001b[0m                 \u001b[0my_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m                 y_var -= np.einsum(\"ij,ij->i\",\n\u001b[0;32m--> 351\u001b[0;31m                                    np.dot(K_trans, self._K_inv), K_trans)\n\u001b[0m\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m                 \u001b[0;31m# Check if any of the variances is negative because of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# dataset in function is X2\n",
    "def evaluateLogReg(C, pred_threshold):\n",
    "    clf = LogisticRegression(C=C, solver='lbfgs', max_iter=10000)\n",
    "    clf = CustomModelWithThreshold(clf,threshold=pred_threshold)\n",
    "    return sum(cross_validate(clf,X2_temporary, y2, scoring=profit_scoring, cv=cv)['test_score'])\n",
    "\n",
    "\n",
    "params_logreg = {\n",
    "    'C': (0.001, 50),\n",
    "    'pred_threshold': (0.5, 1)\n",
    "}\n",
    "\n",
    "optimization_logreg = BayesianOptimization(evaluateLogReg, params_logreg)\n",
    "optimization_logreg.maximize(n_iter=100, init_points=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': 45.0,\n",
       " 'params': {'C': 2.2620169543165747, 'pred_threshold': 0.5954276044708}}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimization_logreg.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scannedLineItemsTotal^2',\n",
       " 'scannedLineItemsTotal^3',\n",
       " 'totalScanTimeInSeconds scannedLineItemsTotal^2',\n",
       " 'totalScanTimeInSeconds lineItemVoids scannedLineItemsTotal',\n",
       " 'totalScanTimeInSeconds scannedLineItemsTotal valuePerLineItem',\n",
       " 'totalScanTimeInSeconds scansWithoutRegistration valuePerLineItem',\n",
       " 'scannedLineItemsTotal^2 lineItemVoids*scansWithoutRegistration']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_select_2 = [features_X_train2_all[i] for i in features_to_use2]\n",
    "features_select_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2_all = pd.DataFrame(X_train2_all, columns=features_X_train2_all)\n",
    "X_train2_selected = X_train2_all.loc[:,features_select_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test2_all = pd.DataFrame(X_test2_all, columns=features_X_test2_all)\n",
    "X_test2_selected = X_test2_all.loc[:,features_select_2]\n",
    "X_test2_selected.index = index_X_test2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final score for 'robustLogReg' in Trust=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify\n",
    "C2 = optimization_logreg.max['params']['C']\n",
    "pred_threshold2 = optimization_logreg.max['params']['pred_threshold']\n",
    "\n",
    "clf2 = LogisticRegression(C=C2, solver='lbfgs', max_iter=10000)\n",
    "clf2 = CustomModelWithThreshold(clf2,threshold=pred_threshold2)\n",
    "# final score for trust=2\n",
    "cv = StratifiedKFold(n_splits=10, random_state=42)\n",
    "sum(cross_validate(clf2,X_train2_selected, y2, scoring=profit_scoring, cv=cv)['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of features used\n",
    "len(X2_temporary.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make final Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if the indices are disjunct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([     2,     17,     32,     36,     45,     52,     57,     65,\n",
       "                73,     74,\n",
       "            ...\n",
       "            498045, 498052, 498060, 498080, 498085, 498092, 498099, 498101,\n",
       "            498112, 498117],\n",
       "           dtype='int64', length=82713)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test1_selected.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([     7,     22,     37,     48,     70,     71,     77,     81,\n",
       "                93,    101,\n",
       "            ...\n",
       "            498058, 498067, 498069, 498071, 498073, 498097, 498102, 498105,\n",
       "            498108, 498119],\n",
       "           dtype='int64', length=82913)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test2_selected.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([     0,      1,      3,      4,      5,      6,      8,      9,\n",
       "                10,     11,\n",
       "            ...\n",
       "            498107, 498109, 498110, 498111, 498113, 498114, 498115, 498116,\n",
       "            498118, 498120],\n",
       "           dtype='int64', length=332495)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_higher.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trust=1\n",
    "clf1.fit(X_train1_selected, y1)\n",
    "X_test1_selected['preds'] = clf1.predict(X_test1_selected)\n",
    "#Trust=2\n",
    "clf2.fit(X_train2_selected, y2)\n",
    "X_test2_selected['preds'] = clf2.predict(X_test2_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/html/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#Higher Trust\n",
    "X_test_higher['preds'] = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pd.concat([X_test1_selected['preds'],X_test2_selected['preds'],X_test_higher['preds'],])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_pred.astype({'preds':'int'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reload test set and concat the predictions to check if they make sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv('test.csv', delimiter=\"|\")\n",
    "X_test['fraud'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23305889037998864"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum((X_test['fraud']==1) & (X_test['trustLevel']==1)) / sum(X_test['trustLevel']==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04796594020238081"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum((X_test['fraud']==1) & (X_test['trustLevel']==2)) / sum(X_test['trustLevel']==2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum((X_test['fraud']==1) & (X_test['trustLevel']>2)) / sum(X_test['trustLevel']>2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trustLevel</th>\n",
       "      <th>totalScanTimeInSeconds</th>\n",
       "      <th>grandTotal</th>\n",
       "      <th>lineItemVoids</th>\n",
       "      <th>scansWithoutRegistration</th>\n",
       "      <th>quantityModifications</th>\n",
       "      <th>scannedLineItemsPerSecond</th>\n",
       "      <th>valuePerSecond</th>\n",
       "      <th>lineItemVoidsPerPosition</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>467</td>\n",
       "      <td>88.48</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.014989</td>\n",
       "      <td>0.189465</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1004</td>\n",
       "      <td>58.99</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.026892</td>\n",
       "      <td>0.058755</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>162</td>\n",
       "      <td>14.00</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.006173</td>\n",
       "      <td>0.086420</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>532</td>\n",
       "      <td>84.79</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.159380</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>890</td>\n",
       "      <td>42.16</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.021348</td>\n",
       "      <td>0.047371</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1072</td>\n",
       "      <td>12.67</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.019590</td>\n",
       "      <td>0.011819</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>259</td>\n",
       "      <td>93.75</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.100386</td>\n",
       "      <td>0.361969</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>1528</td>\n",
       "      <td>47.35</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0.009817</td>\n",
       "      <td>0.030988</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6</td>\n",
       "      <td>816</td>\n",
       "      <td>80.89</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.017157</td>\n",
       "      <td>0.099130</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>31.91</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1.312500</td>\n",
       "      <td>1.994375</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>714</td>\n",
       "      <td>94.29</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.132059</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>1077</td>\n",
       "      <td>66.16</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.015785</td>\n",
       "      <td>0.061430</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4</td>\n",
       "      <td>1301</td>\n",
       "      <td>84.35</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.021522</td>\n",
       "      <td>0.064835</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>1429</td>\n",
       "      <td>47.95</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.003499</td>\n",
       "      <td>0.033555</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>1196</td>\n",
       "      <td>83.77</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004181</td>\n",
       "      <td>0.070042</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>1567</td>\n",
       "      <td>75.53</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.008296</td>\n",
       "      <td>0.048200</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "      <td>289</td>\n",
       "      <td>18.66</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.086505</td>\n",
       "      <td>0.064567</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>335</td>\n",
       "      <td>1.19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.032836</td>\n",
       "      <td>0.003552</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3</td>\n",
       "      <td>1304</td>\n",
       "      <td>30.51</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.012270</td>\n",
       "      <td>0.023397</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5</td>\n",
       "      <td>1353</td>\n",
       "      <td>82.02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.005174</td>\n",
       "      <td>0.060621</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>6</td>\n",
       "      <td>1749</td>\n",
       "      <td>46.56</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.012007</td>\n",
       "      <td>0.026621</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5</td>\n",
       "      <td>757</td>\n",
       "      <td>91.02</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.019815</td>\n",
       "      <td>0.120238</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>1440</td>\n",
       "      <td>15.15</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.010521</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4</td>\n",
       "      <td>1101</td>\n",
       "      <td>22.55</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.019982</td>\n",
       "      <td>0.020481</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6</td>\n",
       "      <td>1404</td>\n",
       "      <td>59.43</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.015670</td>\n",
       "      <td>0.042329</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>6</td>\n",
       "      <td>1396</td>\n",
       "      <td>13.16</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010745</td>\n",
       "      <td>0.009427</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4</td>\n",
       "      <td>248</td>\n",
       "      <td>14.00</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.100806</td>\n",
       "      <td>0.056452</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3</td>\n",
       "      <td>359</td>\n",
       "      <td>6.40</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.019499</td>\n",
       "      <td>0.017827</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>6</td>\n",
       "      <td>915</td>\n",
       "      <td>36.79</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007650</td>\n",
       "      <td>0.040208</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5</td>\n",
       "      <td>617</td>\n",
       "      <td>49.57</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.035656</td>\n",
       "      <td>0.080340</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498091</th>\n",
       "      <td>4</td>\n",
       "      <td>1691</td>\n",
       "      <td>22.89</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0.007688</td>\n",
       "      <td>0.013536</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498092</th>\n",
       "      <td>1</td>\n",
       "      <td>1685</td>\n",
       "      <td>61.99</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001187</td>\n",
       "      <td>0.036789</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498093</th>\n",
       "      <td>4</td>\n",
       "      <td>275</td>\n",
       "      <td>48.23</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.175382</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498094</th>\n",
       "      <td>5</td>\n",
       "      <td>1085</td>\n",
       "      <td>50.15</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.012903</td>\n",
       "      <td>0.046221</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498095</th>\n",
       "      <td>5</td>\n",
       "      <td>687</td>\n",
       "      <td>33.47</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.036390</td>\n",
       "      <td>0.048719</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498096</th>\n",
       "      <td>6</td>\n",
       "      <td>425</td>\n",
       "      <td>18.91</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.009412</td>\n",
       "      <td>0.044494</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498097</th>\n",
       "      <td>2</td>\n",
       "      <td>671</td>\n",
       "      <td>86.03</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.038748</td>\n",
       "      <td>0.128212</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498098</th>\n",
       "      <td>4</td>\n",
       "      <td>1705</td>\n",
       "      <td>98.66</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.002346</td>\n",
       "      <td>0.057865</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498099</th>\n",
       "      <td>1</td>\n",
       "      <td>1822</td>\n",
       "      <td>75.30</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.016465</td>\n",
       "      <td>0.041328</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498100</th>\n",
       "      <td>3</td>\n",
       "      <td>1151</td>\n",
       "      <td>11.37</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.021720</td>\n",
       "      <td>0.009878</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498101</th>\n",
       "      <td>1</td>\n",
       "      <td>796</td>\n",
       "      <td>85.72</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001256</td>\n",
       "      <td>0.107688</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498102</th>\n",
       "      <td>2</td>\n",
       "      <td>1379</td>\n",
       "      <td>48.64</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0.014503</td>\n",
       "      <td>0.035272</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498103</th>\n",
       "      <td>6</td>\n",
       "      <td>885</td>\n",
       "      <td>92.41</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.104418</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498104</th>\n",
       "      <td>3</td>\n",
       "      <td>441</td>\n",
       "      <td>36.91</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.004535</td>\n",
       "      <td>0.083696</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498105</th>\n",
       "      <td>2</td>\n",
       "      <td>319</td>\n",
       "      <td>57.74</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.094044</td>\n",
       "      <td>0.181003</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498106</th>\n",
       "      <td>4</td>\n",
       "      <td>1228</td>\n",
       "      <td>74.44</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.022801</td>\n",
       "      <td>0.060619</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498107</th>\n",
       "      <td>4</td>\n",
       "      <td>708</td>\n",
       "      <td>19.56</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.002825</td>\n",
       "      <td>0.027627</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498108</th>\n",
       "      <td>2</td>\n",
       "      <td>1726</td>\n",
       "      <td>99.80</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007532</td>\n",
       "      <td>0.057822</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498109</th>\n",
       "      <td>4</td>\n",
       "      <td>961</td>\n",
       "      <td>18.62</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003122</td>\n",
       "      <td>0.019376</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498110</th>\n",
       "      <td>3</td>\n",
       "      <td>585</td>\n",
       "      <td>26.17</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.044735</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498111</th>\n",
       "      <td>4</td>\n",
       "      <td>983</td>\n",
       "      <td>57.72</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.030519</td>\n",
       "      <td>0.058718</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498112</th>\n",
       "      <td>1</td>\n",
       "      <td>1342</td>\n",
       "      <td>69.89</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002981</td>\n",
       "      <td>0.052079</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498113</th>\n",
       "      <td>5</td>\n",
       "      <td>553</td>\n",
       "      <td>95.44</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.045208</td>\n",
       "      <td>0.172586</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498114</th>\n",
       "      <td>6</td>\n",
       "      <td>1767</td>\n",
       "      <td>65.98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.013016</td>\n",
       "      <td>0.037340</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498115</th>\n",
       "      <td>6</td>\n",
       "      <td>879</td>\n",
       "      <td>96.34</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.020478</td>\n",
       "      <td>0.109602</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498116</th>\n",
       "      <td>4</td>\n",
       "      <td>783</td>\n",
       "      <td>59.10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.012771</td>\n",
       "      <td>0.075479</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498117</th>\n",
       "      <td>1</td>\n",
       "      <td>278</td>\n",
       "      <td>98.90</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.050360</td>\n",
       "      <td>0.355755</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498118</th>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>5.41</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.018033</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498119</th>\n",
       "      <td>2</td>\n",
       "      <td>1524</td>\n",
       "      <td>33.97</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005906</td>\n",
       "      <td>0.022290</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498120</th>\n",
       "      <td>3</td>\n",
       "      <td>1456</td>\n",
       "      <td>56.97</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>0.039128</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>498121 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        trustLevel  totalScanTimeInSeconds  grandTotal  lineItemVoids  \\\n",
       "0                4                     467       88.48              4   \n",
       "1                3                    1004       58.99              7   \n",
       "2                1                     162       14.00              4   \n",
       "3                5                     532       84.79              9   \n",
       "4                5                     890       42.16              4   \n",
       "5                5                    1072       12.67              3   \n",
       "6                3                     259       93.75              0   \n",
       "7                2                    1528       47.35              2   \n",
       "8                6                     816       80.89              9   \n",
       "9                4                      16       31.91              7   \n",
       "10               3                     714       94.29              8   \n",
       "11               5                    1077       66.16              5   \n",
       "12               4                    1301       84.35              3   \n",
       "13               3                    1429       47.95              8   \n",
       "14               3                    1196       83.77             11   \n",
       "15               3                    1567       75.53              7   \n",
       "16               4                     289       18.66              8   \n",
       "17               1                     335        1.19              0   \n",
       "18               3                    1304       30.51              0   \n",
       "19               5                    1353       82.02              0   \n",
       "20               6                    1749       46.56              5   \n",
       "21               5                     757       91.02              9   \n",
       "22               2                    1440       15.15              0   \n",
       "23               4                    1101       22.55              8   \n",
       "24               6                    1404       59.43              5   \n",
       "25               6                    1396       13.16             11   \n",
       "26               4                     248       14.00              9   \n",
       "27               3                     359        6.40              0   \n",
       "28               6                     915       36.79              9   \n",
       "29               5                     617       49.57              0   \n",
       "...            ...                     ...         ...            ...   \n",
       "498091           4                    1691       22.89             10   \n",
       "498092           1                    1685       61.99              6   \n",
       "498093           4                     275       48.23              6   \n",
       "498094           5                    1085       50.15              3   \n",
       "498095           5                     687       33.47              7   \n",
       "498096           6                     425       18.91              7   \n",
       "498097           2                     671       86.03             11   \n",
       "498098           4                    1705       98.66              5   \n",
       "498099           1                    1822       75.30              9   \n",
       "498100           3                    1151       11.37              3   \n",
       "498101           1                     796       85.72              9   \n",
       "498102           2                    1379       48.64             11   \n",
       "498103           6                     885       92.41              6   \n",
       "498104           3                     441       36.91              0   \n",
       "498105           2                     319       57.74              2   \n",
       "498106           4                    1228       74.44              6   \n",
       "498107           4                     708       19.56              8   \n",
       "498108           2                    1726       99.80              1   \n",
       "498109           4                     961       18.62              1   \n",
       "498110           3                     585       26.17              0   \n",
       "498111           4                     983       57.72              4   \n",
       "498112           1                    1342       69.89              8   \n",
       "498113           5                     553       95.44              9   \n",
       "498114           6                    1767       65.98              0   \n",
       "498115           6                     879       96.34              2   \n",
       "498116           4                     783       59.10              2   \n",
       "498117           1                     278       98.90              9   \n",
       "498118           3                     300        5.41              6   \n",
       "498119           2                    1524       33.97              2   \n",
       "498120           3                    1456       56.97             11   \n",
       "\n",
       "        scansWithoutRegistration  quantityModifications  \\\n",
       "0                              8                      4   \n",
       "1                              6                      1   \n",
       "2                              5                      4   \n",
       "3                              3                      4   \n",
       "4                              0                      0   \n",
       "5                              4                      1   \n",
       "6                              7                      0   \n",
       "7                              9                      5   \n",
       "8                              4                      0   \n",
       "9                              7                      4   \n",
       "10                             7                      0   \n",
       "11                             8                      3   \n",
       "12                            10                      5   \n",
       "13                             1                      3   \n",
       "14                            10                      0   \n",
       "15                            10                      1   \n",
       "16                             4                      0   \n",
       "17                             0                      1   \n",
       "18                             7                      3   \n",
       "19                             0                      2   \n",
       "20                             0                      5   \n",
       "21                             3                      0   \n",
       "22                             6                      5   \n",
       "23                             9                      0   \n",
       "24                             8                      5   \n",
       "25                             2                      0   \n",
       "26                             4                      2   \n",
       "27                             5                      3   \n",
       "28                             0                      0   \n",
       "29                             5                      1   \n",
       "...                          ...                    ...   \n",
       "498091                         6                      5   \n",
       "498092                         0                      4   \n",
       "498093                         1                      3   \n",
       "498094                         6                      2   \n",
       "498095                         1                      1   \n",
       "498096                         9                      4   \n",
       "498097                         1                      5   \n",
       "498098                         3                      2   \n",
       "498099                         2                      4   \n",
       "498100                         1                      0   \n",
       "498101                         3                      1   \n",
       "498102                         7                      5   \n",
       "498103                         5                      0   \n",
       "498104                         8                      4   \n",
       "498105                         1                      0   \n",
       "498106                         5                      3   \n",
       "498107                         1                      3   \n",
       "498108                        10                      1   \n",
       "498109                         0                      1   \n",
       "498110                         9                      2   \n",
       "498111                         9                      4   \n",
       "498112                        10                      5   \n",
       "498113                         5                      5   \n",
       "498114                         0                      1   \n",
       "498115                         9                      1   \n",
       "498116                         2                      0   \n",
       "498117                         5                      4   \n",
       "498118                         6                      4   \n",
       "498119                         5                      3   \n",
       "498120                         7                      2   \n",
       "\n",
       "        scannedLineItemsPerSecond  valuePerSecond  lineItemVoidsPerPosition  \\\n",
       "0                        0.014989        0.189465                  0.571429   \n",
       "1                        0.026892        0.058755                  0.259259   \n",
       "2                        0.006173        0.086420                  4.000000   \n",
       "3                        0.026316        0.159380                  0.642857   \n",
       "4                        0.021348        0.047371                  0.210526   \n",
       "5                        0.019590        0.011819                  0.142857   \n",
       "6                        0.100386        0.361969                  0.000000   \n",
       "7                        0.009817        0.030988                  0.133333   \n",
       "8                        0.017157        0.099130                  0.642857   \n",
       "9                        1.312500        1.994375                  0.333333   \n",
       "10                       0.016807        0.132059                  0.666667   \n",
       "11                       0.015785        0.061430                  0.294118   \n",
       "12                       0.021522        0.064835                  0.107143   \n",
       "13                       0.003499        0.033555                  1.600000   \n",
       "14                       0.004181        0.070042                  2.200000   \n",
       "15                       0.008296        0.048200                  0.538462   \n",
       "16                       0.086505        0.064567                  0.320000   \n",
       "17                       0.032836        0.003552                  0.000000   \n",
       "18                       0.012270        0.023397                  0.000000   \n",
       "19                       0.005174        0.060621                  0.000000   \n",
       "20                       0.012007        0.026621                  0.238095   \n",
       "21                       0.019815        0.120238                  0.600000   \n",
       "22                       0.016667        0.010521                  0.000000   \n",
       "23                       0.019982        0.020481                  0.363636   \n",
       "24                       0.015670        0.042329                  0.227273   \n",
       "25                       0.010745        0.009427                  0.733333   \n",
       "26                       0.100806        0.056452                  0.360000   \n",
       "27                       0.019499        0.017827                  0.000000   \n",
       "28                       0.007650        0.040208                  1.285714   \n",
       "29                       0.035656        0.080340                  0.000000   \n",
       "...                           ...             ...                       ...   \n",
       "498091                   0.007688        0.013536                  0.769231   \n",
       "498092                   0.001187        0.036789                  3.000000   \n",
       "498093                   0.040000        0.175382                  0.545455   \n",
       "498094                   0.012903        0.046221                  0.214286   \n",
       "498095                   0.036390        0.048719                  0.280000   \n",
       "498096                   0.009412        0.044494                  1.750000   \n",
       "498097                   0.038748        0.128212                  0.423077   \n",
       "498098                   0.002346        0.057865                  1.250000   \n",
       "498099                   0.016465        0.041328                  0.300000   \n",
       "498100                   0.021720        0.009878                  0.120000   \n",
       "498101                   0.001256        0.107688                  9.000000   \n",
       "498102                   0.014503        0.035272                  0.550000   \n",
       "498103                   0.016949        0.104418                  0.400000   \n",
       "498104                   0.004535        0.083696                  0.000000   \n",
       "498105                   0.094044        0.181003                  0.066667   \n",
       "498106                   0.022801        0.060619                  0.214286   \n",
       "498107                   0.002825        0.027627                  4.000000   \n",
       "498108                   0.007532        0.057822                  0.076923   \n",
       "498109                   0.003122        0.019376                  0.333333   \n",
       "498110                   0.022222        0.044735                  0.000000   \n",
       "498111                   0.030519        0.058718                  0.133333   \n",
       "498112                   0.002981        0.052079                  2.000000   \n",
       "498113                   0.045208        0.172586                  0.360000   \n",
       "498114                   0.013016        0.037340                  0.000000   \n",
       "498115                   0.020478        0.109602                  0.111111   \n",
       "498116                   0.012771        0.075479                  0.200000   \n",
       "498117                   0.050360        0.355755                  0.642857   \n",
       "498118                   0.030000        0.018033                  0.666667   \n",
       "498119                   0.005906        0.022290                  0.222222   \n",
       "498120                   0.019231        0.039128                  0.392857   \n",
       "\n",
       "        fraud  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "5           0  \n",
       "6           0  \n",
       "7           0  \n",
       "8           0  \n",
       "9           0  \n",
       "10          0  \n",
       "11          0  \n",
       "12          0  \n",
       "13          0  \n",
       "14          0  \n",
       "15          0  \n",
       "16          0  \n",
       "17          0  \n",
       "18          0  \n",
       "19          0  \n",
       "20          0  \n",
       "21          0  \n",
       "22          0  \n",
       "23          0  \n",
       "24          0  \n",
       "25          0  \n",
       "26          0  \n",
       "27          0  \n",
       "28          0  \n",
       "29          0  \n",
       "...       ...  \n",
       "498091      0  \n",
       "498092      0  \n",
       "498093      0  \n",
       "498094      0  \n",
       "498095      0  \n",
       "498096      0  \n",
       "498097      0  \n",
       "498098      0  \n",
       "498099      1  \n",
       "498100      0  \n",
       "498101      0  \n",
       "498102      0  \n",
       "498103      0  \n",
       "498104      0  \n",
       "498105      0  \n",
       "498106      0  \n",
       "498107      0  \n",
       "498108      0  \n",
       "498109      0  \n",
       "498110      0  \n",
       "498111      0  \n",
       "498112      0  \n",
       "498113      0  \n",
       "498114      0  \n",
       "498115      0  \n",
       "498116      0  \n",
       "498117      0  \n",
       "498118      0  \n",
       "498119      0  \n",
       "498120      0  \n",
       "\n",
       "[498121 rows x 10 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The prediction proportions are very similar to the proportions in the train set. Therefore, save as csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.to_csv(\"finalPredictionGroup6.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
