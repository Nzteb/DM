{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "import itertools\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from sklearn import svm as SVM\n",
    "from funcs import cv_profits_for_models, cv_preds_and_confusion_matrix, CustomModelWithThreshold\n",
    "from funcs import profit_scorer, profit_scoring\n",
    "from customClassifiers import OutlierRemover\n",
    "from xgboost import XGBClassifier\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, SelectFromModel\n",
    "from sklearn.feature_selection import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('train.csv' ,delimiter=\"|\")\n",
    "X_test = pd.read_csv('test.csv', delimiter=\"|\")\n",
    "\n",
    "X_train['scannedLineItemsTotal'] = X_train['scannedLineItemsPerSecond'] * X_train['totalScanTimeInSeconds']\n",
    "X_train['valuePerLineItem'] = X_train['grandTotal'] * X_train['scannedLineItemsTotal']\n",
    "X_train['quantityModificationsPerLineItem'] = X_train['quantityModifications'] * X_train['scannedLineItemsTotal']\n",
    "X_train['lineItemVoids*scansWithoutRegistration'] = X_train['lineItemVoids'] * X_train['scansWithoutRegistration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1 = X_train[X_train['trustLevel']==1]\n",
    "y1 = X_train1.pop('fraud')\n",
    "l=X_train1.pop('trustLevel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2 = X_train[X_train['trustLevel']==2]\n",
    "y2 = X_train2.pop('fraud')\n",
    "l=X_train2.pop('trustLevel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trust Level 1 (Calculate Feature Importance with XGboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/niklas/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/niklas/.local/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "# normalize data first to prevent 0's in dataset\n",
    "scaler = StandardScaler()\n",
    "names_X_train1 = X_train1.columns\n",
    "X_train1 = scaler.fit_transform(X_train1)\n",
    "\n",
    "# generate features and rescale\n",
    "polyFeatures = PolynomialFeatures(3, interaction_only=False)\n",
    "X_train1_all = polyFeatures.fit_transform(X_train1)\n",
    "X_train1_all = scaler.fit_transform(X_train1_all)\n",
    "\n",
    "#remove the first var because it is the constant term\n",
    "X_train1_all = X_train1_all[:,1:]\n",
    "features_X_train1_all = polyFeatures.get_feature_names(input_features=names_X_train1)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain feature importance by xgboost\n",
    "xgb = XGBClassifier(num_estimator=100)\n",
    "xgb.fit(X_train1_all, y1)\n",
    "imp = xgb.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# order the feature indices by importance\n",
    "imp = pd.DataFrame(imp)\n",
    "imp = imp.sort_values(by=0, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_use1_cv = []\n",
    "for cvNew in np.arange(0,100,20):\n",
    "    # choose starting model\n",
    "    model = CustomModelWithThreshold(LogisticRegression(C=10, solver='lbfgs', max_iter=300), 0.9)\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=10, random_state=cvNew, shuffle=True)\n",
    "    last_score = -10000\n",
    "\n",
    "    # add most important feature\n",
    "    X1_temporary = pd.DataFrame(X_train1_all[:,(list(imp.index))[0]])\n",
    "\n",
    "    features_to_use1 = [(list(imp.index))[0]]\n",
    "    # iteratively add features one by one\n",
    "    for featnum in (list(imp.index))[1:]:\n",
    "        X_check = pd.concat([X1_temporary,pd.Series(X_train1_all[:,featnum])], axis=1)\n",
    "        score = sum(cross_validate(model,X_check, y1, scoring=profit_scoring, cv=cv)['test_score'])\n",
    "        # add the feature ultimatively if score improved\n",
    "        if score > last_score:\n",
    "            X1_temporary = pd.concat([X1_temporary,pd.Series(X_train1_all[:,featnum])], axis=1)\n",
    "            features_to_use1.append(featnum)\n",
    "            last_score = score    \n",
    "            #print(last_score)\n",
    "    \n",
    "    # for test predictions use features_to_use to select the according features in the test set\n",
    "    features_to_use1_names = [features_X_train1_all[i] for i in features_to_use1]\n",
    "    features_to_use1_cv = features_to_use1_cv + features_to_use1_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'scannedLineItemsTotal': 5,\n",
       "         'scannedLineItemsPerSecond scannedLineItemsTotal': 5,\n",
       "         'lineItemVoids scansWithoutRegistration lineItemVoids*scansWithoutRegistration': 5,\n",
       "         'scansWithoutRegistration scannedLineItemsTotal^2': 2,\n",
       "         'valuePerSecond^2 valuePerLineItem': 1,\n",
       "         'totalScanTimeInSeconds lineItemVoids^2': 4,\n",
       "         'totalScanTimeInSeconds^2 scannedLineItemsTotal': 4,\n",
       "         'lineItemVoidsPerPosition lineItemVoids*scansWithoutRegistration': 4,\n",
       "         'grandTotal^2 scannedLineItemsTotal': 4,\n",
       "         'lineItemVoids^2 valuePerSecond': 3,\n",
       "         'totalScanTimeInSeconds scannedLineItemsTotal valuePerLineItem': 5,\n",
       "         'scannedLineItemsPerSecond valuePerLineItem^2': 3,\n",
       "         'totalScanTimeInSeconds quantityModificationsPerLineItem^2': 2,\n",
       "         'valuePerSecond lineItemVoids*scansWithoutRegistration': 3,\n",
       "         'scannedLineItemsTotal^2 valuePerLineItem': 1,\n",
       "         'valuePerSecond': 1,\n",
       "         'totalScanTimeInSeconds lineItemVoids quantityModifications': 1,\n",
       "         'totalScanTimeInSeconds lineItemVoids*scansWithoutRegistration': 3,\n",
       "         'scannedLineItemsPerSecond^2': 1,\n",
       "         'quantityModificationsPerLineItem lineItemVoids*scansWithoutRegistration': 1,\n",
       "         'totalScanTimeInSeconds scansWithoutRegistration': 1,\n",
       "         'scansWithoutRegistration^2 scannedLineItemsTotal': 1,\n",
       "         'scansWithoutRegistration': 1,\n",
       "         'totalScanTimeInSeconds lineItemVoids quantityModificationsPerLineItem': 1,\n",
       "         'grandTotal^2 lineItemVoids': 1,\n",
       "         'grandTotal^2 valuePerSecond': 1,\n",
       "         'lineItemVoids scansWithoutRegistration quantityModifications': 2,\n",
       "         'lineItemVoids lineItemVoidsPerPosition': 3,\n",
       "         'lineItemVoids scannedLineItemsPerSecond quantityModificationsPerLineItem': 1,\n",
       "         'scansWithoutRegistration quantityModificationsPerLineItem^2': 2,\n",
       "         'scannedLineItemsPerSecond scannedLineItemsTotal valuePerLineItem': 1,\n",
       "         'lineItemVoids^3': 1,\n",
       "         'scansWithoutRegistration lineItemVoidsPerPosition': 3,\n",
       "         'scannedLineItemsPerSecond^2 valuePerLineItem': 1,\n",
       "         'totalScanTimeInSeconds scansWithoutRegistration lineItemVoidsPerPosition': 1,\n",
       "         'totalScanTimeInSeconds^2 valuePerLineItem': 1,\n",
       "         'totalScanTimeInSeconds^2 lineItemVoids*scansWithoutRegistration': 1,\n",
       "         'valuePerSecond quantityModificationsPerLineItem lineItemVoids*scansWithoutRegistration': 1,\n",
       "         'scannedLineItemsTotal valuePerLineItem^2': 2,\n",
       "         'scannedLineItemsTotal^2': 1,\n",
       "         'lineItemVoids valuePerSecond scannedLineItemsTotal': 2,\n",
       "         'quantityModifications^2 lineItemVoidsPerPosition': 1,\n",
       "         'grandTotal lineItemVoids lineItemVoidsPerPosition': 1,\n",
       "         'scannedLineItemsPerSecond^2 scannedLineItemsTotal': 1,\n",
       "         'valuePerSecond scannedLineItemsTotal^2': 2,\n",
       "         'quantityModifications^2 scannedLineItemsTotal': 2,\n",
       "         'scansWithoutRegistration quantityModifications^2': 1,\n",
       "         'scansWithoutRegistration lineItemVoidsPerPosition scannedLineItemsTotal': 1,\n",
       "         'lineItemVoids quantityModificationsPerLineItem^2': 1,\n",
       "         'valuePerLineItem quantityModificationsPerLineItem^2': 1,\n",
       "         'scansWithoutRegistration quantityModifications valuePerLineItem': 1,\n",
       "         'totalScanTimeInSeconds scannedLineItemsTotal^2': 1,\n",
       "         'grandTotal scannedLineItemsPerSecond valuePerLineItem': 1,\n",
       "         'scansWithoutRegistration^2 quantityModifications': 1})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(features_to_use1_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trust Level 2 (Feature Importance by Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/niklas/.local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/niklas/.local/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "# normalize data first to prevent 0's in dataset\n",
    "scaler2 = StandardScaler()\n",
    "names_X_train2 = X_train2.columns\n",
    "X_train2 = scaler2.fit_transform(X_train2)\n",
    "\n",
    "# generate features and rescale\n",
    "polyFeatures2 = PolynomialFeatures(3, interaction_only=False)\n",
    "X_train2_all = polyFeatures2.fit_transform(X_train2)\n",
    "X_train2_all = scaler.fit_transform(X_train2_all)\n",
    "\n",
    "#remove the first var because it is the constant term\n",
    "X_train2_all = X_train2_all[:,1:]\n",
    "features_X_train2_all = polyFeatures2.get_feature_names(input_features=names_X_train2)[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance with logistic Regression\n",
    "lr = LogisticRegression(C=20, solver='lbfgs')\n",
    "lr.fit(X_train2_all, y2)\n",
    "imp = lr.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# order the feature indices by importance\n",
    "imp = pd.DataFrame(imp)\n",
    "imp = imp.sort_values(by=0, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_use2_cv = []\n",
    "for cvNew in np.arange(0,100,20):\n",
    "    # choose starting model\n",
    "    model = CustomModelWithThreshold(LogisticRegression(C=10, solver='lbfgs', max_iter=300), 0.9)\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=10, random_state=cvNew, shuffle=True)\n",
    "    last_score = -10000\n",
    "\n",
    "    # add most important feature\n",
    "    X2_temporary = pd.DataFrame(X_train2_all[:,(list(imp.index))[0]])\n",
    "\n",
    "    features_to_use2 = [(list(imp.index))[0]]\n",
    "    # iteratively add features one by one\n",
    "    for featnum in (list(imp.index))[1:]:\n",
    "        X_check = pd.concat([X2_temporary,pd.Series(X_train2_all[:,featnum])], axis=1)\n",
    "        score = sum(cross_validate(model,X_check, y2, scoring=profit_scoring, cv=cv)['test_score'])\n",
    "        # add the feature ultimatively if score improved\n",
    "        if score > last_score:\n",
    "            X2_temporary = pd.concat([X2_temporary,pd.Series(X_train2_all[:,featnum])], axis=1)\n",
    "            features_to_use2.append(featnum)\n",
    "            last_score = score    \n",
    "            #print(last_score)\n",
    "  \n",
    "    # for test predictions use features_to_use to select the according features in the test set    \n",
    "    features_to_use2_names = [features_X_train2_all[i] for i in features_to_use2]\n",
    "    features_to_use2_cv = features_to_use2_cv + features_to_use2_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'scannedLineItemsTotal^2': 5,\n",
       "         'scannedLineItemsTotal^3': 5,\n",
       "         'totalScanTimeInSeconds scannedLineItemsTotal^2': 5,\n",
       "         'totalScanTimeInSeconds lineItemVoids scannedLineItemsTotal': 4,\n",
       "         'totalScanTimeInSeconds^2 scannedLineItemsTotal': 2,\n",
       "         'totalScanTimeInSeconds scannedLineItemsTotal valuePerLineItem': 4,\n",
       "         'totalScanTimeInSeconds scansWithoutRegistration valuePerLineItem': 5,\n",
       "         'totalScanTimeInSeconds lineItemVoids*scansWithoutRegistration^2': 1,\n",
       "         'scannedLineItemsTotal quantityModificationsPerLineItem lineItemVoids*scansWithoutRegistration': 2,\n",
       "         'lineItemVoids*scansWithoutRegistration': 1,\n",
       "         'scansWithoutRegistration scannedLineItemsTotal valuePerLineItem': 1,\n",
       "         'scannedLineItemsTotal^2 lineItemVoids*scansWithoutRegistration': 2,\n",
       "         'totalScanTimeInSeconds^2 valuePerLineItem': 1,\n",
       "         'lineItemVoids scannedLineItemsTotal^2': 1,\n",
       "         'scannedLineItemsTotal^2 quantityModificationsPerLineItem': 1,\n",
       "         'grandTotal scansWithoutRegistration scannedLineItemsPerSecond': 1,\n",
       "         'lineItemVoids^2 scannedLineItemsTotal': 1,\n",
       "         'scansWithoutRegistration^2': 1,\n",
       "         'totalScanTimeInSeconds^2 scansWithoutRegistration': 1})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(features_to_use2_cv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
