{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### same imports as in main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.tree import DecisionTreeClassifier as DT\n",
    "from sklearn import svm as SVM\n",
    "from sklearn.naive_bayes import GaussianNB as NB\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# custom imports\n",
    "from funcs import plot_cv_confidence_vs_profit, score_dmc_profit,dmc_profit,cv_preds_and_confusion_matrix,cv_profits_for_models, profit_scoring\n",
    "from customClassifiers import CustomModelWithThreshold, TrustHard, PerceptronLearner\n",
    "from pipes import CustomAttributeAdder,Scaling,RandomAttributeAdder,Transformer,ClfSwitcher\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# use sklearn pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv', sep='|')\n",
    "df_test = pd.read_csv('test.csv', sep='|')\n",
    "\n",
    "# split label and predictors\n",
    "X_train, y_train = df_train.drop(columns=['fraud',]), df_train['fraud']\n",
    "X_test = df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = ['scannedLineItemsTotal',\n",
    "                #'valuePerLineItem',\n",
    "                #'quantityModificationsPerLineItem',\n",
    "                'lineItemVoids*scansWithoutRegistration',\n",
    "                'totalScanTimeInSeconds/trustLevel',\n",
    "                'trustLevel_Log', \n",
    "               ]\n",
    "\n",
    "featureGeneration_pipeline = Pipeline([\n",
    "    (\"attribs_adder\", CustomAttributeAdder(featurelist=feature_list)),                \n",
    "    #(\"RandomAttributeAdder\", RandomAttributeAdder())         #  This class is still void\n",
    "    ])\n",
    "\n",
    "\n",
    "preprocessing_pipeline = Pipeline([\n",
    "    #(\"transformer\", Transformer()),                           # This class is still void\n",
    "    (\"scaler\", Scaling(strategy='Standard')),\n",
    "])\n",
    "\n",
    "data_preparation_pipeline = Pipeline([\n",
    "    ('feature_generation', featureGeneration_pipeline),\n",
    "    ('preprocessing', preprocessing_pipeline)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare X_train and X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/niklas/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/niklas/anaconda3/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/niklas/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/niklas/anaconda3/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 2.90890804e-01, -8.48396806e-01,  1.33309604e+00, ...,\n",
       "         1.67119810e-01, -6.91222611e-01,  4.77364223e-01],\n",
       "       [-2.94705662e-01,  1.67163106e-01,  3.11740617e-01, ...,\n",
       "         5.39164642e-01, -1.04481221e-01,  1.46764073e-03],\n",
       "       [-1.46589859e+00, -1.42520458e+00, -1.24644115e+00, ...,\n",
       "        -2.79333988e-01, -5.69386827e-01, -1.81590606e+00],\n",
       "       ...,\n",
       "       [-2.94705662e-01, -1.16422270e+00, -1.54394685e+00, ...,\n",
       "         3.15937743e-01, -7.36322045e-01,  1.46764073e-03],\n",
       "       [-8.80302128e-01,  1.15057308e+00, -5.54801009e-01, ...,\n",
       "        -6.51378820e-01,  1.04611528e+00, -6.69270920e-01],\n",
       "       [-2.94705662e-01,  1.02197331e+00,  2.41780022e-01, ...,\n",
       "         1.84132155e+00,  3.01189308e-01,  1.46764073e-03]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_preparation_pipeline.fit_transform(X_train)\n",
    "data_preparation_pipeline.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['trustLevel', 'totalScanTimeInSeconds', 'grandTotal', 'lineItemVoids',\n",
       "       'scansWithoutRegistration', 'quantityModifications',\n",
       "       'scannedLineItemsPerSecond', 'valuePerSecond',\n",
       "       'lineItemVoidsPerPosition', 'scannedLineItemsTotal',\n",
       "       'lineItemVoids*scansWithoutRegistration',\n",
       "       'totalScanTimeInSeconds/trustLevel', 'trustLevel_Log'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['trustLevel', 'totalScanTimeInSeconds', 'grandTotal', 'lineItemVoids',\n",
       "       'scansWithoutRegistration', 'quantityModifications',\n",
       "       'scannedLineItemsPerSecond', 'valuePerSecond',\n",
       "       'lineItemVoidsPerPosition', 'scannedLineItemsTotal',\n",
       "       'lineItemVoids*scansWithoutRegistration',\n",
       "       'totalScanTimeInSeconds/trustLevel', 'trustLevel_Log'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train best model from presentation 2 on train set\n",
    "### i.e. Logistic Regression with C = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=40, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=42, solver='liblinear',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(C=40, solver='liblinear', random_state=42)\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict fraudsters for the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check percentage of fraudsters predicted and in train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04737603915514504"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(test_predict)/len(test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05534858967535923"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df_train.fraud)/len(df_train.fraud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 4.7% predicted vs. 5.5% in train\n",
    "- seems to be a reasonable result since we want to be careful with predicting someone as a fraud\n",
    "- maybe it makes sense to always check our models on the test set to see how this percentage changes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check how many fraudsters per trustLevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19717\n",
      "3882\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(sum(test_predict[df_test.trustLevel == 1]))\n",
    "print(sum(test_predict[df_test.trustLevel == 2]))\n",
    "print(sum(test_predict[df_test.trustLevel == 3]))\n",
    "print(sum(test_predict[df_test.trustLevel == 4]))\n",
    "print(sum(test_predict[df_test.trustLevel == 5]))\n",
    "print(sum(test_predict[df_test.trustLevel == 6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
